{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       1     1     1     1     1     3     1   data_5\n",
      "NaN       1     1     1     1     1     3     2   data_6\n",
      "NaN       1     1     1     1     3     2     1  data_19\n",
      "NaN       1     1     1     1     3     3     2  data_22\n",
      "NaN       1     1     1     2     1     2     1  data_27\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       0     1     1     1     1     2     2   data_4\n",
      "NaN       0     1     1     1     1     4     1   data_7\n",
      "NaN       0     1     1     1     2     1     1   data_9\n",
      "NaN       0     1     1     1     2     1     2  data_10\n",
      "NaN       0     1     1     1     2     2     1  data_11\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       0     1     1     1     1     1     1  data_1\n",
      "NaN       0     1     1     1     1     1     2  data_2\n",
      "NaN       0     1     1     1     1     2     1  data_3\n",
      "NaN       0     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "NaN       0     1     1     1     1     4     1  data_7\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n"
     ]
    }
   ],
   "source": [
    "from api.data_handler import DataHandler\n",
    "\n",
    "# Creation of a DataHandler Object\n",
    "data_handler = DataHandler(['target', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'id'])\n",
    "\n",
    "# Number of different Datasets\n",
    "datasets_number = 3\n",
    "\n",
    "# Lists of DataFrames\n",
    "df_train : list[pd.DataFrame] = []\n",
    "df_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Load the Training/Test sets into pandas DataFrames\n",
    "for i in range(datasets_number):\n",
    "    df_train.append(data_handler.load_data(f'data/monks/monks-{i+1}.train'))\n",
    "    df_test.append(data_handler.load_data(f'data/monks/monks-{i+1}.test'))\n",
    "\n",
    "    # Print the head of the loaded data\n",
    "    print(df_train[i].head())\n",
    "    print(df_test[i].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data\n",
    "x_train : list[pd.DataFrame] = []\n",
    "y_train : list[pd.DataFrame] = []\n",
    "x_test  : list[pd.DataFrame] = []\n",
    "y_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Split data into TR set and TS set\n",
    "for i in range(datasets_number):\n",
    "\n",
    "    # Saving the splitted TR set data into the lists\n",
    "    x, y = data_handler.split_data(data=df_train[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "\n",
    "    # Saving the splitted TS set data into the lists\n",
    "    x, y = data_handler.split_data(df_test[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monk 1 [TRAIN]: (124, 17)\n",
      "Monk 1 [TEST]: (432, 17)\n",
      "Monk 2 [TRAIN]: (169, 17)\n",
      "Monk 2 [TEST]: (432, 17)\n",
      "Monk 3 [TRAIN]: (122, 17)\n",
      "Monk 3 [TEST]: (432, 17)\n"
     ]
    }
   ],
   "source": [
    "# Applies the 1-Hot Encoding to the \"x\" data\n",
    "for i in range(datasets_number):\n",
    "    x_train[i] = data_handler.one_hot_encoding(x_train[i])\n",
    "    x_test[i]  = data_handler.one_hot_encoding(x_test[i])\n",
    "\n",
    "    # Print of the data modified\n",
    "    print(f\"Monk {i+1} [TRAIN]: \" + str(x_train[i].shape))\n",
    "    print(f\"Monk {i+1} [TEST]: \" + str(x_test[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters' space for Grid Search (1 for each Dataset)\n",
    "param_space = {\n",
    "    0: {\n",
    "        'hidden_units': [3, 4],\n",
    "        'patience': [15, 30],\n",
    "        'learning_rate': [0.3, 0.4],\n",
    "        'batch_size': [4, 6],\n",
    "        'nesterov': [\"T\", \"F\"],\n",
    "        'epochs': [350, 450],\n",
    "        'momentum': [0.6, 0.7]\n",
    "    },\n",
    "    1: {\n",
    "        'hidden_units': [3, 4, 5],\n",
    "        'patience': [15, 30],\n",
    "        'factor_lr_dec': [0.5, 1],\n",
    "        'step_decay': [500, 1000, 1500],\n",
    "        'learning_rate': [0.9, 0.8, 0.7],\n",
    "        'batch_size': [10, 30, 60], \n",
    "        'epochs': [180, 250, 350],\n",
    "        'momentum': [0.6, 0.7, 0.8],\n",
    "        'nesterov': [\"T\", \"F\"],\n",
    "    },\n",
    "    2: {\n",
    "        'hidden_units': [2, 3],\n",
    "        'patience': [10,15,30],\n",
    "        'factor_lr_dec': [0.5, 1],\n",
    "        'step_decay': [500, 1000, 1500],\n",
    "        'learning_rate': [float(i/100) for i in range(1,10)],\n",
    "        'batch_size': [7, 8, 9, 32, 64],\n",
    "        'epochs': [int(350+epochs) for epochs in range(0,50,10)],\n",
    "        'weight_decay': [float(i/1000) for i in range(1,10)],\n",
    "        'momentum': [float(i/1000) for i in range(10,90,5)] + [float(i/100) for i in range(10,90,5)],\n",
    "        'nesterov': [\"T\", \"F\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyperparameters Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.02896787069767015\n",
      " Mean Validation Loss:              0.03841469454346225\n",
      " Mean Training Accuracy:            0.9657575726509094\n",
      " Mean Validation Accuracy:          0.9519999980926513\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.02896787069767015\n",
      " Mean Validation Loss:              0.03841469454346225\n",
      " Mean Training Accuracy:            0.9657575726509094\n",
      " Mean Validation Accuracy:          0.9519999980926513\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             2\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.03897079482267145\n",
      " Mean Validation Loss:              0.07724700019753072\n",
      " Mean Training Accuracy:            0.9576767683029175\n",
      " Mean Validation Accuracy:          0.902999997138977\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.02896787069767015\n",
      " Mean Validation Loss:              0.03841469454346225\n",
      " Mean Training Accuracy:            0.9657575726509094\n",
      " Mean Validation Accuracy:          0.9519999980926513\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             3\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.016835275891935453\n",
      " Mean Validation Loss:              0.03542113358853385\n",
      " Mean Training Accuracy:            0.9797979950904846\n",
      " Mean Validation Accuracy:          0.9519999980926513\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.02896787069767015\n",
      " Mean Validation Loss:              0.03841469454346225\n",
      " Mean Training Accuracy:            0.9657575726509094\n",
      " Mean Validation Accuracy:          0.9519999980926513\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010568265328765846\n",
      " Mean Validation Loss:              0.017208239546744154\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             3\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.016835275891935453\n",
      " Mean Validation Loss:              0.03542113358853385\n",
      " Mean Training Accuracy:            0.9797979950904846\n",
      " Mean Validation Accuracy:          0.9519999980926513\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             5\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.017062875600822737\n",
      " Mean Validation Loss:              0.03841154489782639\n",
      " Mean Training Accuracy:            0.9757575750350952\n",
      " Mean Validation Accuracy:          0.943999993801117\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010568265328765846\n",
      " Mean Validation Loss:              0.017208239546744154\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             6\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010904437662975396\n",
      " Mean Validation Loss:              0.03379426076717209\n",
      " Mean Training Accuracy:            0.9878787994384766\n",
      " Mean Validation Accuracy:          0.9680000066757202\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010568265328765846\n",
      " Mean Validation Loss:              0.017208239546744154\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             7\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.03445071396417916\n",
      " Mean Validation Loss:              0.04227868507441599\n",
      " Mean Training Accuracy:            0.9516161561012269\n",
      " Mean Validation Accuracy:          0.9269999980926513\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010568265328765846\n",
      " Mean Validation Loss:              0.017208239546744154\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             8\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.021861212509975303\n",
      " Mean Validation Loss:              0.025175984905217774\n",
      " Mean Training Accuracy:            0.973737370967865\n",
      " Mean Validation Accuracy:          0.9679999947547913\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010568265328765846\n",
      " Mean Validation Loss:              0.017208239546744154\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             9\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.031735354440752414\n",
      " Mean Validation Loss:              0.05745374829275533\n",
      " Mean Training Accuracy:            0.9636363744735718\n",
      " Mean Validation Accuracy:          0.9360000014305114\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010568265328765846\n",
      " Mean Validation Loss:              0.017208239546744154\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             10\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.00857189051748719\n",
      " Mean Validation Loss:              0.011395658168476075\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010568265328765846\n",
      " Mean Validation Loss:              0.017208239546744154\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             11\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.024383540078997613\n",
      " Mean Validation Loss:              0.04958270822535269\n",
      " Mean Training Accuracy:            0.9697979807853698\n",
      " Mean Validation Accuracy:          0.9429999947547912\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             10\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.00857189051748719\n",
      " Mean Validation Loss:              0.011395658168476075\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             12\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.025725986031466162\n",
      " Mean Validation Loss:              0.06403827677131631\n",
      " Mean Training Accuracy:            0.9778787970542908\n",
      " Mean Validation Accuracy:          0.9269999980926513\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             10\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.00857189051748719\n",
      " Mean Validation Loss:              0.011395658168476075\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             13\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.060843154042959216\n",
      " Mean Validation Loss:              0.09955917447805404\n",
      " Mean Training Accuracy:            0.9174343585968018\n",
      " Mean Validation Accuracy:          0.8700000047683716\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             10\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.00857189051748719\n",
      " Mean Validation Loss:              0.011395658168476075\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             14\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.019456946042191704\n",
      " Mean Validation Loss:              0.03484558949712664\n",
      " Mean Training Accuracy:            0.9758585810661315\n",
      " Mean Validation Accuracy:          0.9590000033378601\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             10\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.00857189051748719\n",
      " Mean Validation Loss:              0.011395658168476075\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             15\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.015279515099246055\n",
      " Mean Validation Loss:              0.024155651964247227\n",
      " Mean Training Accuracy:            0.9839393973350525\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             10\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.00857189051748719\n",
      " Mean Validation Loss:              0.011395658168476075\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             10\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.00857189051748719\n",
      " Mean Validation Loss:              0.011395658168476075\n",
      " Mean Training Accuracy:            0.9858585834503174\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             17\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.03511143037612783\n",
      " Mean Validation Loss:              0.0707480721292086\n",
      " Mean Training Accuracy:            0.9596969723701477\n",
      " Mean Validation Accuracy:          0.9109999895095825\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             18\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.016526324587175623\n",
      " Mean Validation Loss:              0.02330485060811043\n",
      " Mean Training Accuracy:            0.9797979831695557\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             19\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.06059592598321615\n",
      " Mean Validation Loss:              0.059972038489650006\n",
      " Mean Training Accuracy:            0.9112121224403381\n",
      " Mean Validation Accuracy:          0.943999993801117\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             20\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.02587275285331998\n",
      " Mean Validation Loss:              0.0454441486945143\n",
      " Mean Training Accuracy:            0.9696969747543335\n",
      " Mean Validation Accuracy:          0.943999993801117\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             21\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.04078043564513791\n",
      " Mean Validation Loss:              0.02930318543803878\n",
      " Mean Training Accuracy:            0.9334343314170838\n",
      " Mean Validation Accuracy:          0.9759999990463257\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             22\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0031983305554604156\n",
      " Mean Validation Loss:              0.023572218682966196\n",
      " Mean Training Accuracy:            0.9979797959327698\n",
      " Mean Validation Accuracy:          0.9679999947547913\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             23\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.05264523476362228\n",
      " Mean Validation Loss:              0.09654561802744865\n",
      " Mean Training Accuracy:            0.9395959615707398\n",
      " Mean Validation Accuracy:          0.8789999961853028\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             24\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 4, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.010400231601670385\n",
      " Mean Validation Loss:              0.04033678612759104\n",
      " Mean Training Accuracy:            0.9899999976158143\n",
      " Mean Validation Accuracy:          0.9509999990463257\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             25\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.04543105738703161\n",
      " Mean Validation Loss:              0.04579497342929244\n",
      " Mean Training Accuracy:            0.9314141392707824\n",
      " Mean Validation Accuracy:          0.9269999980926513\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             26\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.036118760993122126\n",
      " Mean Validation Loss:              0.04587342223385349\n",
      " Mean Training Accuracy:            0.9515353560447692\n",
      " Mean Validation Accuracy:          0.9440000057220459\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             27\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.03949687832500785\n",
      " Mean Validation Loss:              0.047624587640166284\n",
      " Mean Training Accuracy:            0.9516161561012269\n",
      " Mean Validation Accuracy:          0.9509999990463257\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             28\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.017276141096954235\n",
      " Mean Validation Loss:              0.052549617507611404\n",
      " Mean Training Accuracy:            0.9819191932678223\n",
      " Mean Validation Accuracy:          0.9269999980926513\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             29\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.01545511340664234\n",
      " Mean Validation Loss:              0.04313559461734258\n",
      " Mean Training Accuracy:            0.9838383913040161\n",
      " Mean Validation Accuracy:          0.9600000023841858\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             30\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.03222176969720749\n",
      " Mean Validation Loss:              0.05524515600700397\n",
      " Mean Training Accuracy:            0.961717164516449\n",
      " Mean Validation Accuracy:          0.9269999980926513\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             31\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.022905546007677913\n",
      " Mean Validation Loss:              0.03912184122018516\n",
      " Mean Training Accuracy:            0.9697979807853698\n",
      " Mean Validation Accuracy:          0.9350000023841858\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             32\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'F', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.01684020806060289\n",
      " Mean Validation Loss:              0.028096522483974696\n",
      " Mean Training Accuracy:            0.9778787851333618\n",
      " Mean Validation Accuracy:          0.975\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             33\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 450, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.029631638215505518\n",
      " Mean Validation Loss:              0.0678164403885603\n",
      " Mean Training Accuracy:            0.9659191966056824\n",
      " Mean Validation Accuracy:          0.9183333396911622\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m nn_i\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39mn_hidden_layers_list[dataset_i])\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mnn_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_val\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m nn_i\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     50\u001b[0m     x_train\u001b[38;5;241m=\u001b[39mx_kfold_train,\n\u001b[0;32m     51\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my_kfold_train,\n\u001b[0;32m     52\u001b[0m     x_val\u001b[38;5;241m=\u001b[39mx_kfold_val,\n\u001b[0;32m     53\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_kfold_val\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\corra\\Documents\\GitHub\\Machine_Learning_Project\\api\\binary_nn.py:276\u001b[0m, in \u001b[0;36mBinaryNN.fit\u001b[1;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Training of the model with TR set and VL set (already splitted)\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Error case\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1855\u001b[0m     )\n\u001b[1;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1871\u001b[0m }\n\u001b[0;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2294\u001b[0m             ):\n\u001b[0;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[0;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[1;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from api.binary_nn import BinaryNN\n",
    "\n",
    "# Creation of a BinaryNN objct for each dataset\n",
    "nn: list[BinaryNN] = []\n",
    "\n",
    "# Different values per dataset\n",
    "trials_list = [40, 30, 50]\n",
    "k_values = [5, 5, 5]\n",
    "n_hidden_layers_list = [1, 1, 1]\n",
    "\n",
    "# Search of the best Hyperparameters to each Training set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_train[dataset_i].values\n",
    "    y = y_train[dataset_i].values\n",
    "    k = k_values[dataset_i]\n",
    "\n",
    "    # K-fold Cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Computes and Stores all the parameters combinations\n",
    "    data_handler.set_params_combinations(params=param_space[dataset_i])\n",
    "\n",
    "    params_combinations = data_handler.get_params_combinations()\n",
    "\n",
    "    # For each iteration we choose the hyperparameters and we use them with K-fold CV\n",
    "    for trial, params in enumerate(params_combinations):\n",
    "\n",
    "        # Creation of the Neural Network object\n",
    "        nn_i = BinaryNN(params=params, monk_i=dataset_i+1, trial=trial+1)\n",
    "\n",
    "        # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "        for train_index, val_index in kfold.split(X, y):\n",
    "            x_kfold_train, x_kfold_val = X[train_index], X[val_index]\n",
    "            y_kfold_train, y_kfold_val = y[train_index], y[val_index]\n",
    "\n",
    "            # Building the model\n",
    "            nn_i.create_model(n_hidden_layers=n_hidden_layers_list[dataset_i])\n",
    "\n",
    "            # Training the model\n",
    "            nn_i.fit(\n",
    "                x_train=x_kfold_train,\n",
    "                y_train=y_kfold_train,\n",
    "                x_val=x_kfold_val,\n",
    "                y_val=y_kfold_val\n",
    "            )\n",
    "\n",
    "            # Evaluating the model\n",
    "            nn_i.evaluate(\n",
    "                x_train=x_kfold_train,\n",
    "                y_train=y_kfold_train,\n",
    "                x_val=x_kfold_val,\n",
    "                y_val=y_kfold_val\n",
    "            )\n",
    "\n",
    "        # Case of first append\n",
    "        if len(nn) == dataset_i:\n",
    "            nn.append(nn_i)\n",
    "\n",
    "        # Print the results of this trial\n",
    "        print(\"------------------ Current Hyperparameters ------------------\")\n",
    "        nn_i.print_training_info()\n",
    "        print(\"-------------------- Best Hyperparameters -------------------\")\n",
    "        nn[dataset_i].print_training_info()\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # Update best hyperparameters if: no high overfitting AND (higher mean VL accuracy OR (equal mean AND\n",
    "        if nn_i.mean_tr_accuracy-0.1 <= nn_i.mean_vl_accuracy \\\n",
    "            and (\n",
    "                    nn[dataset_i].mean_vl_accuracy < nn_i.mean_vl_accuracy \\\n",
    "                or (\n",
    "                    nn[dataset_i].mean_vl_accuracy == nn_i.mean_vl_accuracy and nn[dataset_i].mean_tr_accuracy < nn_i.mean_tr_accuracy\n",
    "                    )\n",
    "            ):\n",
    "            nn[dataset_i] = nn_i\n",
    "\n",
    "        # Case of TR/VL AND TR/VL loss minor\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy >= 0.98 \\\n",
    "            and nn_i.mean_tr_accuracy == nn[dataset_i].mean_tr_accuracy \\\n",
    "            and nn_i.mean_vl_accuracy == nn[dataset_i].mean_vl_accuracy \\\n",
    "            and abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < 0.02 \\\n",
    "            and nn_i.mean_vl_loss < nn[dataset_i].mean_vl_loss \\\n",
    "            and nn_i.mean_tr_loss < nn[dataset_i].mean_tr_loss:\n",
    "            nn[dataset_i] = nn_i\n",
    "\n",
    "        # Exit case\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy == 1 \\\n",
    "            and nn_i.mean_vl_loss < 0.1 and nn_i.mean_tr_loss < 0.1 \\\n",
    "            and abs(nn_i.mean_vl_loss - nn_i.mean_tr_loss) < 0.01:\n",
    "            nn[dataset_i] = nn_i\n",
    "            break\n",
    "\n",
    "    # Print output\n",
    "    print(f\"### Best Hyperparameters of Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print of best Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Best Hyperparameters for Monk 1 ###\n",
      " Monk:                              1\n",
      " Trial:                             16\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.0010178768876357935\n",
      " Mean Validation Loss:              0.009073081542737782\n",
      " Mean Training Accuracy:            1.0\n",
      " Mean Validation Accuracy:          0.9919999957084655\n",
      "\n",
      "### Best Hyperparameters for Monk 2 ###\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(datasets_number):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Print best hyperparameters\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Best Hyperparameters for Monk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mprint_training_info()\n\u001b[0;32m      7\u001b[0m     nn[dataset_i]\u001b[38;5;241m.\u001b[39mprint_plot()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# BEST L CURVE M1: >(semismoothed)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1500, 'learning_rate': 0.999, 'batch_size': 17, 'epochs': 350, 'weight_init': 'glorot_normal', 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#  Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.5, 'batch_size': 32, 'epochs': 370, 'weight_init': 'lecun_normal', 'momentum': 0.8, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m    \u001b[38;5;66;03m# BEST SMOOTHER PT2 MONK2:  {'hidden_units': 4, 'patience': 10, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 450, 'momentum': 0.3, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iteration on all the Datasets\n",
    "for dataset_i in range(datasets_number):\n",
    "\n",
    "    # Print best hyperparameters\n",
    "    print(f\"\\n### Best Hyperparameters for Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "    nn[dataset_i].print_plot()\n",
    "   \n",
    " \n",
    "    # BEST L CURVE M1: >(semismoothed)\n",
    "    # Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1500, 'learning_rate': 0.999, 'batch_size': 17, 'epochs': 350, 'weight_init': 'glorot_normal', 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    #  Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.5, 'batch_size': 32, 'epochs': 370, 'weight_init': 'lecun_normal', 'momentum': 0.8, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    # Hyp:  {'input_units': 17, 'hidden_units': 5, 'patience': 200, 'factor_lr_dec': 0.5, 'step_decay': 500, 'learning_rate': 0.99, 'batch_size': 16, 'epochs': 530, 'weight_init': 'lecun_normal', 'momentum': 0.5, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    \n",
    "    # BEST SMOOTHED CURVE MONK1:   HyperparameterS: {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 440, 'momentum': 0.6}\n",
    "                                                     #Hyperparameters:          {'input_units': 17, 'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'F', 'epochs': 440, 'momentum': 0.7, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "\n",
    "   # BEST SMOOTHER PT2 MONK2:  {'hidden_units': 4, 'patience': 10, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 450, 'momentum': 0.3, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "\n",
    "'''\n",
    "Best Hyperparameters for Monk 2\n",
    " Monk:                     2\n",
    " Trial:                    3\n",
    " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 200, 'factor_lr_dec': 1.0, 'step_decay': 500, 'learning_rate': 0.999, 'batch_size': 60, 'epochs': 290, 'momentum': 0.75, 'nesterov': 'T', 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    " Mean Training Loss:       0.0006283932307269424\n",
    " Mean Validation Loss:     0.004200904699973762\n",
    " Mean Training Accuracy:   1.0\n",
    " Mean Validation Accuracy: 1.0\n",
    "\n",
    "### Best Hyperparameters for Monk 3 ###\n",
    " Monk:                     3\n",
    " Trial:                    14\n",
    " Hyperparameters:          {'input_units': 17, 'hidden_units': 2, 'patience': 30, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.07, 'batch_size': 7, 'epochs': 370, 'weight_decay': 0.002, 'momentum': 0.08, 'nesterov': 'T', 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    " Mean Training Loss:       0.059438984096050265\n",
    " Mean Validation Loss:     0.07536792308092118\n",
    " Mean Training Accuracy:   0.9508310675621032\n",
    " Mean Validation Accuracy: 0.934333324432373\n",
    "\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining: Mean, Standard Deviation and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Monk 1 ###\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 2s 31ms/step - loss: 0.2190 - accuracy: 0.6263 - val_loss: 0.2880 - val_accuracy: 0.4800\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1656 - accuracy: 0.7475 - val_loss: 0.4209 - val_accuracy: 0.4800\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.1213 - accuracy: 0.8889 - val_loss: 0.4549 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9091 - val_loss: 0.4560 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0768 - accuracy: 0.9192 - val_loss: 0.4539 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9192 - val_loss: 0.4506 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9192 - val_loss: 0.4503 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0708 - accuracy: 0.9192 - val_loss: 0.4517 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0690 - accuracy: 0.9192 - val_loss: 0.4576 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0655 - accuracy: 0.9192 - val_loss: 0.4597 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9192 - val_loss: 0.4681 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9192 - val_loss: 0.4548 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9192 - val_loss: 0.4656 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9697 - val_loss: 0.4641 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.19557204842567444\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.6854838728904724\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 12ms/step - loss: 0.2163 - accuracy: 0.6869 - val_loss: 0.3705 - val_accuracy: 0.4800\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.7778 - val_loss: 0.4010 - val_accuracy: 0.4400\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.8889 - val_loss: 0.4743 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9192 - val_loss: 0.4898 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9192 - val_loss: 0.4994 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9293 - val_loss: 0.5119 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9596 - val_loss: 0.5227 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.4400\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.4400\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.4400\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.4400\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.4400\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.4400\n",
      " Monk:                              1\n",
      " Trial:                             2\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.21556736528873444\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.6854838728904724\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 9ms/step - loss: 0.2199 - accuracy: 0.6768 - val_loss: 0.3439 - val_accuracy: 0.4400\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.8081 - val_loss: 0.4041 - val_accuracy: 0.4800\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.8485 - val_loss: 0.4282 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9192 - val_loss: 0.4386 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9192 - val_loss: 0.4409 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9192 - val_loss: 0.4354 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9192 - val_loss: 0.4246 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9192 - val_loss: 0.4137 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9192 - val_loss: 0.4188 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9192 - val_loss: 0.4320 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9192 - val_loss: 0.4425 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9293 - val_loss: 0.4560 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9697 - val_loss: 0.4632 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             3\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.20704291760921478\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.7177419066429138\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 11ms/step - loss: 0.2467 - accuracy: 0.5556 - val_loss: 0.3249 - val_accuracy: 0.3600\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.8182 - val_loss: 0.4416 - val_accuracy: 0.4400\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.8687 - val_loss: 0.4464 - val_accuracy: 0.4400\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9091 - val_loss: 0.4723 - val_accuracy: 0.3600\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9192 - val_loss: 0.4590 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9192 - val_loss: 0.4533 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9192 - val_loss: 0.4646 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9192 - val_loss: 0.4683 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9192 - val_loss: 0.4685 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9192 - val_loss: 0.4739 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9495 - val_loss: 0.4694 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9899 - val_loss: 0.4699 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.21829934418201447\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.7016128897666931\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 10ms/step - loss: 0.2218 - accuracy: 0.6364 - val_loss: 0.4090 - val_accuracy: 0.4000\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.8283 - val_loss: 0.4475 - val_accuracy: 0.4800\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.8990 - val_loss: 0.4790 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9192 - val_loss: 0.4704 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9596 - val_loss: 0.5120 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9798 - val_loss: 0.5132 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5216 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             5\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.20656919479370117\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.725806474685669\n",
      " Mean Validation Accuracy:          0\n",
      "\n",
      "Mean TR MSE: 0.20861017405986787\n",
      "\n",
      "Mean VL MSE: 0.0\n",
      "\n",
      "Mean TR Accuracy: 0.7032258033752441\n",
      "\n",
      "Mean VL Accuracy: 0.0\n",
      "\n",
      "Variance TR MSE: 6.377942733019281e-05\n",
      "\n",
      "Variance VL MSE: 0.0\n",
      "\n",
      "Variance TR Accuracy: 0.00027055153117373716\n",
      "\n",
      "Variance VL Accuracy: 0.0\n",
      "Standard Deviation TR MSE: 0.007986202309620813\n",
      "\n",
      "Standard Deviation VL MSE: 0.0\n",
      "Standard Deviation TR Accuracy: 0.016448450722598075\n",
      "Standard Deviation VL Accuracy: 0.0\n",
      "\n",
      "### Monk 2 ###\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Inner loop for different initializations\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_initializations):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Create a new model instance with the best hyperparameters for the current monk\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     nn_instance \u001b[38;5;241m=\u001b[39m BinaryNN(params\u001b[38;5;241m=\u001b[39m\u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mparams, monk_i\u001b[38;5;241m=\u001b[39mdataset_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, trial\u001b[38;5;241m=\u001b[39m_\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m     nn_instance\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39mn_hidden_layers_list[dataset_i])\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Training the model\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of initializations\n",
    "num_initializations = 5\n",
    "\n",
    "# Iterate over each monk (dataset)\n",
    "for dataset_i in range(datasets_number):\n",
    "    print(f\"\\n### Monk {dataset_i + 1} ###\")\n",
    "\n",
    "    # Extract dataset for the current monk\n",
    "    x = x_train[dataset_i].values\n",
    "    y_fit = y_train[dataset_i].values\n",
    "    X = x_test[dataset_i].values\n",
    "    y = y_test[dataset_i].values\n",
    "\n",
    "    tr_mse_values = []  # List to store MSE TR values for each initialization\n",
    "    vl_mse_values = []  # List to store MSE VL values for each initialization\n",
    "    vl_acc_values = []   # List to store Accuracies values for each initialization\n",
    "    tr_acc_values = []   # List to store Accuracies values for each initialization\n",
    "\n",
    "    # Inner loop for different initializations\n",
    "    for _ in range(num_initializations):\n",
    "        # Create a new model instance with the best hyperparameters for the current monk\n",
    "        nn_instance = BinaryNN(params=nn[dataset_i].params, monk_i=dataset_i+1, trial=_+1)\n",
    "        nn_instance.create_model(n_hidden_layers=n_hidden_layers_list[dataset_i])\n",
    "        \n",
    "        # Training the model\n",
    "        nn_instance.fit(x_train=x,\n",
    "               y_train=y_fit\n",
    "                        )\n",
    "\n",
    "        # Evaluating the model\n",
    "        nn_instance.evaluate(\n",
    "                x_train=x,\n",
    "                y_train=y_fit\n",
    "                )\n",
    "       \n",
    "        # Access the training loss from the nn_instance and store it\n",
    "        tr_mse_values.append(nn_instance.mean_tr_loss)\n",
    "        vl_mse_values.append(nn_instance.mean_vl_loss)\n",
    "        tr_acc_values.append(nn_instance.mean_tr_accuracy)\n",
    "        vl_acc_values.append(nn_instance.mean_vl_accuracy)\n",
    "\n",
    "        nn_instance.print_training_info()\n",
    "\n",
    "\n",
    "    # Calculate and print mean, variance and standard deviation\n",
    "    \n",
    "    # Mean TR mse\n",
    "    meantr_mse = np.mean(tr_mse_values)\n",
    "    # Mean VL mse\n",
    "    meanvl_mse = np.mean(vl_mse_values)\n",
    "    \n",
    "    # Mean TR accuracies\n",
    "    meantr_acc = np.mean(tr_acc_values)\n",
    "    # Mean VL accuracies\n",
    "    meanvl_acc = np.mean(vl_acc_values)\n",
    "\n",
    "    # Variance MSE VL\n",
    "    variance_mse_vl = np.var(vl_mse_values)\n",
    "    # Variance MSE TR\n",
    "    variance_mse_tr = np.var(tr_mse_values)\n",
    "\n",
    "    # Variance TR accuracies\n",
    "    variancetr_acc = np.var(tr_acc_values)\n",
    "    # Variance VL accuracies\n",
    "    variancevl_acc = np.var(vl_acc_values)\n",
    "\n",
    "    # Standard dev TR accuracies\n",
    "    std_tr_acc = np.std(tr_acc_values)\n",
    "    # Standard dev VL accuracies\n",
    "    std_vl_acc = np.std(vl_acc_values)\n",
    "    \n",
    "    # Standard dev VL mse\n",
    "    std_deviation_vl = np.std(vl_mse_values)\n",
    "    # Standard dev TR mse\n",
    "    std_deviation_tr = np.std(tr_mse_values)\n",
    "\n",
    "    print(f'\\nMean TR MSE: {meantr_mse}')\n",
    "    print(f'\\nMean VL MSE: {meanvl_mse}')\n",
    "    print(f'\\nMean TR Accuracy: {meantr_acc}')\n",
    "    print(f'\\nMean VL Accuracy: {meanvl_acc}')\n",
    "    print(f'\\nVariance TR MSE: {variance_mse_tr}')\n",
    "    print(f'\\nVariance VL MSE: {variance_mse_vl}')\n",
    "    print(f'\\nVariance TR Accuracy: {variancetr_acc}')\n",
    "    print(f'\\nVariance VL Accuracy: {variancevl_acc}')\n",
    "    print(f'Standard Deviation TR MSE: {std_deviation_tr}')\n",
    "    print(f'\\nStandard Deviation VL MSE: {std_deviation_vl}')\n",
    "    print(f'Standard Deviation TR Accuracy: {std_tr_acc}')\n",
    "    print(f'Standard Deviation VL Accuracy: {std_vl_acc}')\n",
    "\n",
    "    # Plot learning curves\n",
    "    nn_instance.print_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Monk:                         1\n",
      " Trial:                        16\n",
      " Hyperparameters:              {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:           0.0010178768876357935\n",
      " Mean Validation Loss:         0.009073081542737782\n",
      " Test Loss:                    0.00023188439081422985\n",
      " Mean Training Accuracy:       1.0\n",
      " Mean Validation Accuracy:     0.9919999957084655\n",
      " Test Accuracy:                1.0\n",
      " f1 score:                     1.0\n",
      " f2 score:                     1.0\n",
      " Precision score:              1.0\n",
      " Recall score:                 1.0\n",
      "\n",
      "              Predicted_Class_0  Predicted_Class_1\n",
      "Real_Class_0                216                  0\n",
      "Real_Class_1                  0                216\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAGDCAYAAAA72Cm3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABJ70lEQVR4nO3dd3wVVfrH8c9D6BA6IkUEBJSiIEXFRUGsNFFRKRYUFbH3XXet+9N1say9YkMFCSsiYAMbVmyggEgTBSFKb0IgQMjz+2OGbIghuUBuJjf5vl+vvJKZOTPzzLn35rnnzJkZc3dEREQk8ZSKOgARERHZO0riIiIiCUpJXEREJEEpiYuIiCQoJXEREZEEpSQuIiKSoJTEpVCZ2Y9m1jXqOIoKM/uHmT0X0b5HmNndUey7oJnZOWb23l6uu9fvSTP7wswO35t195aZXW1mwwpzn1J0KYmXYGa22My2mNkmM1se/lOvHM99unsrd/84nvvYyczKmdm/zWxJeJw/mdlNZmaFsf9c4ulqZqnZ57n7Pe5+cZz2Z+E//NlmlmZmqWb2mpkdGo/97S0zu9PMRu7LNtx9lLufFMO+/vTFZW/fk2bWG9jo7t+H03ea2fbw87TezKaaWacc61Qzs6fCz9tmM/vBzC7MZdsDzWxauK1lZvaumXUOFw8HzjWz/fKILSFee9l3SuLS290rA22Bw4G/RxvOnjOz0rtZ9BpwPNADSAbOA4YAj8QhBjOzovZ5egS4BrgaqAE0B8YDPQt6R3m8BnEX4b6HAq/kmDcm/DzVAqYQvAcBMLOywAfAgUAnoCpwEzDMzK7PVu564GHgHqAO0BB4EugD4O7pwLvA+XnEVmCvfZSvrcTA3fVTQn+AxcAJ2abvA97ONn0UMBVYD8wEumZbVgN4EfgdWAeMz7asFzAjXG8qcFjOfQL1gC1AjWzLDgdWA2XC6cHA3HD7k4EDs5V14ArgJ2BRLsd2PJAOHJBj/pHADqBpOP0x8G/gG2ADMCFHTHnVwcfAv4AvwmNpClwYxrwR+AW4NCxbKSyTCWwKf+oBdwIjwzKNwuMaBCwJ6+KWbPurALwU1sdc4K9A6m5e22bhcR6Rx+s/AngCeDuM92vgoGzLHwGWAn8A04Fjsi27ExgLjAyXXwwcAXwZ1tUy4HGgbLZ1WgHvA2uBFcA/gFOAbcD2sE5mhmWrAs+H2/kNuBtICpddENb5Q+G27g7nfR4ut3DZyvA1nQW0JvgCtz3c3ybgzZyfAyApjOvnsE6mk+M9FJYrG76eDXLUychs0y3D17N2OH1RGFOlHNvqF8ZTJTzuTcBZ+Xx2zwGm7MNr/zFwcbbprPrL7fMFPA08kGMbE4Drw7/rAa8Dq8LyV0f9/62k/EQegH4ifPF3/efVAPgBeCScrg+sIWjFlgJODKd3/kN6GxgDVAfKAF3C+e3Cf1RHhv8QB4X7KZfLPj8CLskWz/3A0+HfpwELgRZAaeBWYGq2sk6QEGoAFXI5tmHAJ7s57l/5X3L9mCBJtCZItK/zv6SaXx18TJBsW4UxliFo6RxEkEi6AJuBdmH5ruRIuuSexJ8lSNhtgK1Ai+zHFNZ5A4LktLskPhT4NZ/XfwRBEjwijH8UkJJt+blAzXDZDcByoHy2uLeHr1OpMN72BF96SofHMhe4NiyfTJCQbwDKh9NH5qyDbPseDzwTvib7EXzJ2vmaXQBkAFeF+6rArkn8ZILkWy18HVoAdbMd8915fA5uIvgcHByu2waomUvdtQLS8ngty4av12qgdDgvBXgpl22VDo/nZIIvNRk718njtWsHrN2H1/5j8k/iWZ8v4FiCL3QWLq9O8CWmXvj6TwduD4+7CcEX2JOj/h9XEn6KWvefFL7xZraR4AO6ErgjnH8u8I67v+Pume7+PjAN6GFmdYHuwFB3X+fu2939k3C9S4Bn3P1rd9/h7i8RJKKjctn3q8AACLqjgf7hPIBLgX+7+1x3zyDoWmxrZgdmW//f7r7W3bfksu1aBEkjN8vC5Tu94u6z3T0NuA0428yS8qqDbOuOcPcf3T0jrIe33f1nD3wCvAccs5s4duef7r7F3WcStP7bhPPPBu4J6zwVeDSPbdTM4/izG+fu34R1PIrgtAoA7j7S3deEx/YfoBxBctvpS3cfH9bNFnef7u5fheUXEyThLmHZXsByd/+Pu6e7+0Z3/zq3gMysDsH761p3T3P3lQQt6/7Ziv3u7o+F+8r5+m8n+JJwCEHSmevusdQFBD0Kt7r7/PA1nOnua3IpV42gpZ7T2Wa2niDBXQKcGdYt7OY9GS5fHS6vCazOts7ubCRotecm1tc+P9k/X58RJPad7+UzCV7/34GOBF9s/8/dt7n7LwRfRPvnulUpUEricpq7JxO0Eg/hf8ntQOCscIDO+vAfU2egLnAAQStgXS7bOxC4Icd6BxB8Y89pLNDJzOoRfNN3gn8WO7fzSLZtrCVoGdXPtv7SPI5rdRhrbuqGy3Pbzq8ELepa5F0HucZgZt3N7CszWxuW78GuXxhisTzb35uBnYMN6+XYX17Hv4bdH38s+8LMbjCzuWa2ITyWqux6LDmPvbmZvRUO2vqD4IvXzvIHEHRRx+JAgtdgWbZ6f4agRZ7rvrNz948IuvKfAFaY2XAzqxLjvmONcx3BF4Wc/uvu1QjOZc8m6J3YKdf3ZHjOuVa4fA1QK4bz0MkEpwpyE+trn5+sOnZ3J+hJGBDOGkjwpQ+C16tejs/JPwjqQOJMSVwACFuNI4AHwllLCVqo1bL9VHL3YeGyGmZWLZdNLQX+lWO9iu4+Opd9ridoqZ5N8E9hdPjPYud2Ls2xnQruPjX7JvI4pA+AI83sgOwzzewIgn/UH2Wbnb1MQ4KW3Op86uBPMZhZOYLu+AeAOuE/83cIvnzkF28slhF0o+cWd04fAg3MrMPe7MjMjgH+RvDaVA+PZQP/Oxb48/E8BcwDmrl7FYJ/5DvLLyU4zZCbnNtZStB7UytbvVdx91Z5rLPrBt0fdff2BN3ezQm6yfNdL584s/uJoAOpfm4L3X01QW/SnWHPFQTvye5mVilH8b4Ex/sVwZiCdILTFHlpQdBLk5tYXvs0oGK26f1zKZOzrkYDZ4a9YUcSvNchqLNFOT4nye7eA4k7JXHJ7mHgRDNrSzBgqbeZnWxmSWZWPrxEqkHYNfku8KSZVTezMmZ2bLiNZ4GhZnZkOGK7kpn1NLPcWi0QdJ+fT/CP7NVs858G/m5mrQDMrKqZnRXrgbj7BwT/zF43s1bhMRxF0Hp4yt1/ylb8XDNraWYVgf8Dxrr7jrzqYDe7LUvQ5bwKyDCz7kD2y55WADXNbHfdoPn5L0GdVA+Tx5W7Kxge35PA6DDmsmH8/c3s5hj2lUxwbnYVUNrMbicYeJXfOn8Am8zsEOCybMveAvY3s2stuPQv2cyODJetABrtHN0fvr/eA/5jZlXMrJSZHWRmXYiBmXUM339lCJJVOsFAr537apLH6s8Bd5lZs/D9e5iZ1cxZyN23EyTl3cbk7vMIBmT+NZz1CpAKvGZmjcLPzckEp0XudPcN7r6B4NzyE2Z2mplVDMt1N7P7sm2+C8FnMLf9xvLazwDOCLfflGDQXZ48uJRuVVhHk8Mv4RCMV/jDzP5mZhXCz0prM+uY3zZl3ymJSxZ3XwW8DNzm7ksJLmn5B8EHdylBa2bne+Y8ghbrPIJz6deG25hGcC7wcYIux4UEg2Z2ZyLBaNoV4TngnbG8AdwLpIRds7MJzpPuib4El/lMIhjxO5JgxPNVOcq9QtALsZxg0NXVYQz51cEu3H1juO5/CY59YHh8O5fPI2jN/BJ2O+Z2iiEv/0eQBBYRJJCxBC243bma/3UrryfoJj4deDOGfU0mSBILCE4xpJN39z3AjQTHvJHgy9yYnQvCujkR6E1Qzz8Bx4WLd16GtcbMvgv/Pp/gS9EcgrocS+xdxFXC/a8LY1/D/3qYngdahvU/Ppd1HyR4/d4j+ELyPMHArtw8Q/A5yMv9wBAz28/dtxJcmbGU4EqAP8L93eLu9+9cwd0fBK4nGMy58313JcFgP8ysPMFpmpfy2G9+r/1DBKP0V4TbGfXnTeRqdHgMWV+4wy+8vQnGUywi6MV6jt2fs5cCtHOkoUiJZGYfE4wojuSuafvCzC4D+rt7TC1UKXhm9jlwVdhKLax9XkVw2dtf8y0sxZ4u4hdJEOG51SYE502bEVyu9XikQZVw7t45/1IFvs/HCnufUnQpiYskjrIEXbiNCbpIUwjOfYpICaXudBERkQSlgW0iIiIJSklcREQkQSXcOfFatWp5o0aNog5DRESk0EyfPn21u9fOOT/hknijRo2YNm1a1GGIiIgUGjP7Nbf56k4XERFJUEriIiIiCUpJXEREJEEpiYuIiCQoJXEREZEEpSQuIiKSoJTERUREEpSSuIiISIJSEhcREUlQcUviZvaCma00s9m7WW5m9qiZLTSzWWbWLl6xiIiIFEfxbImPAE7JY3l3oFn4MwR4Ko6xiIiIFDtxu3e6u39qZo3yKNIHeNmDB5p/ZWbVzKyuuy+LV0x/Mq4nLHqn0HYnIiLF2+K11WhUYz3c4IWyvyjPidcHlmabTg3n/YmZDTGzaWY2bdWqVQUXgRK4iIgUgMxM4/4pR9Ns2FX8d0arQttvlE8xs1zm5frVxd2HA8MBOnToUPBfbwrpG5OIiBQ/K1ZsYtCg8Uye/DMAPzR6lLMLad9RJvFU4IBs0w2A3yOKRUREZK/885+fMHnyz9SsWYERI06jV6/mhbbvKJP4ROBKM0sBjgQ2FOr5cBERkQLw738fT1radu65pxv161cp1H3H8xKz0cCXwMFmlmpmF5nZUDMbGhZ5B/gFWAg8C1wer1hEREQKyi+/rGPw4Amkp2cAULVqeV566bRCT+AQ39HpA/JZ7sAV8dq/iIhIQRszZjZDhrzFH39spX79ZO66q1uk8UTZnS4iIpIQ0tK2cc01k3j++e8BOP30Q7juuk4RR6UkLiIikqdZs1bQr99Y5s1bTblySTz88Clceml7zHK7yKpwKYmLiIjsxpw5qzjiiGfZunUHLVvWJiWlL4ceWifqsLIoiYuIiOxGixa1OPXUg6levTwPPXQKFSuWiTqkXSiJi4iIZPPZZ79Sp05lmjeviZnx6qt9KV26aD70s2hGJSIiUsh27Mjkn//8mK5dX6J//7Fs3RpcQlZUEzioJS4iIkJq6h+cc844Pv30V8yge/emlCoV/cC1/CiJi4hIiTZx4nwuvHACa9duYf/9KzNy5Okcf3yTqMOKiZK4iIiUWH/96/vcf/9UIGh9jxhxGvvtVyniqGKnJC4iIiVWo0bVKFOmFMOGncC11x6VEF3o2SmJi4hIieHuLFq0niZNqgNw2WUdOOGEJjRvXjPiyPZO0R1yJyIiUoA2bEhn4MBxtGnzNAsXrgXAzBI2gYOSuIiIlADffPMbhx/+DCkps3F35s1bHXVIBULd6SIiUmxlZjr/+c9U/vGPj8jIyOTww/cnJeXMhG59Z6ckLiIixdKKFZsYNGg8kyf/DMC11x7JsGEnUK5c8Ul9xedIREREslm2bBNTpiymZs0KjBhxGr16NY86pAKnJC4iIsXGjh2ZJCUFw73att2fMWPOpGPHetSvXyXiyOJDA9tERKRY+OWXdRx99AukpMzOmnfaaYcU2wQOSuIiIlIMpKTM5vDDn+Gbb37jnns+IzPTow6pUCiJi4hIwkpL28bgwRMYMOB1/vhjK337tuCTTy5IuDuv7S2dExcRkYQ0Y8Zy+vcfy/z5ayhfvjQPPXQyl17aHrOSkcBBSVxERBJQZqZz/vlvMH/+Glq2rM2YMWfSuvV+UYdV6JTERUQk4ZQqZYwYcRrPPfcdDzxwEhUrlok6pEjonLiIiCSETz/9ldtu+yhrul27ujz5ZM8Sm8BBLXERESniMjIyufvuT7nrrk/JzHQ6d27IySc3jTqsIkFJXEREiqylSzdwzjnj+OyzJZjBP/7RmW7dGkcdVpGhJC4iIkXShAnzuPDCCaxbl07dupUZOfIMJfAclMRFRKTIefnlmQwaNB6AHj2aMWJEH2rXrhRtUEWQkriIiBQ5p512CC1a1OKSS9pxzTVHlZibt+wpJXEREYmcu/Paa3Po3bs5FSqUoUqVcsycOZQyZZKiDq1I0yVmIiISqQ0b0hk4cBz9+o3lhhvey5qvBJ4/tcRFRCQyX3+dyoABr7No0XoqVSpDp04Nog4poSiJi4hIocvMdO6//wtuvXUKGRmZtGtXl5SUvjRrVjPq0BKKkriIiBSqzZu3c9ppKbz//i8AXHvtkQwbdgLlyikl7SnVmIiIFKoKFUpTvXoFatWqyIgRfejZs3nUISUsJXEREYm77dt3sGrVZurVS8bMeOaZXmzevJ169ZKjDi2haXS6iIjE1S+/rKNz5xfp0WMU6ekZAFSrVl4JvAAoiYuISNyMHv0Dbds+zTff/Ma6deksWbIh6pCKFXWni4hIgUtL28ZVV73Liy/OAKBv3xY8+2xvqlevEG1gxYySuIiIFKgZM5bTv/9Y5s9fQ/nypXn44ZMZMqQ9Zrp1akFTEhcRkQL19depzJ+/hlatapOSciatW+8XdUjFlpK4iIjssx07MklKCoZZ7Wx1n3vuYVSsWCbiyIo3DWwTEZF98skni2nV6kkWLFgDgJkxZEh7JfBCoCQuIiJ7JSMjkzvumEK3bi8zf/4a/vOfqVGHVOKoO11ERPbY0qUbOOeccXz22RLM4JZbjuHOO7tGHVaJoyQuIiJ7ZPz4eQwePIF169KpW7cyI0eeQbdujaMOq0RSEhcRkZj9/vtG+vcfy9atO+jZsxkvvtiH2rUrRR1WiaUkLiIiMatXL5lHHjmFLVsyuOaaI3Xtd8SUxEVEZLfcnRde+J5KlcrSv39rAC69tEPEUclOSuIiIpKrDRvSufTStxgz5kcqVy7Lccc1ok6dylGHJdnE9RIzMzvFzOab2UIzuzmX5VXN7E0zm2lmP5rZhfGMR0REYvP116kcfvgzjBnzI5UqleHJJ3sogRdBcWuJm1kS8ARwIpAKfGtmE919TrZiVwBz3L23mdUG5pvZKHffFq+4RERk9zIznfvv/4Jbb51CRkYm7drVJSWlL82a1Yw6NMlFPFviRwAL3f2XMCmnAH1ylHEg2YKREZWBtUBGHGMSEZE8XHHF29x884dkZGRy/fVHMXXqYCXwIiyeSbw+sDTbdGo4L7vHgRbA78APwDXunhnHmEREJA+XXtqBBg2q8PbbA/nPf06mXDkNnSrK4pnEc7vuwHNMnwzMAOoBbYHHzazKnzZkNsTMppnZtFWrVhV0nCIiJda2bTt47bUfs6bbtt2fn3++mh49mkUYlcQqnkk8FTgg23QDghZ3dhcC4zywEFgEHJJzQ+4+3N07uHuH2rVrxy1gEZGS5Oef19K58wucffZYxoyZnTW/bNmkCKOSPRHPJP4t0MzMGptZWaA/MDFHmSXA8QBmVgc4GPgljjGJiAjw6qs/cPjhz/Dtt7/TsGFVDjigatQhyV6I28kOd88wsyuByUAS8IK7/2hmQ8PlTwN3ASPM7AeC7ve/ufvqeMUkIlLSbdq0jauuepcRI2YA0LdvC559tjfVq1eINjDZK3EdseDu7wDv5Jj3dLa/fwdOimcMIiISWLhwLb16vcr8+WsoX740jzxyCpdc0k63Tk1gGnYoIlJC1KlTiR07nFatajNmzJm0arVf1CHJPlISFxEpxtas2UyFCmWoWLEMycnlmDTpHOrVS6ZChTJRhyYFIK63XRURkeh88sli2rR5muuum5Q176CDaiiBFyNK4iIixUxGRiZ33DGFbt1e5rffNvLjj6vYsmV71GFJHKg7XUSkGFm6dAMDB47j88+XYAa33noMd9zRldKl1WYrjpTERUSKifHj5zF48ATWrUunXr1kRo48neOOaxx1WBJHSuIiIsXEf//7I+vWpdOrV3NefLEPtWpVjDokiTMlcRGRBJaZ6ZQqFVzn/fTTvTjuuEZcfLGu/S4pdJJERCQBuTvPPfcdRx/9fNagtSpVynHJJe2VwEsQJXERkQSzYUM6Awa8ziWXvMnXX//Ga6/NiTokiYi600VEEshXX6UyYMDrLF68nsqVy/LUUz0599zDog5LIqIkLiKSADIznfvv/4Jbb51CRkYm7dvXZfTovjRrVjPq0CRC6k4XEUkAb7+9gJtv/pCMjEyuv/4opk69SAlc1BIXEUkEvXo157LLOtC7d3O6d28WdThSRKglLiJSBG3btoO///0D5s1bDYCZ8eSTPZXAZRdqiYuIFDELF65lwIDXmTbtd95//xe+/fYSXTYmuVISFxEpQkaNmsVll73Nxo3bOPDAqjz2WHclcNktJXERkSJg06ZtXHnlO7z00kwAzjqrJcOH96ZatfIRRyZFmZK4iEjEduzIpHPnF5g5cwUVKpTmkUdO0a1TJSYa2CYiErGkpFIMHdqB1q33Y9q0Ibp1qsRMSVxEJAKrV2/mo48WZU1feml7pk27hJYta0cYlSQaJXERkUL28ceLadPmaU49dTQ//bQGCC4hK1dOZzhlzyiJi4gUkoyMTG6/fQrdur3E779vpG3b/ZW4ZZ/o3SMiUgiWLNnAwIGv88UXSzGD2247lttv70Lp0mpLyd5TEhcRibPJkxfSv//rrF+fTr16yYwceTrHHdc46rCkGFASFxGJs/33r8yWLdvp1as5L77Yh1q1KkYdkhQTSuIiInHw++8bqVcvGYA2bfbn668v5rDD6ujSMSlQOhkjIlKA3J1nn51O06aPMnr0D1nz27TZXwlcCpySuIhIAVm/Pp1+/cYyZMhbbNmSwdSpS6MOSYo5daeLiBSAL79cysCB41i8eD2VK5fl6ad7cs45h0UdlhRzSuIiIvsgM9O5997Pue22KezY4bRvX5eUlDNp2rRG1KFJCaDudBGRfbBly3ZGjJjJjh3ODTd0YurUi5TApdCoJS4ishfcHTOjUqWypKT0ZfnyTXTv3izqsKSEURIXEdkD27bt4O9//4CNG7cxfHhvAA4/vG7EUUlJpSQuIhKjhQvX0r//WKZPX0bp0qW44YZOHHxwrajDkhJM58RFRGIwcuQsDj/8GaZPX0ajRtX47LMLlcAlcmqJi4jkYdOmbVx55Tu89NJMAM46qyXDh/emWrXyEUcmoiQuIpKnu+76hJdemkmFCqV55JFTuPjidrrzmhQZSuIiInm49dZjWbBgLf/6VzdatqwddTgiu9A5cRGRbFatSuPqq99l8+btACQnl+ONN/opgUuRpJa4iEhoypRFnHPOOJYt20RSkvHQQ6dEHZJInmJuiZtZpXgGIiISlYyMTG677SOOP/5lli3bROfODbnuuk5RhyWSr3yTuJkdbWZzgLnhdBszezLukYmIFIJff11P164juPvuzwC4/fZjmTJlEA0bVo04MpH8xdKd/hBwMjARwN1nmtmxcY1KRKQQLFmygbZtn2H9+nTq1Utm1Kgz6Nq1UdRhicQspnPi7r40xyUVO+ITjohI4TnggCp0796UTZu28cILfahVq2LUIYnskViS+FIzOxpwMysLXE3YtS4ikmh+/HElSUmlOOSQWpgZL7zQh3LlknTttySkWAa2DQWuAOoDqUBb4PI4xiQiUuDcneHDp9Ox47P06zeW9PQMAMqXL60ELgkrlpb4we5+TvYZZvYX4Iv4hCQiUrDWr09nyJA3ee21OQC0a1eXHTsyI45KZN/FksQfA9rFME9EpMj58sulDBjwOr/+uoHk5LI8/XQvBg48NOqwRArEbpO4mXUCjgZqm9n12RZVAZLiHZiIyL568MEv+etf32fHDqdDh3qkpPTloINqRB2WSIHJqyVeFqgclknONv8P4Mx4BiUiUhCSk8uyY4dz442d+Ne/jqdsWbU/pHjZbRJ390+AT8xshLv/ujcbN7NTgEcIWu7PufuwXMp0BR4GygCr3b3L3uxLRARg+fJN7L9/ZQAuvrgd7dvXo127uhFHJRIfsYxO32xm95vZO2b20c6f/FYysyTgCaA70BIYYGYtc5SpBjwJnOrurYCz9vgIRESArVszuP76yTRr9hjz568GwMyUwKVYiyWJjwLmAY2BfwKLgW9jWO8IYKG7/+Lu24AUoE+OMgOBce6+BMDdV8YYt4hIlp9+WsPRR7/AQw99xZYt2/nqq9SoQxIpFLEk8Zru/jyw3d0/cffBwFExrFcfWJptOjWcl11zoLqZfWxm083s/Nw2ZGZDzGyamU1btWpVDLsWkZLilVdm0q7dcL77bhmNGlXj888HM2hQ26jDEikUsVxitj38vczMegK/Aw1iWC+3uyd4LvtvDxwPVAC+NLOv3H3BLiu5DweGA3To0CHnNkSkBNq4cStXXPEOr7wyC4Czz27FM8/0olq18hFHJlJ4Yknid5tZVeAGguvDqwDXxrBeKnBAtukGBF8AcpZZ7e5pQJqZfQq0ARYgIpKHX3/dwGuvzaFChdI89lh3Bg8+XHdekxIn3yTu7m+Ff24AjoOsO7bl51ugmZk1Bn4D+hOcA89uAvC4mZUmuKTtSIKnpomI/Im7ZyXq1q334+WXT6NVq/1o2bJ2xJGJRGO358TNLMnMBpjZjWbWOpzXy8ymAo/nt2F3zwCuBCYTPDDlv+7+o5kNNbOhYZm5wCRgFvANwWVos/f5qESk2Fm1Ko1evUbzyiszs+addVYrJXAp0fJqiT9P0B3+DfComf0KdAJudvfxsWzc3d8B3skx7+kc0/cD9+9BzCJSwkyZsohzzhnHsmWbmD17Jf36tdaNW0TIO4l3AA5z90wzKw+sBpq6+/LCCU1ESrqMjEzuvPNj7rnnM9yhc+eGjBp1hhK4SCivJL7N3TMB3D3dzBYogYtIYfn11/UMHDiOqVOXUqqUcdttx3DbbV0oXTqWK2NFSoa8kvghZjYr/NuAg8JpA9zdD4t7dCJSIrk7/fu/zldfpVK/fjKjRp1Bly6Nog5LpMjJK4m3KLQoRESyMTOeeqon//rXZzz9dE9q1qwYdUgiRVJeD0DZq4eeiIjsjR9/XMm4cXO57bbgGUht2+7Pa6/pcQoieYnlZi8iInHj7gwfPp1rr51MenoGrVvvx+mnqyNQJBZK4iISmXXrtjBkyFuMHTsHgAsvbMtJJx0UcVQiiSOmJG5mFYCG7j4/zvGISAkxdepSBgx4nSVLNpCcXJZnnunFgAGHRh2WSELJ91oNM+sNzCC4sxpm1tbMJsY5LhEpxt56awHHHvsiS5ZsoGPHenz//aVK4CJ7IZaW+J0Ezwb/GMDdZ5hZo/iFJCLFXZcuB9K0aQ1OPfVg7r67m27eIrKXYkniGe6+QU8HEpF98cEHv9CpUwMqVSpLcnI5vvvuUipWLBN1WCIJLZZbH802s4FAkpk1M7PHgKlxjktEiomtWzO4/vrJnHjiK1x77aSs+UrgIvsuliR+FdAK2Aq8SvBI0mvjGJOIFBM//bSGo49+gYce+orSpUvRtGkN3D3qsESKjVi60w9291uAW+IdjIgUH6+8MpPLL3+HTZu20bhxNUaP7suRRzaIOiyRYiWWJP6gmdUFXgNS3P3HOMckIgls+/YdDB48kZEjg0cv9OvXimee6UXVquUjjkyk+Mm3O93djwO6AquA4Wb2g5ndGu/ARCQxlS5dCnenQoXSPPdcb0aP7qsELhInMT3Tz92Xu/ujwFCCa8Zvj2dQIpJY3J1Vq9KA4OElTz7Zk+nTh3DRRe3QlS0i8RPLzV5amNmdZjYbeJxgZLpObIkIAKtWpdGr12iOO+4ltmzZDkCVKuVo0aJ2xJGJFH+xnBN/ERgNnOTuv8c5HhFJIB99tIhzzx3HsmWbqF69PHPnrqZdu7pRhyVSYuSbxN39qMIIREQSx/btO7jzzo/5978/xx2OOaYho0adwQEHVI06NJESZbdJ3Mz+6+5nm9kPQPYLOw1wdz8s7tGJSJGzePF6Bg58nS+/TKVUKeP224/l1luPpXTpmIbYiEgByqslfk34u1dhBCIiiWHKlEV8+WUq9esnM2rUGXTp0ijqkERKrN0mcXdfFv55ubv/LfsyM7sX+Nuf1xKR4sjds0aZX3BBW9avT+f889tQs2bFiCMTKdli6f86MZd53Qs6EBEpmmbPXslRRz3P3LmrgOASsuuu66QELlIE7DaJm9ll4fnwg81sVrafRcCswgtRRKLg7jzzzDQ6dnyWb775jdtv/zjqkEQkh7zOib8KvAv8G7g52/yN7r42rlGJSKTWrdvCJZe8yeuvzwVg8OC2PPqoOuBEipq8kri7+2IzuyLnAjOroUQuUjx98cUSBg4cx5IlG0hOLsszz/RiwIBDow5LRHKRX0u8FzCd4BKz7PdOdKBJHOMSkQisW7eF7t1HsXHjNjp2rMfo0X056KAaUYclIruR1+j0XuHvxoUXjohEqXr1CvznPyexcOFa7rqrG2XLJkUdkojkId87tpnZX4AZ7p5mZucC7YCH3X1J3KMTkbh7552f2LhxK/36tQbgkkvaRxyRiMQqlkvMngI2m1kb4K/Ar8ArcY1KROJu69YMrrtuEj17vspFF01k8eL1UYckInsolgegZLi7m1kf4BF3f97MBsU7MBGJnwUL1jBgwOt8990ySpcuxe23d6FhQ933XCTRxJLEN5rZ34HzgGPMLAkoE9+wRCReXn55Jpdf/jZpadtp3Lgao0f35cgj9XRhkUQUS3d6P2ArMNjdlwP1gfvjGpWIxMXtt09h0KDxpKVtp3//1nz//aVK4CIJLN8kHibuUUBVM+sFpLv7y3GPTEQK3FlntaRGjQo8//ypvPrqGVStWj7qkERkH+SbxM3sbOAb4CzgbOBrMzsz3oGJyL7LzHTeffenrOlDD63Dr79ey+DBh2c90EREElcs3em3AB3dfZC7nw8cAdwW37BEZF+tXJlGr16v0qPHq4wc+b/HHVSuXDbCqESkIMUysK2Uu6/MNr2G2JK/iETkww9/4dxz32D58k1Ur16eqlXLRR2SiMRBLEl8kplNBkaH0/2Ad+IXkojsre3bd3DHHR8zbNjnuMOxxx7IyJGnc8ABunxMpDjKN4m7+01mdgbQmeD+6cPd/Y24RyYie2TZso2cccZ/+eqrVEqVMu6441huvfVYkpLUcSZSXO02iZtZM+AB4CDgB+BGd/+tsAITkT1TpUo51q3bQoMGVRg16gyOPfbAqEMSkTjLqyX+AvAy8CnQG3gMOKMwghKR2GzevB13p1KlslSqVJaJEwdQs2YFatasGHVoIlII8upnS3b3Z919vrs/ADQqpJhEJAazZ6+kY8dnueqqd7PmNW9eUwlcpATJqyVe3swO53/PEa+Qfdrdv4t3cCLyZ+7OM89M57rrJpOensGOHZls2JCuG7eIlEB5JfFlwIPZppdnm3agW7yCEpHcrVu3hYsvfpNx4+YCMHhwWx59tDuVKunab5GSaLdJ3N2PK8xARCRvX3yxhIEDx7FkyQaqVCnHM8/0on//1lGHJSIRiuU6cREpAp577nuWLNnAEUfUZ/TovjRpUj3qkEQkYkriIkWYu2fd4/zRR0/hkENqcv31nShTJiniyESkKNBdIESKqLfeWkDXri+xefN2AJKTy/G3v3VWAheRLLE8xczM7Fwzuz2cbmhmR8Q/NJGSaevWDK69dhK9e4/m009/Zfjw6VGHJCJFVCwt8SeBTsCAcHoj8EQsGzezU8xsvpktNLOb8yjX0cx26BGnUtItWLCGTp2e55FHvqZ06VLcd98JXH31kVGHJSJFVCznxI9093Zm9j2Au68zs3yvZzGzJIJkfyKQCnxrZhPdfU4u5e4FJu9x9CLFyMsvz+Tyy98mLW07TZpUZ/TovhxxRP2owxKRIiyWlvj2MNE6gJnVBjJjWO8IYKG7/+Lu24AUoE8u5a4CXgdW5rJMpET45JPFDBo0nrS07QwY0Jrvv79UCVxE8hVLS/xR4A1gPzP7F3AmcGsM69UHlmabTgV26Rc0s/rA6QQ3jum4uw2Z2RBgCEDDhg1j2LVIYjn22AMZMqQdRx3VgAsuaJs1Il1EJC+xPIp0lJlNB44nuOXqae4+N4Zt5/ZfyHNMPwz8zd135PVPy92HA8MBOnTokHMbIgknM9N5+OGvOOWUprRsWRsz45lnekcdlogkmHyTuJk1BDYDb2af5+5L8lk1FTgg23QD4PccZToAKWECrwX0MLMMdx+ff+giiWnlyjQGDRrPpEkLGTFiBt99dymlS+tqTxHZc7F0p79N0II2oDzQGJgPtMpnvW+BZmbWGPgN6A8MzF7A3Rvv/NvMRgBvKYFLcfbhh79w7rlvsHz5JmrUqMBddx2nBC4iey2W7vRDs0+bWTvg0hjWyzCzKwlGnScBL7j7j2Y2NFz+9N6FLJJ4tm/fwR13fMywYZ/jHpwDHzXqDBo0qBJ1aCKSwPb4tqvu/p2Z7XYQWo6y7wDv5JiXa/J29wv2NBaRRODudO8+ig8/XESpUsYddxzLrbceS1KSWuAism9iOSd+fbbJUkA7YFXcIhIpZsyMAQNaM3/+Gl599QyOOebAqEMSkWIilqZAcrafcgTnyHO73ltEQps3b+fzz/839nPw4MOZM+dyJXARKVB5tsTDm7xUdvebCikekYT3ww8r6N//dRYvXs+0aZfQokVwCVlycrmoQxORYma3LXEzK+3uOwi6z0UkH+7OU099yxFHPMecOas48MCqZGbqtgYiEj95tcS/IUjgM8xsIvAakLZzobuPi3NsIglj7dotXHzxRN54Yx4AF198OA8/fAqVKuX7mAERkb0Wy+j0GsAagluj7rxe3AElcRHgm29+48wz/8vSpX9QpUo5hg/vRb9+raMOS0RKgLyS+H7hyPTZ/C9576Q+QpFQpUplWLVqM0ceWZ/Ro/vSuHH1qEMSkRIirySeBFQmtnugi5Qoa9duoUaNCgC0arUfU6YMon37upQpkxRxZCJSkuSVxJe5+/8VWiQiCeLNN+dz4YUTePDBkzn//DYAHHVUg4ijEpGSKK/rxPUsRJFstm7N4Jpr3uXUU1NYs2YLb765IOqQRKSEy6slfnyhRSFSxM2fv5r+/V9nxozllC5dimHDjue66zpFHZaIlHC7TeLuvrYwAxEpitydl1+eyRVXvENa2naaNKlOSkpfOnasH3VoIiJ7/gAUkZJk27YdDBv2BWlp2xk48FCeeqonVarozmsiUjQoiYvkoVy50owZcybTp//OBRe0xUxDRUSk6FASF8kmM9N56KEvmT9/DcOH9wbgsMPqcNhhdSKOTETkz5TERUIrV6YxaNB4Jk1aCMCQIe3p0KFexFGJiOyekrgI8MEHv3DeeW+wfPkmataswIsv9lECF5EiT0lcSrTt23dw++1TuPfeL3CHLl0OZNSoM6hfv0rUoYmI5Cuvm72IFHv33fcFw4Z9gZnxz3925cMPz1cCF5GEoZa4lGjXXHMUH3/8K7fffizHHHNg1OGIiOwRtcSlRNm8eTu33z6FtLRtAFSuXJb33z9PCVxEEpJa4lJi/PDDCvr1G8vcuatZuTKNp5/uFXVIIiL7RC1xKfbcnSef/JaOHZ9l7tzVtGhRi8sv7xh1WCIi+0wtcSnW1q7dwsUXT+SNN+YBcPHFh/Pww6dQqVLZiCMTEdl3SuJSbK1alUb79sNZuvQPqlQpx/DhvejXr3XUYYmIFBglcSm2ateuRNeujViwYA2jR/elcePqUYckIlKglMSlWPnttz/YtGkbBx9cC4Cnn+5FmTKlKFMmKeLIREQKnga2SbHx5pvzadPmac44479s3rwdgIoVyyiBi0ixpSQuCS89PYNrrnmXU09NYc2aLTRsWJX09IyowxIRiTt1p0tCmz9/Nf37v86MGcspXboUw4Ydz3XXdaJUKT33W0SKPyVxSVijRs3i0kvfIi1tO02aVCclpS8dO9aPOiwRkUKjJC4Ja/v2TNLStjNw4KE89VRPqlQpF3VIIiKFSklcEsr69elUq1YegEGD2tCoUTW6dDkQM3Wfi0jJo4FtkhAyM5377/+CRo0eZs6cVQCYGV27NlICF5ESSy1xKfJWrNjEoEHjmTz5ZwAmTVpIy5a1I45KRCR6SuJSpL3//s+cd94brFiRRs2aFRgx4jR69WoedVgiIkWCkrgUSdu37+DWWz/ivvumAtC1ayNGjjyd+vWrRByZiEjRoXPiUiQtWrSexx77hqQk4667juODD85TAhcRyUEtcSmSmjevyQsv9OGAA6rwl780jDocEZEiSS1xKRLS0rZx8cUTefHF77Pm9e/fWglcRCQPSuISuVmzVtChw7M8//z33HTT+6SlbYs6JBGRhKAkLpFxd5544huOOOJZ5s1bTYsWtZgyZRCVKpWNOjQRkYSgc+ISibVrt3DRRRMZP34eAJdc0o6HHz6FihXLRByZiEjiUBKXSJxzzjgmTVpI1arlePbZ3px1VquoQxIRSThK4hKJ++8/kW3bdvD886fSqFG1qMMREUlIOicuhSI19Q/uu++LrOnWrffjww/PVwIXEdkHaolL3E2cOJ8LL5zA2rVbaNCgCgMHHhp1SCIixYKSuMRNenoGf/3r+zz22DcAdO/elBNOaBJxVCIixYeSuMTFvHmr6d9/LDNnrqBMmVIMG3YC1157FKVK6bGhIiIFRUlcCtxnn/3KKaeMYvPm7TRtWoPRo/vSoUO9qMMSESl24jqwzcxOMbP5ZrbQzG7OZfk5ZjYr/JlqZm3iGY8Ujnbt6tKwYVXOPfcwvvtuiBK4iEicxK0lbmZJwBPAiUAq8K2ZTXT3OdmKLQK6uPs6M+sODAeOjFdMEj/Tp//OwQfXonLlslSqVJapUwdTvXqFqMMSESnW4tkSPwJY6O6/uPs2IAXok72Au09193Xh5FdAgzjGI3GQmencf/8XHHXU81x11btZ85XARUTiL57nxOsDS7NNp5J3K/si4N08lksRs2LFJgYNGs/kyT8DULVqOTIzXYPXREQKSTyTeG7/yT3XgmbHESTxzrtZPgQYAtCwoR5NWRS8997PnH/+G6xYkUbNmhUYMeI0evVqHnVYIiIlSjy701OBA7JNNwB+z1nIzA4DngP6uPua3Dbk7sPdvYO7d6hdu3ZcgpXYZGY6f/vb+5x88khWrEija9dGzJw5VAlcRCQC8Uzi3wLNzKyxmZUF+gMTsxcws4bAOOA8d18Qx1ikgJQqZaxYkUZSknH33cfxwQfnUb9+lajDEhEpkeLWne7uGWZ2JTAZSAJecPcfzWxouPxp4HagJvCkmQFkuHuHeMUke++PP7ZSpUo5AB5/vAdDh3bgqKM0DlFEJEpxvdmLu78DvJNj3tPZ/r4YuDieMci+SUvbxtVXv8vUqalMm3YJlSqVpXLlskrgIiJFgJ5iJrs1c+ZyOnR4lhdemMHixev59ts/DWkQEZEIKYnLn7g7jz/+DUce+Rzz5q2mZcvafPvtJXTt2ijq0EREJBvdO112sXbtFgYPnsCECfMBGDKkHQ89dAoVK5aJODIREclJSVx2MXnyQiZMmE/VquV49tnenHVWq6hDEhGR3VASl13079+aRYvWM3DgoTRqVC3qcEREJA86J17Cpab+wSmnjGT27JUAmBn/+McxSuAiIglALfESbMKEeQwePJG1a7ewY8dk3n//vKhDEhGRPaAkXgKlp2dw003v8fjj3wLQo0czRozok89aIiJS1CiJlzDz5q2mf/+xzJy5gjJlSnHvvSdwzTVH6cljIiIJSEm8BNm8eTvHHvsiq1ZtpmnTGqSk9KV9+3pRhyUiIntJSbwEqVixDMOGncCUKYt58skeJCeXizokERHZBxqdXsx9881v/Pe/P2ZNX3hhW1555XQlcBGRYkAt8WIqM9N54IGp3HLLR5QpU4o2bepw8MG1CJ8WJyIixYCSeDG0fPkmBg0az3vv/QzAlVd21HXfIiLFkJJ4MfPeez9z3nlvsHJlGrVqVWTEiD707Nk86rBERCQOlMSLkcce+5qrr54EwHHHNWLkyDOoVy854qhERCRelMSLkeOPb0Jycln+9re/cPPNnUlK0rhFEZHiTEk8wX3xxRKOPvoAzIyWLWuzaNE11KxZMeqwRESkEKiplqDS0rZx0UUT6Nz5RUaMmJE1XwlcRKTkUEs8Ac2YsZz+/ccyf/4aypcvjXvUEYmISBSUxBOIu/PEE99yww3vsW3bDlq2rM2YMWfSuvV+UYcmIiIRUBJPEOvXp3PBBeOZMGE+AJde2p4HHzyZihXLRByZiIhERUk8QZQtm8RPP62latVyPPfcqZx5ZsuoQxIRkYgpiRdhO3ZksnXrDipWLEPFimUYO/YsKlQoo7uviYgIoNHpRdbSpRvo1u1lhg59K2teixa1lcBFRCSLWuJF0IQJ8xg8eCJr126hbt3KrFixiTp1KkcdloiIFDFqiRch6ekZXHnlO5x22hjWrt1Cjx7NmDlzqBK4iIjkSi3xImLu3FX07/86s2atoEyZUtx77wlcc81RlCqlR4eKiEjulMSLiMce+4ZZs1bQtGkNUlL60r59vahDEhGRIk5JvIi4//4TqVKlHLfccgzJyeWiDkdERBKAzolH5OuvU+nRYxRpadsAqFSpLMOGnaAELiIiMVMSL2SZmc69935O584v8u67C3nggalRhyQiIglK3emFaPnyTZx//hu8//4vAFx77ZHcfHPniKMSEZFEpSReSCZPXsj5549n5co0atWqyIgRfejZs3nUYYmISAJTEi8E33+/jFNOGQXAccc1YuTIM6hXLzniqEREJNEpiReCww+vy+DBbWnSpDo339yZpCQNRRARkX2nJB4nr776A61b78dhh9UB4LnnTsVMN24REZGCoyZhAdu0aRsXXjiBc84ZR//+Y0lPzwBQAhcRkQKnlngBmjFjOf37j2X+/DWUL1+aa689inLlkqIOS0REiikl8QLg7jz++DfceOP7bNu2g1atajNmzJm0arVf1KGJiEgxpiReAM499w1effUHAIYObc+DD55MhQplIo5KRESKO50TLwAnndSEatXKM3bsWTz1VC8lcBERKRRqie+FjIxMZsxYTocOwZPGzj+/DT16NKN27UoRRyYiIiWJWuJ7aOnSDRx33Escc8yL/PjjSiAYea4ELiIihU0t8T0wfvw8Bg+ewLp16dStW5n169OjDklEREowJfEYpKdncMMNk3nyyWkA9OzZjBdf7KPWt4iIREpJPB/z56/m7LPHMmvWCsqUKcV9953INdccqZu3iJQA27dvJzU1lfR09bpJ4ShfvjwNGjSgTJnYBkgriefDHRYuXEuzZjVISTmTdu3qRh2SiBSS1NRUkpOTadSokb64S9y5O2vWrCE1NZXGjRvHtI6SeC7S0rZRsWIZzIxDDqnFO+8MpF27uiQnl4s6NBEpROnp6UrgUmjMjJo1a7Jq1aqY19Ho9By++iqV1q2f4sUXZ2TN69KlkRK4SAmlBC6FaU/fb0riocxM5957P+eYY15k8eL1jBgxA3ePOiwREZHdimsSN7NTzGy+mS00s5tzWW5m9mi4fJaZtYtnPLuzfPkmTj55JDff/CEZGZlcf/1RvP/+efoGLiKRS0pKom3btrRu3ZrevXuzfv36rGU//vgj3bp1o3nz5jRr1oy77rprl8bHu+++S4cOHWjRogWHHHIIN954YwRHkLfvv/+eiy++eJd5ffr0oVOnTrvMu+CCCxg7duwu8ypXrpz194IFC+jRowdNmzalRYsWnH322axYsWKfYnvttddo1aoVpUqVYtq0abstN2nSJA4++GCaNm3KsGHDsuavXbuWE088kWbNmnHiiSeybt06AH744QcuuOCCfYptp7glcTNLAp4AugMtgQFm1jJHse5As/BnCPBUvOLZnUnzmnLYYU/xwQe/UKtWRd5+eyD/+c/JlCun4QIiEr0KFSowY8YMZs+eTY0aNXjiiScA2LJlC6eeeio333wzCxYsYObMmUydOpUnn3wSgNmzZ3PllVcycuRI5s6dy+zZs2nSpEmBxpaRkbHP27jnnnu46qqrsqbXr1/Pd999x/r161m0aFFM20hPT6dnz55cdtllLFy4kLlz53LZZZft0bnl3LRu3Zpx48Zx7LHH7rbMjh07uOKKK3j33XeZM2cOo0ePZs6cOQAMGzaM448/np9++onjjz8+K8EfeuihpKamsmTJkn2KD+I7sO0IYKG7/wJgZilAH2BOtjJ9gJc9+Or4lZlVM7O67r4sjnFl2ZFp/PXtE1m1ajPdujXmlVdOp1695MLYtYgkmv/EqWfuhthP23Xq1IlZs2YB8Oqrr/KXv/yFk046CYCKFSvy+OOP07VrV6644gruu+8+brnlFg455BAASpcuzeWXX/6nbW7atImrrrqKadOmYWbccccd9O3bl8qVK7Np0yYAxo4dy1tvvcWIESO44IILqFGjBt9//z1t27bljTfeYMaMGVSrVg2Apk2b8sUXX1CqVCmGDh2alagefvhh/vKXv+yy740bNzJr1izatGmTNe/111+nd+/e1KlTh5SUFP7+97/nWy+vvvoqnTp1onfv3lnzjjvuuFirdbdatGiRb5lvvvmGpk2bZn1B6t+/PxMmTKBly5ZMmDCBjz/+GIBBgwbRtWtX7r33XgB69+5NSkoKf/3rX/cpxngm8frA0mzTqcCRMZSpD+ySxM1sCEFLnYYNGxZYgEmlnNHnjOXNmuO46aajSUrSEAERKZp27NjBhx9+yEUXXQQEXent27ffpcxBBx3Epk2b+OOPP5g9ezY33HBDvtu96667qFq1Kj/8EDyJcWeXb14WLFjABx98QFJSEpmZmbzxxhtceOGFfP311zRq1Ig6deowcOBArrvuOjp37sySJUs4+eSTmTt37i7bmTZtGq1bt95l3ujRo7njjjuoU6cOZ555ZkxJfPbs2X+qi9xs3LiRY445Jtdlr776Ki1b5uwszt9vv/3GAQcckDXdoEEDvv76awBWrFhB3brBZcl169Zl5cqVWeU6dOjAsGHDinQSz+1ra86vnLGUwd2HA8MBOnToUHCjzW5wWgGtCmyDIlJs7UGLuSBt2bKFtm3bsnjxYtq3b8+JJ54IBNcU727czp6M5/nggw9ISUnJmq5evXq+65x11lkkJSUB0K9fP/7v//6PCy+8kJSUFPr165e13Z3dygB//PEHGzduJDn5f72dy5Yto3bt2lnTK1asYOHChXTu3Bkzo3Tp0syePZvWrVvnekx7Om4pOTmZGTNm7NE6+cltAHQsce233378/vvv+7z/eDY9U4EDsk03AHJGHEsZEZESa+c58V9//ZVt27ZlnRNv1arVnwZb/fLLL1SuXJnk5GRatWrF9OnT893+7r4MZJ+X8451lSr975bTnTp1YuHChaxatYrx48dzxhlnAJCZmcmXX37JjBkzmDFjBr/99tsuCXznsWXf9pgxY1i3bh2NGzemUaNGLF68OOsLRs2aNXfpJVi7di21atXKqotYjnXjxo20bds215/sXzj2RIMGDVi69H8dyqmpqdSrFzzhsk6dOixbFnQsL1u2jP322y+rXHp6OhUqVNirfWYXzyT+LdDMzBqbWVmgPzAxR5mJwPnhKPWjgA2FdT5cRCSRVK1alUcffZQHHniA7du3c8455/D555/zwQcfAEGL/eqrr87qnr3pppu45557WLBgARAk1QcffPBP2z3ppJN4/PHHs6Z3Jso6deowd+7crO7y3TEzTj/9dK6//npatGhBzZo1c91ubi3gFi1asHDhwqzp0aNHM2nSJBYvXszixYuZPn16VhLv2rUrY8aMYdu2bQCMGDEi67z3wIEDmTp1Km+//XbWtiZNmpR1imCnnS3x3H72pisdoGPHjvz0008sWrSIbdu2kZKSwqmnngrAqaeeyksvvQTASy+9RJ8+fbLWW7BgwZ9OJewVd4/bD9ADWAD8DNwSzhsKDA3/NoIR7D8DPwAd8ttm+/btXUSkMMyZMyfqELxSpUq7TPfq1ctffvlld3efNWuWd+nSxZs3b+4HHXSQ33nnnZ6ZmZlV9s033/R27dr5IYcc4i1atPAbb7zxT9vfuHGjn3/++d6qVSs/7LDD/PXXX3d399dee82bNGniXbp08SuuuMIHDRrk7u6DBg3y1157bZdtfPvttw74iBEjsuatWrXKzz77bD/00EO9RYsWfumll+Z6fK1bt/Y//vjDFy1a5PXq1dslfnf3ww8/3L/66it3d7/zzju9devW3qZNGz/jjDN85cqVWeXmzp3rJ598sjdt2tRbtGjh/fr18+XLl+dZt/kZN26c169f38uWLev77befn3TSSe7u/ttvv3n37t2zyr399tverFkzb9Kkid99991Z81evXu3dunXzpk2berdu3XzNmjVZy6644gqfOHFirvvN7X0HTPNccqJ5gt3QpEOHDp7X9XoiIgVl7ty5MY1Qlr330EMPkZyc/KdrxYuzrVu30qVLFz7//HNKl/7z0LTc3ndmNt3dO+Qsq+HYIiISmcsuu4xy5UrWba2XLFnCsGHDck3ge0p3NBERkciUL1+e8847L+owClWzZs1o1qxZgWxLLXERkTwk2ilHSWx7+n5TEhcR2Y3y5cuzZs0aJXIpFB4+T7x8+fIxr6PudBGR3WjQoAGpqan7fA9ukViVL1+eBg0axFxeSVxEZDfKlClD48aNow5DZLfUnS4iIpKglMRFREQSlJK4iIhIgkq4O7aZ2Srg1wLcZC1gdQFur6RSPe471eG+Ux3uO9XhvotHHR7o7rVzzky4JF7QzGxabreykz2jetx3qsN9pzrcd6rDfVeYdajudBERkQSlJC4iIpKglMRheNQBFBOqx32nOtx3qsN9pzrcd4VWhyX+nLiIiEiiUktcREQkQZWYJG5mp5jZfDNbaGY357LczOzRcPksM2sXRZxFWQx1eE5Yd7PMbKqZtYkizqIsvzrMVq6jme0wszMLM75EEUs9mllXM5thZj+a2SeFHWNRF8PnuaqZvWlmM8M6vDCKOIsqM3vBzFaa2ezdLC+cnOLuxf4HSAJ+BpoAZYGZQMscZXoA7wIGHAV8HXXcReknxjo8Gqge/t1ddbjndZit3EfAO8CZUcdd1H5ifC9WA+YADcPp/aKOuyj9xFiH/wDuDf+uDawFykYde1H5AY4F2gGzd7O8UHJKSWmJHwEsdPdf3H0bkAL0yVGmD/CyB74CqplZ3cIOtAjLtw7dfaq7rwsnvwJifxRPyRDL+xDgKuB1YGVhBpdAYqnHgcA4d18C4O6qy13FUocOJJuZAZUJknhG4YZZdLn7pwR1sjuFklNKShKvDyzNNp0aztvTMiXZntbPRQTfQuV/8q1DM6sPnA48XYhxJZpY3ovNgepm9rGZTTez8wstusQQSx0+DrQAfgd+AK5x98zCCa9YKJScUlIeRWq5zMs5LD+WMiVZzPVjZscRJPHOcY0o8cRShw8Df3P3HUEDSHIRSz2WBtoDxwMVgC/N7Ct3XxDv4BJELHV4MjAD6AYcBLxvZp+5+x9xjq24KJScUlKSeCpwQLbpBgTfLve0TEkWU/2Y2WHAc0B3d19TSLEliljqsAOQEibwWkAPM8tw9/GFEmFiiPXzvNrd04A0M/sUaAMoiQdiqcMLgWEenOBdaGaLgEOAbwonxIRXKDmlpHSnfws0M7PGZlYW6A9MzFFmInB+OKLwKGCDuy8r7ECLsHzr0MwaAuOA89TiyVW+dejujd29kbs3AsYClyuB/0ksn+cJwDFmVtrMKgJHAnMLOc6iLJY6XELQk4GZ1QEOBn4p1CgTW6HklBLREnf3DDO7EphMMCrzBXf/0cyGhsufJhgJ3ANYCGwm+BYqoRjr8HagJvBk2JLMcD1IIUuMdSj5iKUe3X2umU0CZgGZwHPunuulQCVRjO/Fu4ARZvYDQdfw39xdTzcLmdlooCtQy8xSgTuAMlC4OUV3bBMREUlQJaU7XUREpNhREhcREUlQSuIiIiIJSklcREQkQSmJi4iIJCglcZEIhE8om5Htp1EeZTcVwP5GmNmicF/fmVmnvdjGc2bWMvz7HzmWTd3XGMPt7KyX2eETtKrlU76tmfUoiH2LJCJdYiYSATPb5O6VC7psHtsYAbzl7mPN7CTgAXc/bB+2t88x5bddM3sJWODu/8qj/AVAB3e/sqBjEUkEaomLFAFmVtnMPgxbyT+Y2Z+ebmZmdc3s02wt1WPC+SeZ2Zfhuq+ZWX7J9VOgabju9eG2ZpvZteG8Smb2dvgc6dlm1i+c/7GZdTCzYUCFMI5R4bJN4e8x2VvGYQ9AXzNLMrP7zexbC56tfGkM1fIl4QMjzOwIC55R/334++DwTmP/B/QLY+kXxv5CuJ/vc6tHkeKkRNyxTaQIqmBmM8K/FwFnAae7+x9mVgv4yswm+q5dZQOBye7+LzNLAiqGZW8FTnD3NDP7G3A9QXLbnd7AD2bWnuAuUkcS3JHrazP7hOAZ07+7e08AM6uafWV3v9nMrnT3trlsOwXoB7wTJtnjgcsIHoizwd07mlk54Asze8/dF+UWYHh8xwPPh7PmAceGdxo7AbjH3fua2e1ka4mb2T3AR+4+OOyK/8bMPgjvoS5S7CiJi0RjS/YkaGZlgHvM7FiC24TWB+oAy7Ot8y3wQlh2vLvPMLMuQEuCpAhQlqAFm5v7zexWYBVBUj0eeGNngjOzccAxwCTgATO7l6AL/rM9OK53gUfDRH0K8Km7bwm78A8zszPDclWBZgRfYLLb+eWmETAdeD9b+ZfMrBnBk6DK7Gb/JwGnmtmN4XR5oCG6b7oUU0riIkXDOUBtoL27bzezxQQJKIu7fxom+Z7AK2Z2P7AOeN/dB8Swj5vcfezOibBF+yfuviBspfcA/h22mPNq2WdfN93MPiZ4jGU/YPTO3QFXufvkfDaxxd3bhq3/t4ArgEcJ7uM9xd1PDwcBfryb9Q3o6+7zY4lXJNHpnLhI0VAVWBkm8OOAA3MWMLMDwzLPEnQztwO+Av5iZjvPcVc0s+Yx7vNT4LRwnUrA6cBnZlYP2OzuI4EHwv3ktD3sEchNCkE3/TEED9gg/H3ZznXMrHm4z1y5+wbgauDGcJ2qwG/h4guyFd0IJGebngxcZWG3hJkdvrt9iBQHSuIiRcMooIOZTSNolc/LpUxXYIaZfQ/0BR5x91UESW20mc0iSOqHxLJDd/8OGEHwfOivCZ709T1wKMG55BnALcDduaw+HJi1c2BbDu8BxwIfuPu2cN5zwBzgOzObDTxDPj2BYSwzCR6TeR9Br8AXBE/d2mkK0HLnwDaCFnuZMLbZ4bRIsaVLzERERBKUWuIiIiIJSklcREQkQSmJi4iIJCglcRERkQSlJC4iIpKglMRFREQSlJK4iIhIglISFxERSVD/D8Ggk1o7IgkrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m y_test[dataset_i]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate the Model on TS set\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtest(\n\u001b[0;32m      8\u001b[0m     x_test\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m      9\u001b[0m     y_test\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Computes the score of the Model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m nn[dataset_i]\u001b[38;5;241m.\u001b[39mscore(x_test\u001b[38;5;241m=\u001b[39mX, y_test\u001b[38;5;241m=\u001b[39my)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Final testing of the Models for each Test set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_test[dataset_i].values\n",
    "    y = y_test[dataset_i].values\n",
    "\n",
    "    # Evaluate the Model on TS set\n",
    "    nn[dataset_i].test(\n",
    "        x_test=X,\n",
    "        y_test=y\n",
    "    )\n",
    "\n",
    "    # Computes the score of the Model\n",
    "    nn[dataset_i].score(x_test=X, y_test=y)\n",
    "\n",
    "    # Prints the results obtained\n",
    "    print(nn[dataset_i])\n",
    "    nn[dataset_i].print_confusion_matrix(y_test=y)\n",
    "    nn[dataset_i].print_roc_curve(y_test=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
