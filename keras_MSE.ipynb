{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       1     1     1     1     1     3     1   data_5\n",
      "NaN       1     1     1     1     1     3     2   data_6\n",
      "NaN       1     1     1     1     3     2     1  data_19\n",
      "NaN       1     1     1     1     3     3     2  data_22\n",
      "NaN       1     1     1     2     1     2     1  data_27\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       0     1     1     1     1     2     2   data_4\n",
      "NaN       0     1     1     1     1     4     1   data_7\n",
      "NaN       0     1     1     1     2     1     1   data_9\n",
      "NaN       0     1     1     1     2     1     2  data_10\n",
      "NaN       0     1     1     1     2     2     1  data_11\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       0     1     1     1     1     1     1  data_1\n",
      "NaN       0     1     1     1     1     1     2  data_2\n",
      "NaN       0     1     1     1     1     2     1  data_3\n",
      "NaN       0     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "NaN       0     1     1     1     1     4     1  data_7\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n"
     ]
    }
   ],
   "source": [
    "from api.data_handler import DataHandler\n",
    "\n",
    "# Creation of a DataHandler Object\n",
    "data_handler = DataHandler(['target', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'id'])\n",
    "\n",
    "# Number of different Datasets\n",
    "datasets_number = 3\n",
    "\n",
    "# Lists of DataFrames\n",
    "df_train : list[pd.DataFrame] = []\n",
    "df_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Load the Training/Test sets into pandas DataFrames\n",
    "for i in range(datasets_number):\n",
    "    df_train.append(data_handler.load_data(f'data/monks/monks-{i+1}.train'))\n",
    "    df_test.append(data_handler.load_data(f'data/monks/monks-{i+1}.test'))\n",
    "\n",
    "    # Print the head of the loaded data\n",
    "    print(df_train[i].head())\n",
    "    print(df_test[i].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data\n",
    "x_train : list[pd.DataFrame] = []\n",
    "y_train : list[pd.DataFrame] = []\n",
    "x_test  : list[pd.DataFrame] = []\n",
    "y_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Split data into TR set and TS set\n",
    "for i in range(datasets_number):\n",
    "\n",
    "    # Saving the splitted TR set data into the lists\n",
    "    x, y = data_handler.split_data(data=df_train[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "\n",
    "    # Saving the splitted TS set data into the lists\n",
    "    x, y = data_handler.split_data(df_test[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monk 1 [TRAIN]: (124, 17)\n",
      "Monk 1 [TEST]: (432, 17)\n",
      "Monk 2 [TRAIN]: (169, 17)\n",
      "Monk 2 [TEST]: (432, 17)\n",
      "Monk 3 [TRAIN]: (122, 17)\n",
      "Monk 3 [TEST]: (432, 17)\n"
     ]
    }
   ],
   "source": [
    "# Applies the 1-Hot Encoding to the \"x\" data\n",
    "for i in range(datasets_number):\n",
    "    x_train[i] = data_handler.one_hot_encoding(x_train[i])\n",
    "    x_test[i]  = data_handler.one_hot_encoding(x_test[i])\n",
    "\n",
    "    # Print of the data modified\n",
    "    print(f\"Monk {i+1} [TRAIN]: \" + str(x_train[i].shape))\n",
    "    print(f\"Monk {i+1} [TEST]: \" + str(x_test[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters' space for Grid Search (1 for each Dataset)\n",
    "param_space = {\n",
    "    0: {\n",
    "        'hidden_units': [3, 4],\n",
    "        'patience': [15, 30],\n",
    "        'learning_rate': [0.3, 0.4],\n",
    "        'batch_size': [4, 6],\n",
    "        'nesterov': [\"T\", \"F\"],\n",
    "        'epochs': [350, 450],\n",
    "        'momentum': [0.6, 0.7]\n",
    "    },\n",
    "    1: {\n",
    "        'hidden_units': [3, 4, 5],\n",
    "        'patience': [15, 30],\n",
    "        'factor_lr_dec': [0.5, 1],\n",
    "        'step_decay': [500, 1000, 1500],\n",
    "        'learning_rate': [0.9, 0.8, 0.7],\n",
    "        'batch_size': [10, 30, 60], \n",
    "        'epochs': [180, 250, 350],\n",
    "        'momentum': [0.6, 0.7, 0.8],\n",
    "        'nesterov': [\"T\", \"F\"],\n",
    "    },\n",
    "    2: {\n",
    "        'hidden_units': [2, 3],\n",
    "        'patience': [10,15,30],\n",
    "        'factor_lr_dec': [0.5, 1],\n",
    "        'step_decay': [500, 1000, 1500],\n",
    "        'learning_rate': [float(i/100) for i in range(1,10)],\n",
    "        'batch_size': [7, 8, 9, 32, 64],\n",
    "        'epochs': [int(350+epochs) for epochs in range(0,50,10)],\n",
    "        'weight_decay': [float(i/1000) for i in range(1,10)],\n",
    "        'momentum': [float(i/1000) for i in range(10,90,5)] + [float(i/100) for i in range(10,90,5)],\n",
    "        'nesterov': [\"T\", \"F\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyperparameters Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.014514806479564869\n",
      " Mean Validation Loss:              0.042414913966786115\n",
      " Mean Training Accuracy:            0.9819191932678223\n",
      " Mean Validation Accuracy:          0.9426666617393493\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.014514806479564869\n",
      " Mean Validation Loss:              0.042414913966786115\n",
      " Mean Training Accuracy:            0.9819191932678223\n",
      " Mean Validation Accuracy:          0.9426666617393493\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m nn_i\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39mn_hidden_layers_list[dataset_i])\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mnn_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_val\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m nn_i\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     50\u001b[0m     x_train\u001b[38;5;241m=\u001b[39mx_kfold_train,\n\u001b[0;32m     51\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my_kfold_train,\n\u001b[0;32m     52\u001b[0m     x_val\u001b[38;5;241m=\u001b[39mx_kfold_val,\n\u001b[0;32m     53\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_kfold_val\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\corra\\Documents\\GitHub\\Machine_Learning_Project\\api\\binary_nn.py:276\u001b[0m, in \u001b[0;36mBinaryNN.fit\u001b[1;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Training of the model with TR set and VL set (already splitted)\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Error case\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1855\u001b[0m     )\n\u001b[1;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1871\u001b[0m }\n\u001b[0;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:2285\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautotune_steps_per_execution:\n\u001b[0;32m   2284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m-> 2285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m   2286\u001b[0m     _,\n\u001b[0;32m   2287\u001b[0m     dataset_or_iterator,\n\u001b[0;32m   2288\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1341\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:500\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:706\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    702\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 706\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:745\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    742\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    743\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    744\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 745\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3421\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3420\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3421\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3422\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3424\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from api.binary_nn import BinaryNN\n",
    "\n",
    "# Creation of a BinaryNN objct for each dataset\n",
    "nn: list[BinaryNN] = []\n",
    "\n",
    "# Different values per dataset\n",
    "trials_list = [40, 30, 50]\n",
    "k_values = [5, 5, 5]\n",
    "n_hidden_layers_list = [1, 1, 1]\n",
    "\n",
    "# Search of the best Hyperparameters to each Training set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_train[dataset_i].values\n",
    "    y = y_train[dataset_i].values\n",
    "    k = k_values[dataset_i]\n",
    "\n",
    "    # K-fold Cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Computes and Stores all the parameters combinations\n",
    "    data_handler.set_params_combinations(params=param_space[dataset_i])\n",
    "\n",
    "    params_combinations = data_handler.get_params_combinations()\n",
    "\n",
    "    # For each iteration we choose the hyperparameters and we use them with K-fold CV\n",
    "    for trial, params in enumerate(params_combinations):\n",
    "\n",
    "        # Creation of the Neural Network object\n",
    "        nn_i = BinaryNN(params=params, monk_i=dataset_i+1, trial=trial+1)\n",
    "\n",
    "        # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "        for train_index, val_index in kfold.split(X, y):\n",
    "            x_kfold_train, x_kfold_val = X[train_index], X[val_index]\n",
    "            y_kfold_train, y_kfold_val = y[train_index], y[val_index]\n",
    "\n",
    "            # Building the model\n",
    "            nn_i.create_model(n_hidden_layers=n_hidden_layers_list[dataset_i])\n",
    "\n",
    "            # Training the model\n",
    "            nn_i.fit(\n",
    "                x_train=x_kfold_train,\n",
    "                y_train=y_kfold_train,\n",
    "                x_val=x_kfold_val,\n",
    "                y_val=y_kfold_val\n",
    "            )\n",
    "\n",
    "            # Evaluating the model\n",
    "            nn_i.evaluate(\n",
    "                x_train=x_kfold_train,\n",
    "                y_train=y_kfold_train,\n",
    "                x_val=x_kfold_val,\n",
    "                y_val=y_kfold_val\n",
    "            )\n",
    "\n",
    "        # Case of first append\n",
    "        if len(nn) == dataset_i:\n",
    "            nn.append(nn_i)\n",
    "\n",
    "        # Print the results of this trial\n",
    "        print(\"------------------ Current Hyperparameters ------------------\")\n",
    "        nn_i.print_training_info()\n",
    "        print(\"-------------------- Best Hyperparameters -------------------\")\n",
    "        nn[dataset_i].print_training_info()\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # Update best hyperparameters if: no high overfitting AND (higher mean VL accuracy OR (equal mean AND\n",
    "        if nn_i.mean_tr_accuracy-0.1 <= nn_i.mean_vl_accuracy \\\n",
    "            and (\n",
    "                    nn[dataset_i].mean_vl_accuracy < nn_i.mean_vl_accuracy \\\n",
    "                or (\n",
    "                    nn[dataset_i].mean_vl_accuracy == nn_i.mean_vl_accuracy and nn[dataset_i].mean_tr_accuracy < nn_i.mean_tr_accuracy\n",
    "                    )\n",
    "            ):\n",
    "            nn[dataset_i] = nn_i\n",
    "\n",
    "        # Case of TR/VL AND TR/VL loss minor\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy >= 0.98 \\\n",
    "            and nn_i.mean_tr_accuracy == nn[dataset_i].mean_tr_accuracy \\\n",
    "            and nn_i.mean_vl_accuracy == nn[dataset_i].mean_vl_accuracy \\\n",
    "            and abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < 0.02 \\\n",
    "            and nn_i.mean_vl_loss < nn[dataset_i].mean_vl_loss \\\n",
    "            and nn_i.mean_tr_loss < nn[dataset_i].mean_tr_loss:\n",
    "            nn[dataset_i] = nn_i\n",
    "\n",
    "        # Exit case\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy == 1 \\\n",
    "            and nn_i.mean_vl_loss < 0.1 and nn_i.mean_tr_loss < 0.1 \\\n",
    "            and abs(nn_i.mean_vl_loss - nn_i.mean_tr_loss) < 0.01:\n",
    "            nn[dataset_i] = nn_i\n",
    "            break\n",
    "\n",
    "    # Print output\n",
    "    print(f\"### Best Hyperparameters of Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print of best Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Best Hyperparameters for Monk 1 ###\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.014514806479564869\n",
      " Mean Validation Loss:              0.042414913966786115\n",
      " Mean Training Accuracy:            0.9819191932678223\n",
      " Mean Validation Accuracy:          0.9426666617393493\n",
      "\n",
      "### Best Hyperparameters for Monk 2 ###\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(datasets_number):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Print best hyperparameters\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Best Hyperparameters for Monk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mprint_training_info()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# BEST L CURVE M1: >(semismoothed)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1500, 'learning_rate': 0.999, 'batch_size': 17, 'epochs': 350, 'weight_init': 'glorot_normal', 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#  Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.5, 'batch_size': 32, 'epochs': 370, 'weight_init': 'lecun_normal', 'momentum': 0.8, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m    \u001b[38;5;66;03m# BEST SMOOTHER PT2 MONK2:  {'hidden_units': 4, 'patience': 10, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 450, 'momentum': 0.3, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03mBest Hyperparameters for Monk 2\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m Monk:                     2\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m '''\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Iteration on all the Datasets\n",
    "for dataset_i in range(datasets_number):\n",
    "\n",
    "    # Print best hyperparameters\n",
    "    print(f\"\\n### Best Hyperparameters for Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "   \n",
    " \n",
    "    # BEST L CURVE M1: >(semismoothed)\n",
    "    # Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1500, 'learning_rate': 0.999, 'batch_size': 17, 'epochs': 350, 'weight_init': 'glorot_normal', 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    #  Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.5, 'batch_size': 32, 'epochs': 370, 'weight_init': 'lecun_normal', 'momentum': 0.8, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    # Hyp:  {'input_units': 17, 'hidden_units': 5, 'patience': 200, 'factor_lr_dec': 0.5, 'step_decay': 500, 'learning_rate': 0.99, 'batch_size': 16, 'epochs': 530, 'weight_init': 'lecun_normal', 'momentum': 0.5, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    \n",
    "    # BEST SMOOTHED CURVE MONK1:   HyperparameterS: {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 440, 'momentum': 0.6}\n",
    "                                                     #Hyperparameters:          {'input_units': 17, 'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'F', 'epochs': 440, 'momentum': 0.7, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "\n",
    "   # BEST SMOOTHER PT2 MONK2:  {'hidden_units': 4, 'patience': 10, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 450, 'momentum': 0.3, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "\n",
    "'''\n",
    "Best Hyperparameters for Monk 2\n",
    " Monk:                     2\n",
    " Trial:                    3\n",
    " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 200, 'factor_lr_dec': 1.0, 'step_decay': 500, 'learning_rate': 0.999, 'batch_size': 60, 'epochs': 290, 'momentum': 0.75, 'nesterov': 'T', 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    " Mean Training Loss:       0.0006283932307269424\n",
    " Mean Validation Loss:     0.004200904699973762\n",
    " Mean Training Accuracy:   1.0\n",
    " Mean Validation Accuracy: 1.0\n",
    "\n",
    "### Best Hyperparameters for Monk 3 ###\n",
    " Monk:                     3\n",
    " Trial:                    14\n",
    " Hyperparameters:          {'input_units': 17, 'hidden_units': 2, 'patience': 30, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.07, 'batch_size': 7, 'epochs': 370, 'weight_decay': 0.002, 'momentum': 0.08, 'nesterov': 'T', 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    " Mean Training Loss:       0.059438984096050265\n",
    " Mean Validation Loss:     0.07536792308092118\n",
    " Mean Training Accuracy:   0.9508310675621032\n",
    " Mean Validation Accuracy: 0.934333324432373\n",
    "\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining: Mean, Standard Deviation and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Monk 1 ###\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.16719716787338257\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.7983871102333069\n",
      " Mean Validation Accuracy:          0\n",
      " Monk:                              1\n",
      " Trial:                             2\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.22415238618850708\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.6290322542190552\n",
      " Mean Validation Accuracy:          0\n",
      " Monk:                              1\n",
      " Trial:                             3\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.21877817809581757\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.7096773982048035\n",
      " Mean Validation Accuracy:          0\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.16832686960697174\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.8225806355476379\n",
      " Mean Validation Accuracy:          0\n",
      " Monk:                              1\n",
      " Trial:                             5\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.1676415205001831\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.8064516186714172\n",
      " Mean Validation Accuracy:          0\n",
      "\n",
      "Mean TR MSE: 0.1892192244529724\n",
      "\n",
      "Mean VL MSE: 0.0\n",
      "\n",
      "Mean TR Accuracy: 0.7532258033752441\n",
      "\n",
      "Mean VL Accuracy: 0.0\n",
      "\n",
      "Variance TR MSE: 0.0006962232608361951\n",
      "\n",
      "Variance VL MSE: 0.0\n",
      "\n",
      "Variance TR Accuracy: 0.005400625008326188\n",
      "\n",
      "Variance VL Accuracy: 0.0\n",
      "Standard Deviation TR MSE: 0.026386042917349223\n",
      "\n",
      "Standard Deviation VL MSE: 0.0\n",
      "Standard Deviation TR Accuracy: 0.07348894480346134\n",
      "Standard Deviation VL Accuracy: 0.0\n",
      "\n",
      "### Monk 2 ###\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Inner loop for different initializations\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_initializations):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Create a new model instance with the best hyperparameters for the current monk\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     nn_instance \u001b[38;5;241m=\u001b[39m BinaryNN(params\u001b[38;5;241m=\u001b[39m\u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mparams, monk_i\u001b[38;5;241m=\u001b[39mdataset_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, trial\u001b[38;5;241m=\u001b[39m_\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m     nn_instance\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39mn_hidden_layers_list[dataset_i])\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Training the model\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of initializations\n",
    "num_initializations = 5\n",
    "\n",
    "# Iterate over each monk (dataset)\n",
    "for dataset_i in range(datasets_number):\n",
    "    print(f\"\\n### Monk {dataset_i + 1} ###\")\n",
    "\n",
    "    # Extract dataset for the current monk\n",
    "    x = x_train[dataset_i].values\n",
    "    y_fit = y_train[dataset_i].values\n",
    "    X = x_test[dataset_i].values\n",
    "    y = y_test[dataset_i].values\n",
    "\n",
    "    tr_mse_values = []  # List to store MSE TR values for each initialization\n",
    "    vl_mse_values = []  # List to store MSE VL values for each initialization\n",
    "    vl_acc_values = []   # List to store Accuracies values for each initialization\n",
    "    tr_acc_values = []   # List to store Accuracies values for each initialization\n",
    "\n",
    "    # Inner loop for different initializations\n",
    "    for _ in range(num_initializations):\n",
    "        # Create a new model instance with the best hyperparameters for the current monk\n",
    "        nn_instance = BinaryNN(params=nn[dataset_i].params, monk_i=dataset_i+1, trial=_+1)\n",
    "        nn_instance.create_model(n_hidden_layers=n_hidden_layers_list[dataset_i])\n",
    "\n",
    "\n",
    "        # Training the model\n",
    "        nn_instance.fit(x_train=x,\n",
    "               y_train=y_fit\n",
    "                        )\n",
    "\n",
    "        # Evaluating the model\n",
    "        nn_instance.evaluate(\n",
    "                x_train=x,\n",
    "                y_train=y_fit\n",
    "                )\n",
    "       \n",
    "        # Access the training loss from the nn_instance and store it\n",
    "        tr_mse_values.append(nn_instance.mean_tr_loss)\n",
    "        vl_mse_values.append(nn_instance.mean_vl_loss)\n",
    "        tr_acc_values.append(nn_instance.mean_tr_accuracy)\n",
    "        vl_acc_values.append(nn_instance.mean_vl_accuracy)\n",
    "\n",
    "        nn_instance.print_training_info()\n",
    "\n",
    "\n",
    "    # Calculate and print mean, variance and standard deviation\n",
    "    \n",
    "    # Mean TR mse\n",
    "    meantr_mse = np.mean(tr_mse_values)\n",
    "    # Mean VL mse\n",
    "    meanvl_mse = np.mean(vl_mse_values)\n",
    "    \n",
    "    # Mean TR accuracies\n",
    "    meantr_acc = np.mean(tr_acc_values)\n",
    "    # Mean VL accuracies\n",
    "    meanvl_acc = np.mean(vl_acc_values)\n",
    "\n",
    "    # Variance MSE VL\n",
    "    variance_mse_vl = np.var(vl_mse_values)\n",
    "    # Variance MSE TR\n",
    "    variance_mse_tr = np.var(tr_mse_values)\n",
    "\n",
    "    # Variance TR accuracies\n",
    "    variancetr_acc = np.var(tr_acc_values)\n",
    "    # Variance VL accuracies\n",
    "    variancevl_acc = np.var(vl_acc_values)\n",
    "\n",
    "    # Standard dev TR accuracies\n",
    "    std_tr_acc = np.std(tr_acc_values)\n",
    "    # Standard dev VL accuracies\n",
    "    std_vl_acc = np.std(vl_acc_values)\n",
    "    \n",
    "    # Standard dev VL mse\n",
    "    std_deviation_vl = np.std(vl_mse_values)\n",
    "    # Standard dev TR mse\n",
    "    std_deviation_tr = np.std(tr_mse_values)\n",
    "\n",
    "    print(f'\\nMean TR MSE: {meantr_mse}')\n",
    "    print(f'\\nMean VL MSE: {meanvl_mse}')\n",
    "    print(f'\\nMean TR Accuracy: {meantr_acc}')\n",
    "    print(f'\\nMean VL Accuracy: {meanvl_acc}')\n",
    "    print(f'\\nVariance TR MSE: {variance_mse_tr}')\n",
    "    print(f'\\nVariance VL MSE: {variance_mse_vl}')\n",
    "    print(f'\\nVariance TR Accuracy: {variancetr_acc}')\n",
    "    print(f'\\nVariance VL Accuracy: {variancevl_acc}')\n",
    "    print(f'Standard Deviation TR MSE: {std_deviation_tr}')\n",
    "    print(f'\\nStandard Deviation VL MSE: {std_deviation_vl}')\n",
    "    print(f'Standard Deviation TR Accuracy: {std_tr_acc}')\n",
    "    print(f'Standard Deviation VL Accuracy: {std_vl_acc}')\n",
    "\n",
    "    # Plot learning curves\n",
    "    nn_instance.print_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final testing of the Models for each Test set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_test[dataset_i].values\n",
    "    y = y_test[dataset_i].values\n",
    "\n",
    "    # Evaluate the Model on TS set\n",
    "    nn[dataset_i].test(\n",
    "        x_test=X,\n",
    "        y_test=y\n",
    "    )\n",
    "\n",
    "    # Computes the score of the Model\n",
    "    nn[dataset_i].score(x_test=X, y_test=y)\n",
    "\n",
    "    # Prints the results obtained\n",
    "    print(nn[dataset_i])\n",
    "    nn[dataset_i].print_confusion_matrix(y_test=y)\n",
    "    nn[dataset_i].print_roc_curve(y_test=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
