{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       1     1     1     1     1     3     1   data_5\n",
      "NaN       1     1     1     1     1     3     2   data_6\n",
      "NaN       1     1     1     1     3     2     1  data_19\n",
      "NaN       1     1     1     1     3     3     2  data_22\n",
      "NaN       1     1     1     2     1     2     1  data_27\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       0     1     1     1     1     2     2   data_4\n",
      "NaN       0     1     1     1     1     4     1   data_7\n",
      "NaN       0     1     1     1     2     1     1   data_9\n",
      "NaN       0     1     1     1     2     1     2  data_10\n",
      "NaN       0     1     1     1     2     2     1  data_11\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       0     1     1     1     1     1     1  data_1\n",
      "NaN       0     1     1     1     1     1     2  data_2\n",
      "NaN       0     1     1     1     1     2     1  data_3\n",
      "NaN       0     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "NaN       0     1     1     1     1     4     1  data_7\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n"
     ]
    }
   ],
   "source": [
    "from api.data_handler import DataHandler\n",
    "\n",
    "# Creation of a DataHandler Object\n",
    "data_handler = DataHandler(['target', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'id'])\n",
    "\n",
    "# Number of different Datasets\n",
    "datasets_number = 3\n",
    "\n",
    "# Lists of DataFrames\n",
    "df_train : list[pd.DataFrame] = []\n",
    "df_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Load the Training/Test sets into pandas DataFrames\n",
    "for i in range(datasets_number):\n",
    "    df_train.append(data_handler.load_data(f'data/monks/monks-{i+1}.train'))\n",
    "    df_test.append(data_handler.load_data(f'data/monks/monks-{i+1}.test'))\n",
    "\n",
    "    # Print the head of the loaded data\n",
    "    print(df_train[i].head())\n",
    "    print(df_test[i].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data\n",
    "x_train : list[pd.DataFrame] = []\n",
    "y_train : list[pd.DataFrame] = []\n",
    "x_test  : list[pd.DataFrame] = []\n",
    "y_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Split data into TR set and TS set\n",
    "for i in range(datasets_number):\n",
    "\n",
    "    # Saving the splitted TR set data into the lists\n",
    "    x, y = data_handler.split_data(data=df_train[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "\n",
    "    # Saving the splitted TS set data into the lists\n",
    "    x, y = data_handler.split_data(df_test[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monk 1 [TRAIN]: (124, 17)\n",
      "Monk 1 [TEST]: (432, 17)\n",
      "Monk 2 [TRAIN]: (169, 17)\n",
      "Monk 2 [TEST]: (432, 17)\n",
      "Monk 3 [TRAIN]: (122, 17)\n",
      "Monk 3 [TEST]: (432, 17)\n"
     ]
    }
   ],
   "source": [
    "# Applies the 1-Hot Encoding to the \"x\" data\n",
    "for i in range(datasets_number):\n",
    "    x_train[i] = data_handler.one_hot_encoding(x_train[i])\n",
    "    x_test[i]  = data_handler.one_hot_encoding(x_test[i])\n",
    "\n",
    "    # Print of the data modified\n",
    "    print(f\"Monk {i+1} [TRAIN]: \" + str(x_train[i].shape))\n",
    "    print(f\"Monk {i+1} [TEST]: \" + str(x_test[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters' space for Grid Search (1 for each Dataset)\n",
    "param_space = {\n",
    "    0: {\n",
    "        'hidden_units': [3, 4],\n",
    "        'patience': [15, 30],\n",
    "        'learning_rate': [0.3, 0.4],\n",
    "        'batch_size': [4, 6],\n",
    "        'nesterov': [\"T\", \"F\"],\n",
    "        'epochs': [350, 450],\n",
    "        'momentum': [0.6, 0.7]\n",
    "    },\n",
    "    1: {\n",
    "        'hidden_units': [3, 4, 5],\n",
    "        'patience': [15, 30],\n",
    "        'factor_lr_dec': [0.5, 1],\n",
    "        'step_decay': [500, 1000, 1500],\n",
    "        'learning_rate': [0.9, 0.8, 0.7],\n",
    "        'batch_size': [10, 30, 60], \n",
    "        'epochs': [180, 250, 350],\n",
    "        'momentum': [0.6, 0.7, 0.8],\n",
    "        'nesterov': [\"T\", \"F\"],\n",
    "    },\n",
    "    2: {\n",
    "        'hidden_units': [2, 3],\n",
    "        'patience': [10,15,30],\n",
    "        'factor_lr_dec': [0.5, 1],\n",
    "        'step_decay': [500, 1000, 1500],\n",
    "        'learning_rate': [float(i/100) for i in range(1,10)],\n",
    "        'batch_size': [7, 8, 9, 32, 64],\n",
    "        'epochs': [int(350+epochs) for epochs in range(0,50,10)],\n",
    "        'weight_decay': [float(i/1000) for i in range(1,10)],\n",
    "        'momentum': [float(i/1000) for i in range(10,90,5)] + [float(i/100) for i in range(10,90,5)],\n",
    "        'nesterov': [\"T\", \"F\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyperparameters Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.014316057164978701\n",
      " Mean Validation Loss:              0.05967546286992729\n",
      " Mean Training Accuracy:            0.9839393973350525\n",
      " Mean Validation Accuracy:          0.9270000100135803\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.014316057164978701\n",
      " Mean Validation Loss:              0.05967546286992729\n",
      " Mean Training Accuracy:            0.9839393973350525\n",
      " Mean Validation Accuracy:          0.9270000100135803\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                              1\n",
      " Trial:                             2\n",
      " Hyperparameters:                   {'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.05766060999740148\n",
      " Mean Validation Loss:              0.07892083491315134\n",
      " Mean Training Accuracy:            0.9295959711074829\n",
      " Mean Validation Accuracy:          0.9026666641235351\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.014316057164978701\n",
      " Mean Validation Loss:              0.05967546286992729\n",
      " Mean Training Accuracy:            0.9839393973350525\n",
      " Mean Validation Accuracy:          0.9270000100135803\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m nn_i\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39mn_hidden_layers_list[dataset_i])\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mnn_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_val\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m nn_i\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     50\u001b[0m     x_train\u001b[38;5;241m=\u001b[39mx_kfold_train,\n\u001b[0;32m     51\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my_kfold_train,\n\u001b[0;32m     52\u001b[0m     x_val\u001b[38;5;241m=\u001b[39mx_kfold_val,\n\u001b[0;32m     53\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_kfold_val\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\corra\\Documents\\GitHub\\Machine_Learning_Project\\api\\binary_nn.py:276\u001b[0m, in \u001b[0;36mBinaryNN.fit\u001b[1;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Training of the model with TR set and VL set (already splitted)\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Error case\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from api.binary_nn import BinaryNN\n",
    "\n",
    "# Creation of a BinaryNN objct for each dataset\n",
    "nn: list[BinaryNN] = []\n",
    "\n",
    "# Different values per dataset\n",
    "trials_list = [40, 30, 50]\n",
    "k_values = [5, 5, 5]\n",
    "n_hidden_layers_list = [1, 1, 1]\n",
    "\n",
    "# Search of the best Hyperparameters to each Training set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_train[dataset_i].values\n",
    "    y = y_train[dataset_i].values\n",
    "    k = k_values[dataset_i]\n",
    "\n",
    "    # K-fold Cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Computes and Stores all the parameters combinations\n",
    "    data_handler.set_params_combinations(params=param_space[dataset_i])\n",
    "\n",
    "    params_combinations = data_handler.get_params_combinations()\n",
    "\n",
    "    # For each iteration we choose the hyperparameters and we use them with K-fold CV\n",
    "    for trial, params in enumerate(params_combinations):\n",
    "\n",
    "        # Creation of the Neural Network object\n",
    "        nn_i = BinaryNN(params=params, monk_i=dataset_i+1, trial=trial+1)\n",
    "\n",
    "        # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "        for train_index, val_index in kfold.split(X, y):\n",
    "            x_kfold_train, x_kfold_val = X[train_index], X[val_index]\n",
    "            y_kfold_train, y_kfold_val = y[train_index], y[val_index]\n",
    "\n",
    "            # Building the model\n",
    "            nn_i.create_model(n_hidden_layers=n_hidden_layers_list[dataset_i])\n",
    "\n",
    "            # Training the model\n",
    "            nn_i.fit(\n",
    "                x_train=x_kfold_train,\n",
    "                y_train=y_kfold_train,\n",
    "                x_val=x_kfold_val,\n",
    "                y_val=y_kfold_val\n",
    "            )\n",
    "\n",
    "            # Evaluating the model\n",
    "            nn_i.evaluate(\n",
    "                x_train=x_kfold_train,\n",
    "                y_train=y_kfold_train,\n",
    "                x_val=x_kfold_val,\n",
    "                y_val=y_kfold_val\n",
    "            )\n",
    "\n",
    "        # Case of first append\n",
    "        if len(nn) == dataset_i:\n",
    "            nn.append(nn_i)\n",
    "\n",
    "        # Print the results of this trial\n",
    "        print(\"------------------ Current Hyperparameters ------------------\")\n",
    "        nn_i.print_training_info()\n",
    "        print(\"-------------------- Best Hyperparameters -------------------\")\n",
    "        nn[dataset_i].print_training_info()\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # Update best hyperparameters if: no high overfitting AND (higher mean VL accuracy OR (equal mean AND\n",
    "        if nn_i.mean_tr_accuracy-0.1 <= nn_i.mean_vl_accuracy \\\n",
    "            and (\n",
    "                    nn[dataset_i].mean_vl_accuracy < nn_i.mean_vl_accuracy \\\n",
    "                or (\n",
    "                    nn[dataset_i].mean_vl_accuracy == nn_i.mean_vl_accuracy and nn[dataset_i].mean_tr_accuracy < nn_i.mean_tr_accuracy\n",
    "                    )\n",
    "            ):\n",
    "            nn[dataset_i] = nn_i\n",
    "\n",
    "        # Case of TR/VL AND TR/VL loss minor\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy >= 0.98 \\\n",
    "            and nn_i.mean_tr_accuracy == nn[dataset_i].mean_tr_accuracy \\\n",
    "            and nn_i.mean_vl_accuracy == nn[dataset_i].mean_vl_accuracy \\\n",
    "            and abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < 0.02 \\\n",
    "            and nn_i.mean_vl_loss < nn[dataset_i].mean_vl_loss \\\n",
    "            and nn_i.mean_tr_loss < nn[dataset_i].mean_tr_loss:\n",
    "            nn[dataset_i] = nn_i\n",
    "\n",
    "        # Exit case\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy == 1 \\\n",
    "            and nn_i.mean_vl_loss < 0.1 and nn_i.mean_tr_loss < 0.1 \\\n",
    "            and abs(nn_i.mean_vl_loss - nn_i.mean_tr_loss) < 0.01:\n",
    "            nn[dataset_i] = nn_i\n",
    "            break\n",
    "\n",
    "    # Print output\n",
    "    print(f\"### Best Hyperparameters of Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print of best Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Best Hyperparameters for Monk 1 ###\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.014316057164978701\n",
      " Mean Validation Loss:              0.05967546286992729\n",
      " Mean Training Accuracy:            0.9839393973350525\n",
      " Mean Validation Accuracy:          0.9270000100135803\n",
      "\n",
      "### Best Hyperparameters for Monk 2 ###\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(datasets_number):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Print best hyperparameters\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Best Hyperparameters for Monk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mprint_training_info()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# BEST L CURVE M1: >(semismoothed)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1500, 'learning_rate': 0.999, 'batch_size': 17, 'epochs': 350, 'weight_init': 'glorot_normal', 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#  Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.5, 'batch_size': 32, 'epochs': 370, 'weight_init': 'lecun_normal', 'momentum': 0.8, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m    \u001b[38;5;66;03m# BEST SMOOTHER PT2 MONK2:  {'hidden_units': 4, 'patience': 10, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 450, 'momentum': 0.3, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03mBest Hyperparameters for Monk 2\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m Monk:                     2\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m '''\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Iteration on all the Datasets\n",
    "for dataset_i in range(datasets_number):\n",
    "\n",
    "    # Print best hyperparameters\n",
    "    print(f\"\\n### Best Hyperparameters for Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "   \n",
    " \n",
    "    # BEST L CURVE M1: >(semismoothed)\n",
    "    # Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1500, 'learning_rate': 0.999, 'batch_size': 17, 'epochs': 350, 'weight_init': 'glorot_normal', 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    #  Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.5, 'batch_size': 32, 'epochs': 370, 'weight_init': 'lecun_normal', 'momentum': 0.8, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    # Hyp:  {'input_units': 17, 'hidden_units': 5, 'patience': 200, 'factor_lr_dec': 0.5, 'step_decay': 500, 'learning_rate': 0.99, 'batch_size': 16, 'epochs': 530, 'weight_init': 'lecun_normal', 'momentum': 0.5, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "    \n",
    "    # BEST SMOOTHED CURVE MONK1:   HyperparameterS: {'hidden_units': 4, 'patience': 30, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 440, 'momentum': 0.6}\n",
    "                                                     #Hyperparameters:          {'input_units': 17, 'hidden_units': 4, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'F', 'epochs': 440, 'momentum': 0.7, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "\n",
    "   # BEST SMOOTHER PT2 MONK2:  {'hidden_units': 4, 'patience': 10, 'learning_rate': 0.4, 'batch_size': 6, 'nesterov': 'T', 'epochs': 450, 'momentum': 0.3, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    "\n",
    "'''\n",
    "Best Hyperparameters for Monk 2\n",
    " Monk:                     2\n",
    " Trial:                    3\n",
    " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 200, 'factor_lr_dec': 1.0, 'step_decay': 500, 'learning_rate': 0.999, 'batch_size': 60, 'epochs': 290, 'momentum': 0.75, 'nesterov': 'T', 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    " Mean Training Loss:       0.0006283932307269424\n",
    " Mean Validation Loss:     0.004200904699973762\n",
    " Mean Training Accuracy:   1.0\n",
    " Mean Validation Accuracy: 1.0\n",
    "\n",
    "### Best Hyperparameters for Monk 3 ###\n",
    " Monk:                     3\n",
    " Trial:                    14\n",
    " Hyperparameters:          {'input_units': 17, 'hidden_units': 2, 'patience': 30, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.07, 'batch_size': 7, 'epochs': 370, 'weight_decay': 0.002, 'momentum': 0.08, 'nesterov': 'T', 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
    " Mean Training Loss:       0.059438984096050265\n",
    " Mean Validation Loss:     0.07536792308092118\n",
    " Mean Training Accuracy:   0.9508310675621032\n",
    " Mean Validation Accuracy: 0.934333324432373\n",
    "\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining: Mean, Standard Deviation and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Monk 1 ###\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 2s 31ms/step - loss: 0.2190 - accuracy: 0.6263 - val_loss: 0.2880 - val_accuracy: 0.4800\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1656 - accuracy: 0.7475 - val_loss: 0.4209 - val_accuracy: 0.4800\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.1213 - accuracy: 0.8889 - val_loss: 0.4549 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9091 - val_loss: 0.4560 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0768 - accuracy: 0.9192 - val_loss: 0.4539 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9192 - val_loss: 0.4506 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9192 - val_loss: 0.4503 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0708 - accuracy: 0.9192 - val_loss: 0.4517 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0690 - accuracy: 0.9192 - val_loss: 0.4576 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0655 - accuracy: 0.9192 - val_loss: 0.4597 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9192 - val_loss: 0.4681 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9192 - val_loss: 0.4548 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9192 - val_loss: 0.4656 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9697 - val_loss: 0.4641 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             1\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.19557204842567444\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.6854838728904724\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 12ms/step - loss: 0.2163 - accuracy: 0.6869 - val_loss: 0.3705 - val_accuracy: 0.4800\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.7778 - val_loss: 0.4010 - val_accuracy: 0.4400\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.8889 - val_loss: 0.4743 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9192 - val_loss: 0.4898 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9192 - val_loss: 0.4994 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9293 - val_loss: 0.5119 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9596 - val_loss: 0.5227 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.4400\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.4400\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.4400\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.4400\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.4400\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.4400\n",
      " Monk:                              1\n",
      " Trial:                             2\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.21556736528873444\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.6854838728904724\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 9ms/step - loss: 0.2199 - accuracy: 0.6768 - val_loss: 0.3439 - val_accuracy: 0.4400\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.8081 - val_loss: 0.4041 - val_accuracy: 0.4800\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.8485 - val_loss: 0.4282 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9192 - val_loss: 0.4386 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9192 - val_loss: 0.4409 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9192 - val_loss: 0.4354 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9192 - val_loss: 0.4246 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9192 - val_loss: 0.4137 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9192 - val_loss: 0.4188 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9192 - val_loss: 0.4320 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9192 - val_loss: 0.4425 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9293 - val_loss: 0.4560 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9697 - val_loss: 0.4632 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             3\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.20704291760921478\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.7177419066429138\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 11ms/step - loss: 0.2467 - accuracy: 0.5556 - val_loss: 0.3249 - val_accuracy: 0.3600\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.8182 - val_loss: 0.4416 - val_accuracy: 0.4400\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.8687 - val_loss: 0.4464 - val_accuracy: 0.4400\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9091 - val_loss: 0.4723 - val_accuracy: 0.3600\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9192 - val_loss: 0.4590 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9192 - val_loss: 0.4533 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9192 - val_loss: 0.4646 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9192 - val_loss: 0.4683 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9192 - val_loss: 0.4685 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9192 - val_loss: 0.4739 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9495 - val_loss: 0.4694 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9899 - val_loss: 0.4699 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             4\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.21829934418201447\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.7016128897666931\n",
      " Mean Validation Accuracy:          0\n",
      "Epoch 1/350\n",
      "25/25 [==============================] - 1s 10ms/step - loss: 0.2218 - accuracy: 0.6364 - val_loss: 0.4090 - val_accuracy: 0.4000\n",
      "Epoch 2/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.8283 - val_loss: 0.4475 - val_accuracy: 0.4800\n",
      "Epoch 3/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.8990 - val_loss: 0.4790 - val_accuracy: 0.4800\n",
      "Epoch 4/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9192 - val_loss: 0.4704 - val_accuracy: 0.4800\n",
      "Epoch 5/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9596 - val_loss: 0.5120 - val_accuracy: 0.4800\n",
      "Epoch 6/350\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9798 - val_loss: 0.5132 - val_accuracy: 0.4800\n",
      "Epoch 7/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.4800\n",
      "Epoch 8/350\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.4800\n",
      "Epoch 9/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.4800\n",
      "Epoch 10/350\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.4800\n",
      "Epoch 11/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.4800\n",
      "Epoch 12/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5216 - val_accuracy: 0.4800\n",
      "Epoch 13/350\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.4800\n",
      "Epoch 14/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.4800\n",
      "Epoch 15/350\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.4800\n",
      "Epoch 16/350\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.4800\n",
      " Monk:                              1\n",
      " Trial:                             5\n",
      " Hyperparameters:                   {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:                0.20656919479370117\n",
      " Mean Validation Loss:              0\n",
      " Mean Training Accuracy:            0.725806474685669\n",
      " Mean Validation Accuracy:          0\n",
      "\n",
      "Mean TR MSE: 0.20861017405986787\n",
      "\n",
      "Mean VL MSE: 0.0\n",
      "\n",
      "Mean TR Accuracy: 0.7032258033752441\n",
      "\n",
      "Mean VL Accuracy: 0.0\n",
      "\n",
      "Variance TR MSE: 6.377942733019281e-05\n",
      "\n",
      "Variance VL MSE: 0.0\n",
      "\n",
      "Variance TR Accuracy: 0.00027055153117373716\n",
      "\n",
      "Variance VL Accuracy: 0.0\n",
      "Standard Deviation TR MSE: 0.007986202309620813\n",
      "\n",
      "Standard Deviation VL MSE: 0.0\n",
      "Standard Deviation TR Accuracy: 0.016448450722598075\n",
      "Standard Deviation VL Accuracy: 0.0\n",
      "\n",
      "### Monk 2 ###\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Inner loop for different initializations\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_initializations):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Create a new model instance with the best hyperparameters for the current monk\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     nn_instance \u001b[38;5;241m=\u001b[39m BinaryNN(params\u001b[38;5;241m=\u001b[39m\u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mparams, monk_i\u001b[38;5;241m=\u001b[39mdataset_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, trial\u001b[38;5;241m=\u001b[39m_\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m     nn_instance\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39mn_hidden_layers_list[dataset_i])\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Training the model\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of initializations\n",
    "num_initializations = 5\n",
    "\n",
    "# Iterate over each monk (dataset)\n",
    "for dataset_i in range(datasets_number):\n",
    "    print(f\"\\n### Monk {dataset_i + 1} ###\")\n",
    "\n",
    "    # Extract dataset for the current monk\n",
    "    x = x_train[dataset_i].values\n",
    "    y_fit = y_train[dataset_i].values\n",
    "    X = x_test[dataset_i].values\n",
    "    y = y_test[dataset_i].values\n",
    "\n",
    "    tr_mse_values = []  # List to store MSE TR values for each initialization\n",
    "    vl_mse_values = []  # List to store MSE VL values for each initialization\n",
    "    vl_acc_values = []   # List to store Accuracies values for each initialization\n",
    "    tr_acc_values = []   # List to store Accuracies values for each initialization\n",
    "\n",
    "    # Inner loop for different initializations\n",
    "    for _ in range(num_initializations):\n",
    "        # Create a new model instance with the best hyperparameters for the current monk\n",
    "        nn_instance = BinaryNN(params=nn[dataset_i].params, monk_i=dataset_i+1, trial=_+1)\n",
    "        nn_instance.create_model(n_hidden_layers=n_hidden_layers_list[dataset_i])\n",
    "        \n",
    "        # Training the model\n",
    "        nn_instance.fit(x_train=x,\n",
    "               y_train=y_fit\n",
    "                        )\n",
    "\n",
    "        # Evaluating the model\n",
    "        nn_instance.evaluate(\n",
    "                x_train=x,\n",
    "                y_train=y_fit\n",
    "                )\n",
    "       \n",
    "        # Access the training loss from the nn_instance and store it\n",
    "        tr_mse_values.append(nn_instance.mean_tr_loss)\n",
    "        vl_mse_values.append(nn_instance.mean_vl_loss)\n",
    "        tr_acc_values.append(nn_instance.mean_tr_accuracy)\n",
    "        vl_acc_values.append(nn_instance.mean_vl_accuracy)\n",
    "\n",
    "        nn_instance.print_training_info()\n",
    "\n",
    "\n",
    "    # Calculate and print mean, variance and standard deviation\n",
    "    \n",
    "    # Mean TR mse\n",
    "    meantr_mse = np.mean(tr_mse_values)\n",
    "    # Mean VL mse\n",
    "    meanvl_mse = np.mean(vl_mse_values)\n",
    "    \n",
    "    # Mean TR accuracies\n",
    "    meantr_acc = np.mean(tr_acc_values)\n",
    "    # Mean VL accuracies\n",
    "    meanvl_acc = np.mean(vl_acc_values)\n",
    "\n",
    "    # Variance MSE VL\n",
    "    variance_mse_vl = np.var(vl_mse_values)\n",
    "    # Variance MSE TR\n",
    "    variance_mse_tr = np.var(tr_mse_values)\n",
    "\n",
    "    # Variance TR accuracies\n",
    "    variancetr_acc = np.var(tr_acc_values)\n",
    "    # Variance VL accuracies\n",
    "    variancevl_acc = np.var(vl_acc_values)\n",
    "\n",
    "    # Standard dev TR accuracies\n",
    "    std_tr_acc = np.std(tr_acc_values)\n",
    "    # Standard dev VL accuracies\n",
    "    std_vl_acc = np.std(vl_acc_values)\n",
    "    \n",
    "    # Standard dev VL mse\n",
    "    std_deviation_vl = np.std(vl_mse_values)\n",
    "    # Standard dev TR mse\n",
    "    std_deviation_tr = np.std(tr_mse_values)\n",
    "\n",
    "    print(f'\\nMean TR MSE: {meantr_mse}')\n",
    "    print(f'\\nMean VL MSE: {meanvl_mse}')\n",
    "    print(f'\\nMean TR Accuracy: {meantr_acc}')\n",
    "    print(f'\\nMean VL Accuracy: {meanvl_acc}')\n",
    "    print(f'\\nVariance TR MSE: {variance_mse_tr}')\n",
    "    print(f'\\nVariance VL MSE: {variance_mse_vl}')\n",
    "    print(f'\\nVariance TR Accuracy: {variancetr_acc}')\n",
    "    print(f'\\nVariance VL Accuracy: {variancevl_acc}')\n",
    "    print(f'Standard Deviation TR MSE: {std_deviation_tr}')\n",
    "    print(f'\\nStandard Deviation VL MSE: {std_deviation_vl}')\n",
    "    print(f'Standard Deviation TR Accuracy: {std_tr_acc}')\n",
    "    print(f'Standard Deviation VL Accuracy: {std_vl_acc}')\n",
    "\n",
    "    # Plot learning curves\n",
    "    nn_instance.print_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Monk:                         1\n",
      " Trial:                        1\n",
      " Hyperparameters:              {'hidden_units': 3, 'patience': 15, 'learning_rate': 0.3, 'batch_size': 4, 'nesterov': 'T', 'epochs': 350, 'momentum': 0.6}\n",
      " Mean Training Loss:           0.055430112034082414\n",
      " Mean Validation Loss:         0.09350064843893051\n",
      " Test Loss:                    0.04788719862699509\n",
      " Mean Training Accuracy:       0.9314141511917114\n",
      " Mean Validation Accuracy:     0.8790000081062317\n",
      " Test Accuracy:                0.9166666865348816\n",
      " f1 score:                     0.9090909090909091\n",
      " f2 score:                     0.8620689655172415\n",
      " Precision score:              1.0\n",
      " Recall score:                 0.8333333333333334\n",
      "\n",
      "              Predicted_Class_0  Predicted_Class_1\n",
      "Real_Class_0                216                  0\n",
      "Real_Class_1                 36                180\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m y_test[dataset_i]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate the Model on TS set\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtest(\n\u001b[0;32m      8\u001b[0m     x_test\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m      9\u001b[0m     y_test\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Computes the score of the Model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m nn[dataset_i]\u001b[38;5;241m.\u001b[39mscore(x_test\u001b[38;5;241m=\u001b[39mX, y_test\u001b[38;5;241m=\u001b[39my)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Final testing of the Models for each Test set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_test[dataset_i].values\n",
    "    y = y_test[dataset_i].values\n",
    "\n",
    "    # Evaluate the Model on TS set\n",
    "    nn[dataset_i].test(\n",
    "        x_test=X,\n",
    "        y_test=y\n",
    "    )\n",
    "\n",
    "    # Computes the score of the Model\n",
    "    nn[dataset_i].score(x_test=X, y_test=y)\n",
    "\n",
    "    # Prints the results obtained\n",
    "    print(nn[dataset_i])\n",
    "    nn[dataset_i].print_confusion_matrix(y_test=y)\n",
    "    nn[dataset_i].print_roc_curve(y_test=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
