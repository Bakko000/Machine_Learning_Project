{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      col1      col2      col3      col4      col5      col6      col7  \\\n",
      "0   1 -0.917280 -0.712727 -0.989904  0.992819  0.993649  0.995543  0.711074   \n",
      "1   2 -0.858784  0.998755 -0.998396  0.999909  0.316503 -0.951897 -0.163139   \n",
      "2   3 -0.990441  0.958726 -0.998675  0.997216  0.987166  0.356483 -0.279689   \n",
      "3   4  0.937117  0.984474 -0.612420  0.999812  0.728623 -0.539962 -0.165939   \n",
      "4   5 -0.906628 -0.884567 -0.932487  0.941037  0.978134  0.998179  0.749606   \n",
      "\n",
      "       col8      col9     col10   target_x   target_y   target_z  \n",
      "0  0.407645 -0.688548  0.616890   7.897453 -35.936382  21.077147  \n",
      "1  0.980982  0.661759 -0.800155  -9.330632  19.901571   6.069154  \n",
      "2  0.599163 -0.684630  0.922901  14.849400   3.374090  19.667479  \n",
      "3  0.999352 -0.921444 -0.974766 -46.591854  13.734777  17.953600  \n",
      "4 -0.590599 -0.508268  0.691798   8.217500 -45.885254  14.894251  \n",
      "   id      col1      col2      col3      col4      col5      col6      col7  \\\n",
      "0   1 -0.983589  0.989514 -0.998539  0.999440  0.970297 -0.234119 -0.133332   \n",
      "1   2 -0.296891 -0.831832 -0.967981  0.986235  0.998669  0.997767 -0.340468   \n",
      "2   3 -0.986512  0.979557 -0.998547  0.999430  0.985407  0.166472  0.035096   \n",
      "3   4 -0.594083  0.986703 -0.992113  0.999881  0.982517  0.187048 -0.135851   \n",
      "4   5  0.940018  0.934761 -0.159506  0.999147  0.846696  0.413116 -0.628644   \n",
      "\n",
      "       col8      col9     col10  target_x  target_y  target_z  \n",
      "0  0.899576 -0.605156  0.656074       NaN       NaN       NaN  \n",
      "1  0.817937 -0.968516  0.699273       NaN       NaN       NaN  \n",
      "2  0.877812 -0.698500  0.667267       NaN       NaN       NaN  \n",
      "3  0.995478 -0.801041 -0.864406       NaN       NaN       NaN  \n",
      "4  0.998797 -0.967884 -0.949134       NaN       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "from api.data_handler import DataHandler\n",
    "\n",
    "# Creation of a DataHandler Object\n",
    "data_handler = DataHandler(['id', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'target_x', 'target_y', 'target_z'])\n",
    "\n",
    "# Load the Training/Test sets into pandas DataFrames\n",
    "df_train : pd.DataFrame = data_handler.load_data(f'data/cup/ML-CUP23-TR.csv', delimiter=',')\n",
    "df_test  : pd.DataFrame = data_handler.load_data(f'data/cup/ML-CUP23-TS.csv', delimiter=',')\n",
    "\n",
    "# Print the head of the loaded data\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters' space for Grid Search (1 for each Dataset)\n",
    "param_space = {\n",
    "    0: {\n",
    "        'hidden_units': [30, 40, 50],\n",
    "        'patience': [10,15,30],\n",
    "        'factor_lr_dec': [0.5, 1],\n",
    "        'step_decay': [500, 1000, 1500],\n",
    "        'learning_rate': [float(i/10) for i in range(1,10)] + [float(i/100) for i in range(1,10)] + [0.99, 0.999],\n",
    "        'batch_size': [7, 8, 9, 15, 16, 17, 31, 32, 33, 62, 63, 64, 65],\n",
    "        'epochs': [int(350+epochs) for epochs in range(0,50,10)],\n",
    "        'weight_decay': [float(i/10) for i in range(1,10)] + [0.01, 0.001, 0.0001],\n",
    "        'weight_init': ['glorot_normal', 'lecun_normal', 'he_normal', 'he_uniform'],\n",
    "        'momentum': [float(i/100) for i in range(1,9)] + [float(i/10) for i in range(1,9)],\n",
    "        'activation': ['tanh', 'linear'],\n",
    "        'output_activation': ['linear'],\n",
    "        'metrics': ['mean_squared_error'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IDs TR SET]: (1000,)\n",
      "[IDs TS SET]: (900,)\n",
      "[TR SET - x]: (800, 10)\n",
      "[TR SET - y]: (800, 3)\n",
      "[Internal TS SET - x]: (200, 10)\n",
      "[Internal TS SET - y]: (200, 3)\n",
      "[TS SET - x]: (900, 10)\n",
      "[TS SET - y]: (900, 3)\n"
     ]
    }
   ],
   "source": [
    "# Saving the ID columns\n",
    "df_id_train: pd.DataFrame = df_train['id']\n",
    "df_id_test: pd.DataFrame = df_test['id']\n",
    "\n",
    "# Drop the ID columns\n",
    "df_train = df_train.drop(columns=['id'],axis=1).copy(deep=True)\n",
    "df_test = df_test.drop(columns=['id'],axis=1).copy(deep=True)\n",
    "\n",
    "# Split of columns and rows (0.8/0.2) into: TR set and Internal TS set\n",
    "x_train, y_train, x_internal_test, y_internal_test = data_handler.split_data(\n",
    "    data=df_train,\n",
    "    cols_name_split=['target_x','target_y','target_z'],\n",
    "    rows_split_perc=0.8\n",
    ")\n",
    "\n",
    "# Split on columns\n",
    "x_test, y_test = data_handler.split_data(data=df_test, cols_name_split=['target_x','target_y','target_z'])\n",
    "\n",
    "# Print of the shapes\n",
    "print(f\"[IDs TR SET]: \" + str(df_id_train.shape))\n",
    "print(f\"[IDs TS SET]: \" + str(df_id_test.shape))\n",
    "print(f\"[TR SET - x]: \" + str(x_train.shape))\n",
    "print(f\"[TR SET - y]: \" + str(y_train.shape))\n",
    "print(f\"[Internal TS SET - x]: \" + str(x_internal_test.shape))\n",
    "print(f\"[Internal TS SET - y]: \" + str(y_internal_test.shape))\n",
    "print(f\"[TS SET - x]: \" + str(x_test.shape))\n",
    "print(f\"[TS SET - y]: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 2, 'patience': 10, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.08, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.0001, 'weight_init': 'glorot_normal', 'momentum': 0.04, 'activation': 'tanh', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       292.4246551513672\n",
      " Mean Validation Loss:     288.5699981689453\n",
      " Mean Training Accuracy:   292.3843994140625\n",
      " Mean Validation Accuracy: 288.5297332763672\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     3\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 4, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1000, 'learning_rate': 0.08, 'batch_size': 17, 'epochs': 380, 'weight_decay': 0.8, 'weight_init': 'lecun_normal', 'momentum': 0.03, 'activation': 'tanh', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       380.80029296875\n",
      " Mean Validation Loss:     379.55149536132814\n",
      " Mean Training Accuracy:   266.6454315185547\n",
      " Mean Validation Accuracy: 265.39661865234376\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     4\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 4, 'patience': 100, 'factor_lr_dec': 1.0, 'step_decay': 500, 'learning_rate': 0.09, 'batch_size': 33, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'he_normal', 'momentum': 0.03, 'activation': 'tanh', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       209.8324462890625\n",
      " Mean Validation Loss:     210.609033203125\n",
      " Mean Training Accuracy:   166.03087158203124\n",
      " Mean Validation Accuracy: 166.80746154785157\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     5\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 0.5, 'step_decay': 500, 'learning_rate': 0.6, 'batch_size': 31, 'epochs': 380, 'weight_decay': 0.1, 'weight_init': 'glorot_normal', 'momentum': 0.4, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     6\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 4, 'patience': 200, 'factor_lr_dec': 0.5, 'step_decay': 500, 'learning_rate': 0.99, 'batch_size': 64, 'epochs': 380, 'weight_decay': 0.6, 'weight_init': 'he_normal', 'momentum': 0.8, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     7\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 3, 'patience': 200, 'factor_lr_dec': 0.5, 'step_decay': 500, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 390, 'weight_decay': 0.3, 'weight_init': 'glorot_normal', 'momentum': 0.08, 'activation': 'tanh', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       285.06862487792966\n",
      " Mean Validation Loss:     287.26210327148436\n",
      " Mean Training Accuracy:   238.80015563964844\n",
      " Mean Validation Accuracy: 240.99362182617188\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     8\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 4, 'patience': 10, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.6, 'batch_size': 8, 'epochs': 350, 'weight_decay': 0.1, 'weight_init': 'he_uniform', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     9\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 2, 'patience': 10, 'factor_lr_dec': 0.5, 'step_decay': 1000, 'learning_rate': 0.01, 'batch_size': 65, 'epochs': 360, 'weight_decay': 0.5, 'weight_init': 'he_uniform', 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       151.23797912597655\n",
      " Mean Validation Loss:     153.21451721191406\n",
      " Mean Training Accuracy:   148.44345397949218\n",
      " Mean Validation Accuracy: 150.42001342773438\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 2, 'patience': 100, 'factor_lr_dec': 0.5, 'step_decay': 1500, 'learning_rate': 0.02, 'batch_size': 16, 'epochs': 360, 'weight_decay': 0.9, 'weight_init': 'he_normal', 'momentum': 0.3, 'activation': 'tanh', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       285.006298828125\n",
      " Mean Validation Loss:     287.6145812988281\n",
      " Mean Training Accuracy:   255.04509582519532\n",
      " Mean Validation Accuracy: 257.65338134765625\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     11\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.999, 'batch_size': 16, 'epochs': 380, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.01, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_units': 17, 'hidden_units': 5, 'patience': 10, 'factor_lr_dec': 1.0, 'step_decay': 1500, 'learning_rate': 0.7, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.2, 'weight_init': 'lecun_normal', 'momentum': 0.02, 'activation': 'linear', 'output_activation': 'linear', 'metrics': 'mean_squared_error'}\n",
      " Mean Training Loss:       nan\n",
      " Mean Validation Loss:     nan\n",
      " Mean Training Accuracy:   nan\n",
      " Mean Validation Accuracy: nan\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     y_kfold_train, y_kfold_val \u001b[38;5;241m=\u001b[39m y[train_index], y[val_index]\n\u001b[0;32m     39\u001b[0m     nn_i\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mnn_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_val\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     nn_i\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     49\u001b[0m         x_train\u001b[38;5;241m=\u001b[39mx_kfold_train,\n\u001b[0;32m     50\u001b[0m         y_train\u001b[38;5;241m=\u001b[39my_kfold_train,\n\u001b[0;32m     51\u001b[0m         x_val\u001b[38;5;241m=\u001b[39mx_kfold_val,\n\u001b[0;32m     52\u001b[0m         y_val\u001b[38;5;241m=\u001b[39my_kfold_val\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Case of first assignment\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\Documents\\GitHub\\Machine_Learning_Project\\api\\keras\\binary_nn.py:232\u001b[0m, in \u001b[0;36mBinaryNN.fit\u001b[1;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Training of the model with TR set and VL set (already splitted)\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# Error case\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1841\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;66;03m# Create data_handler for evaluation and cache it.\u001b[39;00m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1843\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1851\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m   1857\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1858\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1867\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1868\u001b[0m )\n\u001b[0;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1871\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:370\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m options\u001b[38;5;241m.\u001b[39mexperimental_distribute\u001b[38;5;241m.\u001b[39mauto_shard_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    366\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAutoShardPolicy\u001b[38;5;241m.\u001b[39mDATA\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mwith_options(options)\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1240\u001b[0m, in \u001b[0;36mDatasetV2.prefetch\u001b[1;34m(self, buffer_size, name)\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprefetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer_size, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1213\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` that prefetches elements from this dataset.\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \n\u001b[0;32m   1215\u001b[0m \u001b[38;5;124;03m  Most dataset input pipelines should end with a call to `prefetch`. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1240\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprefetch_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   1241\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:28\u001b[0m, in \u001b[0;36m_prefetch\u001b[1;34m(input_dataset, buffer_size, name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m input_dataset\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_PrefetchDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:46\u001b[0m, in \u001b[0;36m_PrefetchDataset.__init__\u001b[1;34m(self, input_dataset, buffer_size, slack_period, name)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# We colocate the prefetch dataset with its input as this collocation only\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# happens automatically in graph mode.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m---> 46\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mprefetch_dataset(\n\u001b[0;32m     47\u001b[0m       input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,\n\u001b[0;32m     48\u001b[0m       buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_size,\n\u001b[0;32m     49\u001b[0m       slack_period\u001b[38;5;241m=\u001b[39mslack_period,\n\u001b[0;32m     50\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:5933\u001b[0m, in \u001b[0;36mprefetch_dataset\u001b[1;34m(input_dataset, buffer_size, output_types, output_shapes, slack_period, legacy_autotune, buffer_size_min, metadata, name)\u001b[0m\n\u001b[0;32m   5931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   5932\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5933\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5934\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrefetchDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5935\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5936\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mslack_period\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslack_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlegacy_autotune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy_autotune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5937\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuffer_size_min\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   5939\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from api.keras.binary_nn import BinaryNN\n",
    "\n",
    "# Creation of a BinaryNN objct for each dataset\n",
    "nn: BinaryNN = None\n",
    "\n",
    "# Different values per dataset\n",
    "trials = 20\n",
    "k = 5\n",
    "\n",
    "# Search of the best Hyperparameters\n",
    "X = x_train.values.astype(dtype=float)\n",
    "y = y_train.values.astype(dtype=float)\n",
    "\n",
    "# K-fold Cross-validation\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Sets all the combinations of the entire set of parameters\n",
    "#data_handler.set_params_combinations(params=param_space[dataset_i])\n",
    "\n",
    "# Gets the list with the combinations of all the parameters\n",
    "#params_combinations = data_handler.get_params_combinations()\n",
    "\n",
    "# For each iteration we choose the hyperparameters (randomly) and we use them with K-fold CV\n",
    "#for trial, params in enumerate(params_combinations):\n",
    "for trial in range(trials):\n",
    "\n",
    "    # Choose random hyperparameters\n",
    "    params = data_handler.random_dictionary(params=param_space[0])\n",
    "\n",
    "    # Creation of the Neural Network object\n",
    "    nn_i = BinaryNN(params=params, monk_i=trial+1, trial=+1)\n",
    "                    \n",
    "    # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "    for train_index, val_index in kfold.split(X, y):\n",
    "        x_kfold_train, x_kfold_val = X[train_index], X[val_index]\n",
    "        y_kfold_train, y_kfold_val = y[train_index], y[val_index]\n",
    "\n",
    "        nn_i.create_model(n_hidden_layers=1)\n",
    "\n",
    "        nn_i.fit(\n",
    "            x_train=x_kfold_train,\n",
    "            y_train=y_kfold_train,\n",
    "            x_val=x_kfold_val,\n",
    "            y_val=y_kfold_val\n",
    "        )\n",
    "\n",
    "        nn_i.evaluate(\n",
    "            x_train=x_kfold_train,\n",
    "            y_train=y_kfold_train,\n",
    "            x_val=x_kfold_val,\n",
    "            y_val=y_kfold_val\n",
    "        )\n",
    "\n",
    "    # Case of first assignment\n",
    "    if nn is None:\n",
    "        nn = nn_i\n",
    "    \n",
    "    # Print the results of this trial\n",
    "    print(\"\\n------------------ Current Hyperparameters ------------------\")\n",
    "    nn_i.print_training_info()\n",
    "    print(\"------------------ CUP Best Hyperparameters -----------------\")\n",
    "    nn.print_training_info()\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Update best hyperparameters if: no overfitting AND (higher mean VL accuracy OR (equal mean AND\n",
    "    if nn_i.mean_tr_accuracy-0.1 <= nn_i.mean_vl_accuracy \\\n",
    "        and (\n",
    "            nn.mean_vl_accuracy < nn_i.mean_vl_accuracy \\\n",
    "            or (\n",
    "                nn.mean_vl_accuracy == nn_i.mean_vl_accuracy \\\n",
    "                and nn.mean_tr_accuracy < nn_i.mean_tr_accuracy\n",
    "            )\n",
    "        ):\n",
    "        nn = nn_i\n",
    "    \n",
    "    # Case of higher mean VL accuracy AND NO Overfitting\n",
    "    if nn_i.mean_vl_accuracy > nn.mean_vl_accuracy \\\n",
    "        and (\n",
    "            abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < abs(nn.mean_tr_accuracy - nn.mean_vl_accuracy) \\\n",
    "            or abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < 0.02\n",
    "        ):\n",
    "        nn = nn_i\n",
    "    \n",
    "    # Exit case\n",
    "    if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy == 1 \\\n",
    "        and nn_i.mean_vl_loss < 0.1 and nn_i.mean_tr_loss < 0.1 \\\n",
    "        and abs(nn_i.mean_vl_loss - nn_i.mean_tr_loss) < 0.01:\n",
    "        nn = nn_i\n",
    "        break\n",
    "\n",
    "# Print output\n",
    "print(f\"### Best Hyperparameters for CUP ###\")\n",
    "nn.print_training_info()\n",
    "print(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
