{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      col1      col2      col3      col4      col5      col6      col7  \\\n",
      "0   1 -0.917280 -0.712727 -0.989904  0.992819  0.993649  0.995543  0.711074   \n",
      "1   2 -0.858784  0.998755 -0.998396  0.999909  0.316503 -0.951897 -0.163139   \n",
      "2   3 -0.990441  0.958726 -0.998675  0.997216  0.987166  0.356483 -0.279689   \n",
      "3   4  0.937117  0.984474 -0.612420  0.999812  0.728623 -0.539962 -0.165939   \n",
      "4   5 -0.906628 -0.884567 -0.932487  0.941037  0.978134  0.998179  0.749606   \n",
      "\n",
      "       col8      col9     col10   target_x   target_y   target_z  \n",
      "0  0.407645 -0.688548  0.616890   7.897453 -35.936382  21.077147  \n",
      "1  0.980982  0.661759 -0.800155  -9.330632  19.901571   6.069154  \n",
      "2  0.599163 -0.684630  0.922901  14.849400   3.374090  19.667479  \n",
      "3  0.999352 -0.921444 -0.974766 -46.591854  13.734777  17.953600  \n",
      "4 -0.590599 -0.508268  0.691798   8.217500 -45.885254  14.894251  \n",
      "   id      col1      col2      col3      col4      col5      col6      col7  \\\n",
      "0   1 -0.983589  0.989514 -0.998539  0.999440  0.970297 -0.234119 -0.133332   \n",
      "1   2 -0.296891 -0.831832 -0.967981  0.986235  0.998669  0.997767 -0.340468   \n",
      "2   3 -0.986512  0.979557 -0.998547  0.999430  0.985407  0.166472  0.035096   \n",
      "3   4 -0.594083  0.986703 -0.992113  0.999881  0.982517  0.187048 -0.135851   \n",
      "4   5  0.940018  0.934761 -0.159506  0.999147  0.846696  0.413116 -0.628644   \n",
      "\n",
      "       col8      col9     col10  target_x  target_y  target_z  \n",
      "0  0.899576 -0.605156  0.656074       NaN       NaN       NaN  \n",
      "1  0.817937 -0.968516  0.699273       NaN       NaN       NaN  \n",
      "2  0.877812 -0.698500  0.667267       NaN       NaN       NaN  \n",
      "3  0.995478 -0.801041 -0.864406       NaN       NaN       NaN  \n",
      "4  0.998797 -0.967884 -0.949134       NaN       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "from api.data_handler import DataHandler\n",
    "\n",
    "# Creation of a DataHandler Object\n",
    "data_handler = DataHandler(['id', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'target_x', 'target_y', 'target_z'])\n",
    "\n",
    "# Load the Training/Test sets into pandas DataFrames\n",
    "df_train : pd.DataFrame = data_handler.load_data(f'data/cup/ML-CUP23-TR.csv', delimiter=',')\n",
    "df_test  : pd.DataFrame = data_handler.load_data(f'data/cup/ML-CUP23-TS.csv', delimiter=',')\n",
    "\n",
    "# Print the head of the loaded data\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters' space for Grid Search (1 for each Dataset)\n",
    "param_space = {\n",
    "    0: {\n",
    "        'hidden_units': [64, 70, 75], \n",
    "        'patience': [10,15,30],\n",
    "        'learning_rate': [float(i/1000) for i in range(6,9)]+[float(i/100) for i in range(6,9)],\n",
    "        'batch_size': [16, 32, 64, 128],\n",
    "        'epochs': [int(450+epochs) for epochs in range(0,100,50)],\n",
    "        'weight_decay': [0.00001, 0.00003, 0.0006, 0.002], #float(i/1000) for i in range(1,5)] + [0.001, 0.0001, 0.1],\n",
    "        'momentum': [0.0001, 0.07, 0.001],\n",
    "        'activation': ['tanh'],\n",
    "        'nesterov': [True, False],\n",
    "        'output_activation': ['linear']    \n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IDs TR SET]: (1000,)\n",
      "[IDs TS SET]: (900,)\n",
      "[TR SET - x]: (800, 10)\n",
      "[TR SET - y]: (800, 3)\n",
      "[Internal TS SET - x]: (200, 10)\n",
      "[Internal TS SET - y]: (200, 3)\n",
      "[TS SET - x]: (900, 10)\n",
      "[TS SET - y]: (900, 3)\n"
     ]
    }
   ],
   "source": [
    "# Saving the ID columns\n",
    "df_id_train: pd.DataFrame = df_train['id']\n",
    "df_id_test: pd.DataFrame = df_test['id']\n",
    "\n",
    "# Drop the ID columns\n",
    "df_train = df_train.drop(columns=['id'],axis=1).copy(deep=True)\n",
    "df_test = df_test.drop(columns=['id'],axis=1).copy(deep=True)\n",
    "\n",
    "# Split of columns and rows (0.8/0.2) into: TR set and Internal TS set\n",
    "x_train, y_train, x_internal_test, y_internal_test = data_handler.split_data(\n",
    "    data=df_train,\n",
    "    cols_name_split=['target_x','target_y','target_z'],\n",
    "    rows_split_perc=0.8\n",
    ")\n",
    "\n",
    "# Split on columns\n",
    "x_test, y_test = data_handler.split_data(data=df_test, cols_name_split=['target_x','target_y','target_z'])\n",
    "\n",
    "# Print of the shapes\n",
    "print(f\"[IDs TR SET]: \" + str(df_id_train.shape))\n",
    "print(f\"[IDs TS SET]: \" + str(df_id_test.shape))\n",
    "print(f\"[TR SET - x]: \" + str(x_train.shape))\n",
    "print(f\"[TR SET - y]: \" + str(y_train.shape))\n",
    "print(f\"[Internal TS SET - x]: \" + str(x_internal_test.shape))\n",
    "print(f\"[Internal TS SET - y]: \" + str(y_internal_test.shape))\n",
    "print(f\"[TS SET - x]: \" + str(x_test.shape))\n",
    "print(f\"[TS SET - y]: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.006, 'batch_size': 128, 'epochs': 500, 'weight_decay': 0.002, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        1.3161060810089111\n",
      " Mean Validation MSE:      1.6448766469955445\n",
      " Mean Training MEE:        1.4763398885726928\n",
      " Mean Validation MEE:      1.6662020683288574\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.006, 'batch_size': 128, 'epochs': 500, 'weight_decay': 0.002, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        1.3161060810089111\n",
      " Mean Validation MSE:      1.6448766469955445\n",
      " Mean Training MEE:        1.4763398885726928\n",
      " Mean Validation MEE:      1.6662020683288574\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2427554726600647\n",
      " Mean Validation MSE:      0.5770864009857177\n",
      " Mean Training MEE:        0.7363458871841431\n",
      " Mean Validation MEE:      1.0052515387535095\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.006, 'batch_size': 128, 'epochs': 500, 'weight_decay': 0.002, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        1.3161060810089111\n",
      " Mean Validation MSE:      1.6448766469955445\n",
      " Mean Training MEE:        1.4763398885726928\n",
      " Mean Validation MEE:      1.6662020683288574\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     3\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 15, 'learning_rate': 0.007, 'batch_size': 128, 'epochs': 500, 'weight_decay': 0.002, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        1.203292965888977\n",
      " Mean Validation MSE:      1.5078601121902466\n",
      " Mean Training MEE:        1.4031104803085328\n",
      " Mean Validation MEE:      1.579607653617859\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2427554726600647\n",
      " Mean Validation MSE:      0.5770864009857177\n",
      " Mean Training MEE:        0.7363458871841431\n",
      " Mean Validation MEE:      1.0052515387535095\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     4\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 10, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 0.0006, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.5550194919109345\n",
      " Mean Validation MSE:      0.7845528364181519\n",
      " Mean Training MEE:        0.9178380370140076\n",
      " Mean Validation MEE:      1.1100006818771362\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2427554726600647\n",
      " Mean Validation MSE:      0.5770864009857177\n",
      " Mean Training MEE:        0.7363458871841431\n",
      " Mean Validation MEE:      1.0052515387535095\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     5\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 10, 'learning_rate': 0.008, 'batch_size': 16, 'epochs': 450, 'weight_decay': 0.002, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.6771551609039307\n",
      " Mean Validation MSE:      0.8774916052818298\n",
      " Mean Training MEE:        0.9160846710205078\n",
      " Mean Validation MEE:      1.084611678123474\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2427554726600647\n",
      " Mean Validation MSE:      0.5770864009857177\n",
      " Mean Training MEE:        0.7363458871841431\n",
      " Mean Validation MEE:      1.0052515387535095\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     6\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 64, 'epochs': 450, 'weight_decay': 0.0006, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.4197096824645996\n",
      " Mean Validation MSE:      0.6423928499221802\n",
      " Mean Training MEE:        0.7517111897468567\n",
      " Mean Validation MEE:      0.9695963621139526\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2427554726600647\n",
      " Mean Validation MSE:      0.5770864009857177\n",
      " Mean Training MEE:        0.7363458871841431\n",
      " Mean Validation MEE:      1.0052515387535095\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     7\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2117713510990143\n",
      " Mean Validation MSE:      0.4856574535369873\n",
      " Mean Training MEE:        0.6844335675239563\n",
      " Mean Validation MEE:      0.9437568426132202\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     6\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 64, 'epochs': 450, 'weight_decay': 0.0006, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.4197096824645996\n",
      " Mean Validation MSE:      0.6423928499221802\n",
      " Mean Training MEE:        0.7517111897468567\n",
      " Mean Validation MEE:      0.9695963621139526\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     8\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 10, 'learning_rate': 0.07, 'batch_size': 64, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.5662514209747315\n",
      " Mean Validation MSE:      0.8587968468666076\n",
      " Mean Training MEE:        1.0830417990684509\n",
      " Mean Validation MEE:      1.2715808629989624\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     7\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2117713510990143\n",
      " Mean Validation MSE:      0.4856574535369873\n",
      " Mean Training MEE:        0.6844335675239563\n",
      " Mean Validation MEE:      0.9437568426132202\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     9\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.08, 'batch_size': 128, 'epochs': 500, 'weight_decay': 0.0006, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.7212316989898682\n",
      " Mean Validation MSE:      1.0225560903549193\n",
      " Mean Training MEE:        1.0535144925117492\n",
      " Mean Validation MEE:      1.2851152896881104\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     7\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2117713510990143\n",
      " Mean Validation MSE:      0.4856574535369873\n",
      " Mean Training MEE:        0.6844335675239563\n",
      " Mean Validation MEE:      0.9437568426132202\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     7\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2117713510990143\n",
      " Mean Validation MSE:      0.4856574535369873\n",
      " Mean Training MEE:        0.6844335675239563\n",
      " Mean Validation MEE:      0.9437568426132202\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     11\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 15, 'learning_rate': 0.06, 'batch_size': 32, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2224975645542145\n",
      " Mean Validation MSE:      0.47434121966362\n",
      " Mean Training MEE:        0.7055767893791198\n",
      " Mean Validation MEE:      0.9462252855300903\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     12\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 10, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 0.0006, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.6229703366756439\n",
      " Mean Validation MSE:      0.8692438840866089\n",
      " Mean Training MEE:        0.9245700120925904\n",
      " Mean Validation MEE:      1.1122568607330323\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     13\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 10, 'learning_rate': 0.06, 'batch_size': 128, 'epochs': 450, 'weight_decay': 0.0006, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        1.708228588104248\n",
      " Mean Validation MSE:      1.8544072389602662\n",
      " Mean Training MEE:        1.6404158353805542\n",
      " Mean Validation MEE:      1.796855902671814\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     14\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 64, 'epochs': 450, 'weight_decay': 0.0006, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.48276477456092837\n",
      " Mean Validation MSE:      0.7128167390823364\n",
      " Mean Training MEE:        0.827483868598938\n",
      " Mean Validation MEE:      1.037916886806488\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     15\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 0.0006, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.43047847151756286\n",
      " Mean Validation MSE:      0.6410733580589294\n",
      " Mean Training MEE:        0.7218689560890198\n",
      " Mean Validation MEE:      0.9194240570068359\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     16\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 15, 'learning_rate': 0.007, 'batch_size': 64, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.47681877613067625\n",
      " Mean Validation MSE:      0.7316341638565064\n",
      " Mean Training MEE:        1.0214811563491821\n",
      " Mean Validation MEE:      1.2077947854995728\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     17\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 15, 'learning_rate': 0.007, 'batch_size': 32, 'epochs': 500, 'weight_decay': 0.002, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.6947878837585449\n",
      " Mean Validation MSE:      0.9206803917884827\n",
      " Mean Training MEE:        0.9428641438484192\n",
      " Mean Validation MEE:      1.1275137424468995\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     10\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.06, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.1681699961423874\n",
      " Mean Validation MSE:      0.4371948778629303\n",
      " Mean Training MEE:        0.6110775470733643\n",
      " Mean Validation MEE:      0.882560646533966\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     19\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.006, 'batch_size': 64, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.6181473016738892\n",
      " Mean Validation MSE:      0.8864858508110046\n",
      " Mean Training MEE:        1.148945188522339\n",
      " Mean Validation MEE:      1.3344581604003907\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     20\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 30, 'learning_rate': 0.08, 'batch_size': 128, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.6261400938034057\n",
      " Mean Validation MSE:      0.9220929265022277\n",
      " Mean Training MEE:        1.1469900608062744\n",
      " Mean Validation MEE:      1.3396089553833008\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     21\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 10, 'learning_rate': 0.008, 'batch_size': 128, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.786933958530426\n",
      " Mean Validation MSE:      1.0782992720603943\n",
      " Mean Training MEE:        1.295087718963623\n",
      " Mean Validation MEE:      1.4870317697525024\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     22\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.006, 'batch_size': 128, 'epochs': 500, 'weight_decay': 0.002, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        1.3730202198028565\n",
      " Mean Validation MSE:      1.698737096786499\n",
      " Mean Training MEE:        1.5106175422668457\n",
      " Mean Validation MEE:      1.684676170349121\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     23\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 32, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.16323747038841246\n",
      " Mean Validation MSE:      0.4012082815170288\n",
      " Mean Training MEE:        0.5765269637107849\n",
      " Mean Validation MEE:      0.8399297595024109\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     24\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 10, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.347453361749649\n",
      " Mean Validation MSE:      0.6026013493537903\n",
      " Mean Training MEE:        0.8654239177703857\n",
      " Mean Validation MEE:      1.086999249458313\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     25\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 15, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 450, 'weight_decay': 1e-05, 'momentum': 0.001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.2802810072898865\n",
      " Mean Validation MSE:      0.5164567589759826\n",
      " Mean Training MEE:        0.7963414788246155\n",
      " Mean Validation MEE:      1.0177052736282348\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     26\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 15, 'learning_rate': 0.07, 'batch_size': 64, 'epochs': 450, 'weight_decay': 0.0006, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.678963041305542\n",
      " Mean Validation MSE:      0.9712441086769104\n",
      " Mean Training MEE:        1.0457759261131288\n",
      " Mean Validation MEE:      1.2518783807754517\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     27\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 64, 'patience': 10, 'learning_rate': 0.06, 'batch_size': 128, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        1.620570421218872\n",
      " Mean Validation MSE:      1.9113489389419556\n",
      " Mean Training MEE:        1.757462215423584\n",
      " Mean Validation MEE:      1.8974188327789308\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     28\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 75, 'patience': 15, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 450, 'weight_decay': 0.0006, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.6082635402679444\n",
      " Mean Validation MSE:      0.8846250653266907\n",
      " Mean Training MEE:        0.8799182534217834\n",
      " Mean Validation MEE:      1.1139113903045654\n",
      "------------------ CUP Best Hyperparameters -----------------\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     y_kfold_train, y_kfold_val \u001b[38;5;241m=\u001b[39m y[train_index], y[val_index]\n\u001b[0;32m     39\u001b[0m     nn_i\u001b[38;5;241m.\u001b[39mcreate_model(n_hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mnn_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_val\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     nn_i\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m     49\u001b[0m         x_train\u001b[38;5;241m=\u001b[39mx_kfold_train,\n\u001b[0;32m     50\u001b[0m         y_train\u001b[38;5;241m=\u001b[39my_kfold_train,\n\u001b[0;32m     51\u001b[0m         x_val\u001b[38;5;241m=\u001b[39mx_kfold_val,\n\u001b[0;32m     52\u001b[0m         y_val\u001b[38;5;241m=\u001b[39my_kfold_val\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Case of first assignment\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\Documents\\GitHub\\Machine_Learning_Project\\api\\keras\\binary_nn.py:190\u001b[0m, in \u001b[0;36mBinaryNN.fit\u001b[1;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Training of the model with TR set and VL set (already splitted)\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Error case\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1855\u001b[0m     )\n\u001b[1;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1871\u001b[0m }\n\u001b[0;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2294\u001b[0m             ):\n\u001b[0;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[1;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[0;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[1;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from api.keras.binary_nn import BinaryNN\n",
    "\n",
    "# Creation of a BinaryNN objct for each dataset\n",
    "nn: BinaryNN = None\n",
    "\n",
    "# Different values per dataset\n",
    "trials = 100\n",
    "k = 5\n",
    "\n",
    "# Search of the best Hyperparameters\n",
    "X = x_train.values.astype(dtype=float)\n",
    "y = y_train.values.astype(dtype=float)\n",
    "\n",
    "# K-fold Cross-validation\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Sets all the combinations of the entire set of parameters\n",
    "#data_handler.set_params_combinations(params=param_space[dataset_i])\n",
    "\n",
    "# Gets the list with the combinations of all the parameters\n",
    "#params_combinations = data_handler.get_params_combinations()\n",
    "\n",
    "# For each iteration we choose the hyperparameters (randomly) and we use them with K-fold CV\n",
    "#for trial, params in enumerate(params_combinations):\n",
    "for trial in range(trials):\n",
    "\n",
    "    # Choose random hyperparameters\n",
    "    params = data_handler.random_dictionary(params=param_space[0])\n",
    "\n",
    "    # Creation of the Neural Network object\n",
    "    nn_i = BinaryNN(params=params, monk_i=trial+1, trial=+1)\n",
    "                    \n",
    "    # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "    for train_index, val_index in kfold.split(X, y):\n",
    "        x_kfold_train, x_kfold_val = X[train_index], X[val_index]\n",
    "        y_kfold_train, y_kfold_val = y[train_index], y[val_index]\n",
    "\n",
    "        nn_i.create_model(n_hidden_layers=1)\n",
    "\n",
    "        nn_i.fit(\n",
    "            x_train=x_kfold_train,\n",
    "            y_train=y_kfold_train,\n",
    "            x_val=x_kfold_val,\n",
    "            y_val=y_kfold_val\n",
    "        )\n",
    "\n",
    "        nn_i.evaluate(\n",
    "            x_train=x_kfold_train,\n",
    "            y_train=y_kfold_train,\n",
    "            x_val=x_kfold_val,\n",
    "            y_val=y_kfold_val\n",
    "        )\n",
    "\n",
    "    # Case of first assignment\n",
    "    if nn is None:\n",
    "        nn = nn_i\n",
    "    \n",
    "    # Print the results of this trial\n",
    "    print(\"\\n------------------ Current Hyperparameters ------------------\")\n",
    "    nn_i.print_training_info()\n",
    "    print(\"------------------ CUP Best Hyperparameters -----------------\")\n",
    "    nn.print_training_info()\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Update best hyperparameters if: no overfitting AND (higher mean VL accuracy OR (equal mean AND\n",
    "    #if nn_i.mean_tr_accuracy-0.1 <= nn_i.mean_vl_accuracy: #\\\n",
    "    #    and (\n",
    "    #        nn.mean_vl_accuracy < nn_i.mean_vl_accuracy \\\n",
    "    #        or (\n",
    "    #            nn.mean_vl_accuracy == nn_i.mean_vl_accuracy \\\n",
    "    #            and nn.mean_tr_accuracy < nn_i.mean_tr_accuracy\n",
    "    #        )\n",
    "    #    ):\n",
    "        #nn = nn_i\n",
    "    \n",
    "    # Case of higher mean VL accuracy AND NO Overfitting\n",
    "    if nn_i.mean_vl_accuracy < nn.mean_vl_accuracy: \n",
    "        #\\\n",
    "        #and (\n",
    "        #    abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < abs(nn.mean_tr_accuracy - nn.mean_vl_accuracy) \\\n",
    "        #    or abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < 0.02\n",
    "        #):\n",
    "        nn = nn_i\n",
    "    \n",
    "    # Exit case\n",
    "    if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy == 1 \\\n",
    "        and nn_i.mean_vl_loss < 0.1 and nn_i.mean_tr_loss < 0.1 \\\n",
    "        and abs(nn_i.mean_vl_loss - nn_i.mean_tr_loss) < 0.01:\n",
    "        nn = nn_i\n",
    "        break\n",
    "\n",
    "# Print output\n",
    "print(f\"### Best Hyperparameters for CUP ###\")\n",
    "nn.print_training_info()\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Best Hyperparameters for CUP ###\n",
      " Monk:                     18\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'hidden_units': 70, 'patience': 30, 'learning_rate': 0.07, 'batch_size': 16, 'epochs': 500, 'weight_decay': 3e-05, 'momentum': 0.07, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
      " Mean Training MSE:        0.14734718650579454\n",
      " Mean Validation MSE:      0.4145717203617096\n",
      " Mean Training MEE:        0.551966392993927\n",
      " Mean Validation MEE:      0.8332421898841857\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print best hyperparameters\n",
    "print(f\"\\n### Best Hyperparameters for CUP ###\")\n",
    "nn.print_training_info()\n",
    "nn.print_plot()\n",
    "\n",
    "\n",
    "# BEST BEST BEST CURVES 'hidden_units': 30, 'patience': 30, 'learning_rate': 0.002, 'batch_size': 65, 'epochs': 350, 'weight_decay': 0.001, 'weight_init': 'glorot_normal', 'momentum': 0.0, 'activation': 'linear', 'output_activation': 'linear'}\n",
    "# Monk:                     6\n",
    "# Trial:                    1\n",
    "# Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.003, 'batch_size': 16, 'epochs': 450, 'weight_decay': 6e-05, 'momentum': 0.5, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
    "# Mean Training MSE:        0.2653432160615921\n",
    "# Mean Validation MSE:      0.48080223202705386\n",
    "# Mean Training MEE:        0.7562257528305054\n",
    "# Mean Validation MEE:      0.965958833694458\n",
    "\n",
    "### Best Hyperparameters for CUP ###\n",
    "#Monk:                     18\n",
    "# Trial:                    1\n",
    "# Hyperparameters:          {'hidden_units': 60, 'patience': 30, 'learning_rate': 0.03, 'batch_size': 32, 'epochs': 400, 'weight_decay': 0.0001, 'momentum': 0.0, 'activation': 'tanh', 'nesterov': False, 'output_activation': 'linear'}\n",
    "# Mean Training MSE:       0.20921985805034637\n",
    "# Mean Validation MSE:     0.4135563313961029\n",
    "# Mean Training MEE:   0.6518718361854553\n",
    "# Mean Validation MEE: 0.8760325312614441\n",
    "\n",
    "### Best Hyperparameters for CUP ###\n",
    "#Monk:                     5\n",
    "# Trial:                    1\n",
    "# Hyperparameters:          {'hidden_units': 64, 'patience': 30, 'learning_rate': 0.03, 'batch_size': 16, 'epochs': 500, 'weight_decay': 1e-05, 'momentum': 0.0001, 'activation': 'tanh', 'nesterov': True, 'output_activation': 'linear'}\n",
    "# Mean Training MSE:        0.14074430167675017\n",
    "# Mean Validation MSE:      0.34424884915351867\n",
    "# Mean Training MEE:        0.560929274559021\n",
    "# Mean Validation MEE:      0.7960572957992553\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 10)\n",
      "(900, 3)\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Mean Euclidean Error (Internal) test set: 0.9\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# Evaluation of the Model\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X = x_internal_test.values\n",
    "y = y_internal_test.values\n",
    "\n",
    "y_pred = nn.predict(x_its=X, y_its=y)\n",
    "\n",
    "# Prints the results obtained\n",
    "#print(nn)\n",
    "\n",
    "print(\"Mean Euclidean Error (Internal) test set:\", round(K.eval(y_pred), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
