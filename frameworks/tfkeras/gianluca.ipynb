{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.metrics import MeanSquaredError\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'frameworks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mframeworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mNN_api\u001b[39;00m \u001b[39mimport\u001b[39;00m pd\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mframeworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mNN_api\u001b[39;00m \u001b[39mimport\u001b[39;00m load_data\n\u001b[1;32m      4\u001b[0m \u001b[39m# Path to the Data sets\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'frameworks'"
     ]
    }
   ],
   "source": [
    "from frameworks.api.NN_api import pd\n",
    "from frameworks.api.NN_api import load_data\n",
    "\n",
    "# Path to the Data sets\n",
    "path_to_monks = '/data/monks/'\n",
    "\n",
    "# Load the Training sets into pandas DataFrames\n",
    "df_train1 = load_data(path_to_monks+'monks-1.train')\n",
    "df_train2 = load_data(path_to_monks+'monks-2.train')\n",
    "df_train3 = load_data(path_to_monks+'monks-3.train')\n",
    "\n",
    "# Load the Test sets into pandas DataFrames\n",
    "df_test1 = load_data(path_to_monks+'monks-1.test')\n",
    "df_test2 = load_data(path_to_monks+'monks-2.test')\n",
    "df_test3 = load_data(path_to_monks+'monks-3.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  col1  col2  col3  col4  col5  col6       id\n",
       "NaN       1     1     1     1     1     3     1   data_5\n",
       "NaN       1     1     1     1     1     3     2   data_6\n",
       "NaN       1     1     1     1     3     2     1  data_19\n",
       "NaN       1     1     1     1     3     3     2  data_22\n",
       "NaN       1     1     1     2     1     2     1  data_27"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  col1  col2  col3  col4  col5  col6       id\n",
       "NaN       0     1     1     1     1     2     2   data_4\n",
       "NaN       0     1     1     1     1     4     1   data_7\n",
       "NaN       0     1     1     1     2     1     1   data_9\n",
       "NaN       0     1     1     1     2     1     2  data_10\n",
       "NaN       0     1     1     1     2     2     1  data_11"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  col1  col2  col3  col4  col5  col6      id\n",
       "NaN       1     1     1     1     1     1     2  data_2\n",
       "NaN       1     1     1     1     1     2     1  data_3\n",
       "NaN       1     1     1     1     1     2     2  data_4\n",
       "NaN       0     1     1     1     1     3     1  data_5\n",
       "NaN       0     1     1     1     1     4     1  data_7"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  col1  col2  col3  col4  col5  col6      id\n",
       "NaN       1     1     1     1     1     1     1  data_1\n",
       "NaN       1     1     1     1     1     1     2  data_2\n",
       "NaN       1     1     1     1     1     2     1  data_3\n",
       "NaN       1     1     1     1     1     2     2  data_4\n",
       "NaN       1     1     1     1     1     3     1  data_5"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  col1  col2  col3  col4  col5  col6      id\n",
       "NaN       0     1     1     1     1     1     1  data_1\n",
       "NaN       0     1     1     1     1     1     2  data_2\n",
       "NaN       0     1     1     1     1     2     1  data_3\n",
       "NaN       0     1     1     1     1     2     2  data_4\n",
       "NaN       0     1     1     1     1     3     1  data_5"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  col1  col2  col3  col4  col5  col6      id\n",
       "NaN       1     1     1     1     1     1     1  data_1\n",
       "NaN       1     1     1     1     1     1     2  data_2\n",
       "NaN       1     1     1     1     1     2     1  data_3\n",
       "NaN       1     1     1     1     1     2     2  data_4\n",
       "NaN       1     1     1     1     1     3     1  data_5"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'split_data' from 'frameworks.api.NN_api' (/Users/gianlucapanzani/Documents/GitHub/Machine_Learning_Project/frameworks/tfkeras/../../frameworks/api/NN_api.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[270], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mframeworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mNN_api\u001b[39;00m \u001b[39mimport\u001b[39;00m split_data\n\u001b[1;32m      3\u001b[0m \u001b[39m# Splits the TR sets into datas and labels\u001b[39;00m\n\u001b[1;32m      4\u001b[0m x_train1, y_train1 \u001b[39m=\u001b[39m split_data(df_train1)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'split_data' from 'frameworks.api.NN_api' (/Users/gianlucapanzani/Documents/GitHub/Machine_Learning_Project/frameworks/tfkeras/../../frameworks/api/NN_api.py)"
     ]
    }
   ],
   "source": [
    "from frameworks.api.NN_api import split_data\n",
    "\n",
    "# Splits the TR sets into datas and labels\n",
    "x_train1, y_train1 = split_data(df_train1)\n",
    "x_train2, y_train2 = split_data(df_train2)\n",
    "x_train3, y_train3 = split_data(df_train3)\n",
    "\n",
    "# Splits the TS sets into datas and labels\n",
    "x_test1, y_test1 = split_data(df_test1)\n",
    "x_test2, y_test2 = split_data(df_test2)\n",
    "x_test3, y_test3 = split_data(df_test3)\n",
    "\n",
    "(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Initializing labels/targets vector\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Drop of the IDs and the targets\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "# Initializing the one-hot DataFrame\n",
    "df_copy = df.copy(deep=True)\n",
    "\n",
    "# Iteration on the columns of the DataFrame\n",
    "for column in df.columns:\n",
    "\n",
    "    # Creation of the one-hot encoding's columns\n",
    "    df_one_hot = pd.get_dummies(df[column], dtype=float)\n",
    "\n",
    "    # Rename the columns\n",
    "    df_one_hot = df_one_hot.set_axis([column+'_'+str(col) for col in df_one_hot.columns], axis=1)\n",
    "\n",
    "    # Drop of the initial column\n",
    "    df_copy.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    # Concatenation of the new columns to the DataFrame\n",
    "    df_copy = pd.concat([df_copy,df_one_hot], axis=1)\n",
    "\n",
    "# Print of the obtained DataFrame\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Parameters' space for Grid Search\n",
    "param_space = {\n",
    "    'input_units': [17],\n",
    "    'hidden_units': [4],\n",
    "    'learning_rate': [0.2, 0.3],\n",
    "    'optimizer': [Adam(beta_1=0.9, beta_2=0.999, learning_rate=0.001, epsilon=1e-08, weight_decay=0)],\n",
    "    'batch_size': [128], #[16, 32, 64],\n",
    "    'epochs': [390],\n",
    "    'weight_decay': [0.002, 0.003],\n",
    "    'momentum': [0.4, 0.5, 0.6],\n",
    "    'loss': [MeanSquaredError()],\n",
    "    'input_activation': ['relu'],\n",
    "    'hidden_activation': ['tanh'],\n",
    "    'output_activation': ['sigmoid'],\n",
    "    'dropout': [0.2],\n",
    "    'metrics': ['accuracy'],\n",
    "    'patience': [50]\n",
    "}\n",
    "\n",
    "# Parameters' space for Grid Search (accuracy=0.89)\n",
    "#param_space = {\n",
    "    #'units': [3, 4],\n",
    "    #'optimizer': ['sgd'],\n",
    "    #'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    #'batch_size': [15, 16, 17],\n",
    "    #'epochs': [1250, 1500, 1750],\n",
    "    #'weight_decay': [0.005, 0.01],\n",
    "    #'momentum': [0.7, 0.8, 0.9],\n",
    "    #'loss': ['binary_crossentropy'] #['log_loss', 'binary_crossentropy']\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_78/bias:0', 'dense_79/bias:0', 'dense_80/kernel:0', 'dense_80/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_81/bias:0', 'dense_82/bias:0', 'dense_83/kernel:0', 'dense_83/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_84/bias:0', 'dense_85/bias:0', 'dense_86/kernel:0', 'dense_86/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_87/bias:0', 'dense_88/bias:0', 'dense_89/kernel:0', 'dense_89/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_90/bias:0', 'dense_91/bias:0', 'dense_92/kernel:0', 'dense_92/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.3, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.002, 'momentum': 0.4, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  0: Units=4, Dropout: 0.2, Learning Rate=0.3, Weight Decay=0.002, Epochs=390, Batch Size=128, Momentum=0.4 \n",
      "Training Accuracy=0.5000, Validation Accuracy=0.8400\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_93/bias:0', 'dense_94/bias:0', 'dense_95/kernel:0', 'dense_95/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_96/bias:0', 'dense_97/bias:0', 'dense_98/kernel:0', 'dense_98/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_99/bias:0', 'dense_100/bias:0', 'dense_101/kernel:0', 'dense_101/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_102/bias:0', 'dense_103/bias:0', 'dense_104/kernel:0', 'dense_104/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_105/bias:0', 'dense_106/bias:0', 'dense_107/kernel:0', 'dense_107/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.3, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.003, 'momentum': 0.4, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  1: Units=4, Dropout: 0.2, Learning Rate=0.3, Weight Decay=0.003, Epochs=390, Batch Size=128, Momentum=0.4 \n",
      "Training Accuracy=0.4758, Validation Accuracy=0.1600\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_108/bias:0', 'dense_109/bias:0', 'dense_110/kernel:0', 'dense_110/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_111/bias:0', 'dense_112/bias:0', 'dense_113/kernel:0', 'dense_113/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_114/bias:0', 'dense_115/bias:0', 'dense_116/kernel:0', 'dense_116/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_117/bias:0', 'dense_118/bias:0', 'dense_119/kernel:0', 'dense_119/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_120/bias:0', 'dense_121/bias:0', 'dense_122/kernel:0', 'dense_122/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.2, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.003, 'momentum': 0.6, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  2: Units=4, Dropout: 0.2, Learning Rate=0.2, Weight Decay=0.003, Epochs=390, Batch Size=128, Momentum=0.6 \n",
      "Training Accuracy=0.4355, Validation Accuracy=0.6000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_123/bias:0', 'dense_124/bias:0', 'dense_125/kernel:0', 'dense_125/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_126/bias:0', 'dense_127/bias:0', 'dense_128/kernel:0', 'dense_128/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_129/bias:0', 'dense_130/bias:0', 'dense_131/kernel:0', 'dense_131/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_132/bias:0', 'dense_133/bias:0', 'dense_134/kernel:0', 'dense_134/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_135/bias:0', 'dense_136/bias:0', 'dense_137/kernel:0', 'dense_137/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.3, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.002, 'momentum': 0.4, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  3: Units=4, Dropout: 0.2, Learning Rate=0.3, Weight Decay=0.002, Epochs=390, Batch Size=128, Momentum=0.4 \n",
      "Training Accuracy=0.5242, Validation Accuracy=0.2800\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_138/bias:0', 'dense_139/bias:0', 'dense_140/kernel:0', 'dense_140/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_141/bias:0', 'dense_142/bias:0', 'dense_143/kernel:0', 'dense_143/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_144/bias:0', 'dense_145/bias:0', 'dense_146/kernel:0', 'dense_146/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_147/bias:0', 'dense_148/bias:0', 'dense_149/kernel:0', 'dense_149/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_150/bias:0', 'dense_151/bias:0', 'dense_152/kernel:0', 'dense_152/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.2, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.002, 'momentum': 0.5, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  4: Units=4, Dropout: 0.2, Learning Rate=0.2, Weight Decay=0.002, Epochs=390, Batch Size=128, Momentum=0.5 \n",
      "Training Accuracy=0.4919, Validation Accuracy=0.8400\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_153/bias:0', 'dense_154/bias:0', 'dense_155/kernel:0', 'dense_155/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_156/bias:0', 'dense_157/bias:0', 'dense_158/kernel:0', 'dense_158/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_159/bias:0', 'dense_160/bias:0', 'dense_161/kernel:0', 'dense_161/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_162/bias:0', 'dense_163/bias:0', 'dense_164/kernel:0', 'dense_164/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_165/bias:0', 'dense_166/bias:0', 'dense_167/kernel:0', 'dense_167/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.2, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.002, 'momentum': 0.4, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  5: Units=4, Dropout: 0.2, Learning Rate=0.2, Weight Decay=0.002, Epochs=390, Batch Size=128, Momentum=0.4 \n",
      "Training Accuracy=0.5081, Validation Accuracy=0.8800\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_168/bias:0', 'dense_169/bias:0', 'dense_170/kernel:0', 'dense_170/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_171/bias:0', 'dense_172/bias:0', 'dense_173/kernel:0', 'dense_173/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_174/bias:0', 'dense_175/bias:0', 'dense_176/kernel:0', 'dense_176/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_177/bias:0', 'dense_178/bias:0', 'dense_179/kernel:0', 'dense_179/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_180/bias:0', 'dense_181/bias:0', 'dense_182/kernel:0', 'dense_182/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.3, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.003, 'momentum': 0.6, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  6: Units=4, Dropout: 0.2, Learning Rate=0.3, Weight Decay=0.003, Epochs=390, Batch Size=128, Momentum=0.6 \n",
      "Training Accuracy=0.4113, Validation Accuracy=0.6000\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_183/bias:0', 'dense_184/bias:0', 'dense_185/kernel:0', 'dense_185/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_186/bias:0', 'dense_187/bias:0', 'dense_188/kernel:0', 'dense_188/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_189/bias:0', 'dense_190/bias:0', 'dense_191/kernel:0', 'dense_191/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_192/bias:0', 'dense_193/bias:0', 'dense_194/kernel:0', 'dense_194/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_195/bias:0', 'dense_196/bias:0', 'dense_197/kernel:0', 'dense_197/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.2, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.003, 'momentum': 0.5, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  7: Units=4, Dropout: 0.2, Learning Rate=0.2, Weight Decay=0.003, Epochs=390, Batch Size=128, Momentum=0.5 \n",
      "Training Accuracy=0.5000, Validation Accuracy=0.8400\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_198/bias:0', 'dense_199/bias:0', 'dense_200/kernel:0', 'dense_200/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_201/bias:0', 'dense_202/bias:0', 'dense_203/kernel:0', 'dense_203/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_204/bias:0', 'dense_205/bias:0', 'dense_206/kernel:0', 'dense_206/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_207/bias:0', 'dense_208/bias:0', 'dense_209/kernel:0', 'dense_209/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_210/bias:0', 'dense_211/bias:0', 'dense_212/kernel:0', 'dense_212/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.3, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.003, 'momentum': 0.6, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  8: Units=4, Dropout: 0.2, Learning Rate=0.3, Weight Decay=0.003, Epochs=390, Batch Size=128, Momentum=0.6 \n",
      "Training Accuracy=0.4597, Validation Accuracy=0.2400\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_213/bias:0', 'dense_214/bias:0', 'dense_215/kernel:0', 'dense_215/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_216/bias:0', 'dense_217/bias:0', 'dense_218/kernel:0', 'dense_218/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/bias:0', 'dense_220/bias:0', 'dense_221/kernel:0', 'dense_221/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_222/bias:0', 'dense_223/bias:0', 'dense_224/kernel:0', 'dense_224/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_225/bias:0', 'dense_226/bias:0', 'dense_227/kernel:0', 'dense_227/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10: Mean Training Accuracy=nan, Mean Validation Accuracy=nan\n",
      "Hyperparameters: {'input_units': 17, 'hidden_units': 4, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x290e9a5d0>, 'learning_rate': 0.2, 'batch_size': 128, 'epochs': 390, 'weight_decay': 0.002, 'momentum': 0.6, 'loss': <keras.src.metrics.regression_metrics.MeanSquaredError object at 0x28a06d710>, 'input_activation': 'relu', 'hidden_activation': 'tanh', 'output_activation': 'sigmoid', 'dropout': 0.2, 'metrics': 'accuracy', 'patience': 50}\n",
      "Trial  9: Units=4, Dropout: 0.2, Learning Rate=0.2, Weight Decay=0.002, Epochs=390, Batch Size=128, Momentum=0.6 \n",
      "Training Accuracy=0.5081, Validation Accuracy=0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/gianlucapanzani/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Assigning new DataFrame to Data set variable\n",
    "X = df_copy.values\n",
    "\n",
    "# K-fold Cross-validation\n",
    "k = 5\n",
    "kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store training and validation accuracies\n",
    "training_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "# Lists to store best hyperparameters\n",
    "best_hyperparameters = {\n",
    "    'trial': 0,\n",
    "    'params': {},\n",
    "    'mean_validation_accuracy': 0\n",
    "}\n",
    "\n",
    "# Number of trials with random combinations\n",
    "num_trials = 10\n",
    "for i in range(num_trials):\n",
    "    \n",
    "    # Random parameters\n",
    "    params = {\n",
    "        'input_units': np.random.choice(param_space['input_units']),\n",
    "        'hidden_units': np.random.choice(param_space['hidden_units']),\n",
    "        'optimizer': np.random.choice(param_space['optimizer']),\n",
    "        'learning_rate': np.random.choice(param_space['learning_rate']),\n",
    "        'batch_size': np.random.choice(param_space['batch_size']),\n",
    "        'epochs': np.random.choice(param_space['epochs']),\n",
    "        'weight_decay': np.random.choice(param_space['weight_decay']),\n",
    "        'momentum': np.random.choice(param_space['momentum']),\n",
    "        'loss': np.random.choice(param_space['loss']),\n",
    "        'input_activation': np.random.choice(param_space['input_activation']),\n",
    "        'hidden_activation': np.random.choice(param_space['hidden_activation']),\n",
    "        'output_activation': np.random.choice(param_space['output_activation']),\n",
    "        'dropout': np.random.choice(param_space['dropout']),\n",
    "        'metrics': np.random.choice(param_space['metrics']),\n",
    "        'patience': np.random.choice(param_space['patience'])\n",
    "    }\n",
    "\n",
    "    # Lists to store fold-wise accuracies\n",
    "    fold_training_accuracies = []\n",
    "    fold_validation_accuracies = []\n",
    "\n",
    "    # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "    for train_index, val_index in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Building the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=params['input_units'], activation=params['input_activation'], kernel_regularizer=l2(params['weight_decay']), use_bias=True))\n",
    "        model.add(Dense(units=params['hidden_units'], activation=params['hidden_activation'], kernel_regularizer=l2(params['weight_decay']), use_bias=True))\n",
    "        #model.add(Dropout(params['dropout']))\n",
    "        model.add(Dense(units=1, activation=params['output_activation']))\n",
    "\n",
    "        # Sets the Loss Function, the Optimizer used in the model and the Metrics used for evaluation\n",
    "        model.compile(\n",
    "            loss_weights=params['loss'],\n",
    "            optimizer=SGD(learning_rate=params['learning_rate'], nesterov=True, weight_decay=params['weight_decay'], momentum=params['momentum']),\n",
    "            metrics=params['metrics']\n",
    "        )\n",
    "\n",
    "        # Sets the Early Stopping for the model\n",
    "        #early_stopping_callback = EarlyStopping(monitor=params['loss'], patience=params['patience'], restore_best_weights=True)\n",
    "\n",
    "        # Training of the model\n",
    "        history = model.fit(\n",
    "            x=X,\n",
    "            y=y,\n",
    "            shuffle=True,\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            #validation_batch_size=params['batch_size'],\n",
    "            validation_split=0.2,\n",
    "            verbose=0,\n",
    "            #callbacks=[early_stopping_callback]\n",
    "        )\n",
    "\n",
    "        # Evaluation of the model\n",
    "        loss, training_accuracy = model.evaluate(X, y, verbose=0)\n",
    "\n",
    "        # Validation accuracy\n",
    "        validation_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    # Calculate mean accuracies across folds for this trial\n",
    "    mean_training_accuracy = np.mean(fold_training_accuracies)\n",
    "    mean_validation_accuracy = np.mean(fold_validation_accuracies)\n",
    "\n",
    "    # Store mean accuracies for this trial\n",
    "    training_accuracies.append(mean_training_accuracy)\n",
    "    validation_accuracies.append(mean_validation_accuracy)\n",
    "\n",
    "    # Print mean accuracies and hyperparameters for this trial\n",
    "    print(f\"Trial {i+1}: Mean Training Accuracy={mean_training_accuracy:.4f}, Mean Validation Accuracy={mean_validation_accuracy:.4f}\")\n",
    "    print(\"Hyperparameters:\", params)\n",
    "\n",
    "    # Update best hyperparameters if current trial has higher validation accuracy\n",
    "    if mean_validation_accuracy > best_hyperparameters['mean_validation_accuracy']:\n",
    "        best_hyperparameters['trial'] = i + 1\n",
    "        best_hyperparameters['params'] = params\n",
    "        best_hyperparameters['mean_validation_accuracy'] = mean_validation_accuracy\n",
    "\n",
    "    # Print the used parameters\n",
    "    print(\n",
    "        f\"Trial {i:>2}: Units={params['hidden_units']}, Dropout: {params['dropout']}, \"\n",
    "        f\"Learning Rate={params['learning_rate']}, Weight Decay={params['weight_decay']}, \"\n",
    "        f\"Epochs={params['epochs']}, Batch Size={params['batch_size']}, \"\n",
    "        f\"Momentum={params['momentum']} \\nTraining Accuracy={training_accuracy:.4f}, \"\n",
    "        f\"Validation Accuracy={validation_accuracy:.4f}\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Mean Training Accuracy: nan\n",
      "Overall Mean Validation Accuracy: nan\n",
      "\n",
      "Best Hyperparameters:\n",
      "Trial: 0\n",
      "Hyperparameters: {}\n",
      "Mean Validation Accuracy: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print overall mean accuracies\n",
    "print(f\"\\nOverall Mean Training Accuracy: {np.mean(training_accuracies):.4f}\")\n",
    "print(f\"Overall Mean Validation Accuracy: {np.mean(validation_accuracies):.4f}\")\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(\"Trial:\", best_hyperparameters['trial'])\n",
    "print(\"Hyperparameters:\", best_hyperparameters['params'])\n",
    "print(\"Mean Validation Accuracy:\", best_hyperparameters['mean_validation_accuracy'])\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
