{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gianlucapanzani/Documents/GitHub/Machine_Learning_Project/frameworks/tfkeras\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>data_432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  col1  col2  col3  col4  col5  col6        id\n",
       "NaN       1     1     1     1     1     1     2    data_2\n",
       "NaN       1     1     1     1     1     2     1    data_3\n",
       "NaN       1     1     1     1     1     2     2    data_4\n",
       "NaN       0     1     1     1     1     3     1    data_5\n",
       "NaN       0     1     1     1     1     4     1    data_7\n",
       "..      ...   ...   ...   ...   ...   ...   ...       ...\n",
       "NaN       0     3     3     2     2     2     2  data_420\n",
       "NaN       0     3     3     2     2     3     2  data_422\n",
       "NaN       0     3     3     2     3     1     1  data_425\n",
       "NaN       0     3     3     2     3     3     2  data_430\n",
       "NaN       0     3     3     2     3     4     2  data_432\n",
       "\n",
       "[122 rows x 8 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a pandas DataFrame\n",
    "print(os.getcwd())\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer=os.getcwd()+'/../../data/monks/monks-3.train',\n",
    "    names=['target', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'id'],\n",
    "    delimiter=' '\n",
    ")\n",
    "\n",
    "# Display the loaded data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1_1</th>\n",
       "      <th>col1_2</th>\n",
       "      <th>col1_3</th>\n",
       "      <th>col2_1</th>\n",
       "      <th>col2_2</th>\n",
       "      <th>col2_3</th>\n",
       "      <th>col3_1</th>\n",
       "      <th>col3_2</th>\n",
       "      <th>col4_1</th>\n",
       "      <th>col4_2</th>\n",
       "      <th>col4_3</th>\n",
       "      <th>col5_1</th>\n",
       "      <th>col5_2</th>\n",
       "      <th>col5_3</th>\n",
       "      <th>col5_4</th>\n",
       "      <th>col6_1</th>\n",
       "      <th>col6_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col1_1  col1_2  col1_3  col2_1  col2_2  col2_3  col3_1  col3_2  col4_1  \\\n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "\n",
       "     col4_2  col4_3  col5_1  col5_2  col5_3  col5_4  col6_1  col6_2  \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     0.0     0.0     1.0  \n",
       "NaN     0.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0  \n",
       "NaN     0.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0  \n",
       "NaN     0.0     0.0     0.0     0.0     1.0     0.0     1.0     0.0  \n",
       "NaN     0.0     0.0     0.0     0.0     0.0     1.0     1.0     0.0  \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0  \n",
       "NaN     1.0     0.0     0.0     0.0     1.0     0.0     0.0     1.0  \n",
       "NaN     0.0     1.0     1.0     0.0     0.0     0.0     1.0     0.0  \n",
       "NaN     0.0     1.0     0.0     0.0     1.0     0.0     0.0     1.0  \n",
       "NaN     0.0     1.0     0.0     0.0     0.0     1.0     0.0     1.0  \n",
       "\n",
       "[122 rows x 17 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing labels/targets vector\n",
    "y = df['target'].values.astype(float)\n",
    "\n",
    "# Drop of the IDs and the targets\n",
    "df = df.drop(columns=['target','id'], axis=1)\n",
    "\n",
    "# Initializing the one-hot DataFrame\n",
    "df_copy = df.copy(deep=True)\n",
    "\n",
    "# Iteration on the columns of the DataFrame\n",
    "for column in df.columns:\n",
    "\n",
    "    # Creation of the one-hot encoding's columns\n",
    "    df_one_hot = pd.get_dummies(df[column], dtype=float)\n",
    "\n",
    "    # Change the name of the columns\n",
    "    df_one_hot = df_one_hot.set_axis([column+'_'+str(col) for col in df_one_hot.columns], axis=1)\n",
    "\n",
    "    # Drop of the initial column\n",
    "    df_copy.drop(labels=column, axis=1, inplace=True)\n",
    "\n",
    "    # Concatenation of the new columns to the DataFrame\n",
    "    df_copy = pd.concat([df_copy,df_one_hot], axis=1)\n",
    "\n",
    "# Print of the obtained DataFrame   col1_2\tcol1_3\t col2_2\tcol2_3  col3_2\tcol3_3  col4_2\tcol4_3\tcol5_2\tcol5_3 col6_2\t\t\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters' space for Grid Search\n",
    "param_space = {\n",
    "    'input_units': [17],\n",
    "    'units': [3, 4],\n",
    "    'optimizer': ['sgd'],\n",
    "    'learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'batch_size': [15, 30, 60, 120],\n",
    "    'epochs': [390],\n",
    "    'weight_decay': [0.001, 0.01, 0.02],\n",
    "    'momentum': [0.4, 0.5, 0.6, 0.7],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'output_activation': ['sigmoid'],\n",
    "    'metrics': ['accuracy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: Mean Training Accuracy=0.9673, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.1, 'batch_size': 120, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.7, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 2: Mean Training Accuracy=0.9447, Mean Validation Accuracy=0.9263\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 60, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 3: Mean Training Accuracy=0.9591, Mean Validation Accuracy=0.9260\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.3, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.5, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 4: Mean Training Accuracy=0.9652, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.1, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.7, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 5: Mean Training Accuracy=0.9611, Mean Validation Accuracy=0.9260\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.2, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.01, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 6: Mean Training Accuracy=0.9508, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 7: Mean Training Accuracy=0.9754, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 120, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.5, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 8: Mean Training Accuracy=0.9569, Mean Validation Accuracy=0.9263\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.5, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 9: Mean Training Accuracy=0.9508, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.2, 'batch_size': 60, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.5, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 10: Mean Training Accuracy=0.9631, Mean Validation Accuracy=0.9260\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.2, 'batch_size': 120, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 11: Mean Training Accuracy=0.9487, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.3, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.7, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 12: Mean Training Accuracy=0.9591, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.2, 'batch_size': 120, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.7, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 13: Mean Training Accuracy=0.9426, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.1, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.6, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 14: Mean Training Accuracy=0.9529, Mean Validation Accuracy=0.9260\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.1, 'batch_size': 120, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 15: Mean Training Accuracy=0.9060, Mean Validation Accuracy=0.8343\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.1, 'batch_size': 120, 'epochs': 390, 'weight_decay': 0.01, 'momentum': 0.5, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 16: Mean Training Accuracy=0.9693, Mean Validation Accuracy=0.9180\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 120, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.4, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 17: Mean Training Accuracy=0.9467, Mean Validation Accuracy=0.9263\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.5, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 18: Mean Training Accuracy=0.9446, Mean Validation Accuracy=0.9263\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.3, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.5, 'activation': 'tanh', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 19: Mean Training Accuracy=0.9673, Mean Validation Accuracy=0.9180\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.1, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.01, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 20: Mean Training Accuracy=0.9673, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.2, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 21: Mean Training Accuracy=0.9488, Mean Validation Accuracy=0.9263\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 22: Mean Training Accuracy=0.9632, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.2, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 23: Mean Training Accuracy=0.9734, Mean Validation Accuracy=0.9343\n",
      "Hyperparameters: {'input_units': 17, 'units': 4, 'optimizer': 'sgd', 'learning_rate': 0.1, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.4, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 24: Mean Training Accuracy=0.9529, Mean Validation Accuracy=0.9347\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Trial 25: Mean Training Accuracy=0.9467, Mean Validation Accuracy=0.9180\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 30, 'epochs': 390, 'weight_decay': 0.02, 'momentum': 0.4, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "\n",
      "Best Hyperparameters:\n",
      "Trial: 24\n",
      "Hyperparameters: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n",
      "Mean Training Accuracy: 0.9528508424758911\n",
      "Mean Validation Accuracy: 0.934666657447815\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assigning new DataFrame to Data set variable\n",
    "X = df_copy.values\n",
    "\n",
    "# Number of trials with random combinations\n",
    "num_trials = 25\n",
    "\n",
    "# K-fold Cross-validation\n",
    "k = 5\n",
    "kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store training and validation accuracies\n",
    "trials_training_accuracies = []\n",
    "trials_validation_accuracies = []\n",
    "\n",
    "# Lists to store best hyperparameters\n",
    "best_hyperparameters = {\n",
    "    'trial': 0,\n",
    "    'params': {},\n",
    "    'mean_training_accuracy': 0, \n",
    "    'mean_validation_accuracy': 0\n",
    "}\n",
    "\n",
    "# For each iteration we choose the hyperparameters (randomly) and we use them with K-fold CV\n",
    "for i in range(num_trials):\n",
    "    \n",
    "    # Random parameters\n",
    "    params = {\n",
    "        'input_units': np.random.choice(param_space['input_units']),\n",
    "        'units': np.random.choice(param_space['units']),\n",
    "        'optimizer': np.random.choice(param_space['optimizer']),\n",
    "        'learning_rate': np.random.choice(param_space['learning_rate']),\n",
    "        'batch_size': np.random.choice(param_space['batch_size']),\n",
    "        'epochs': np.random.choice(param_space['epochs']),\n",
    "        'weight_decay': np.random.choice(param_space['weight_decay']),\n",
    "        'momentum': np.random.choice(param_space['momentum']),\n",
    "        'activation': np.random.choice(param_space['activation']),\n",
    "        'output_activation': np.random.choice(param_space['output_activation']),\n",
    "        'metrics': np.random.choice(param_space['metrics']),\n",
    "    }\n",
    "\n",
    "    # Lists to store fold-wise accuracies\n",
    "    fold_training_accuracies = []\n",
    "    fold_validation_accuracies = []\n",
    "\n",
    "    # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "    for train_index, val_index in kfold.split(X, y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=params['input_units'], activation=params['activation'], use_bias=True))\n",
    "        model.add(Dense(units=params['units'], activation=params['activation'], use_bias=True))\n",
    "        model.add(Dense(units=1, activation=params['output_activation'], use_bias=True))\n",
    "\n",
    "        # Set the optimizer with the sampled learning rate\n",
    "        opt = optimizers.legacy.SGD(learning_rate=params['learning_rate'], momentum=params['momentum'])\n",
    "\n",
    "        # Sets the Loss Function, the Optimizer used in the model, and the Metrics used for evaluation\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[params['metrics']])\n",
    "\n",
    "        # Set the Early Stopping for the model\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Training of the model with validation split and early stopping\n",
    "        history = model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train,\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping],  # Add early stopping callback\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Evaluate on both training and validation sets\n",
    "        training_loss, training_accuracy     = model.evaluate(X_train, y_train, verbose=0)\n",
    "        validation_loss, validation_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "        # Add the TR accuracy and VL accuracy to the lists (to compute the mean)\n",
    "        fold_training_accuracies.append(training_accuracy)\n",
    "        fold_validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "    # Calculate the Mean of the Accuracies (for this trial)\n",
    "    mean_training_accuracy_i = np.mean(fold_training_accuracies)\n",
    "    mean_validation_accuracy_i = np.mean(fold_validation_accuracies)\n",
    "\n",
    "    # Store the Mean of the Accuracies for each Trail\n",
    "    trials_training_accuracies.append(mean_training_accuracy_i)\n",
    "    trials_validation_accuracies.append(mean_validation_accuracy_i)\n",
    "\n",
    "    # Print mean accuracies and hyperparameters for this trial\n",
    "    print(f\"Trial {i+1}: Mean Training Accuracy={mean_training_accuracy_i:.4f}, Mean Validation Accuracy={mean_validation_accuracy_i:.4f}\")\n",
    "    print(\"Hyperparameters:\", params)\n",
    "\n",
    "    # Update best hyperparameters if current trial has higher validation accuracy\n",
    "    if mean_validation_accuracy_i > best_hyperparameters['mean_validation_accuracy']:\n",
    "        best_hyperparameters['trial'] = i + 1\n",
    "        best_hyperparameters['params'] = params\n",
    "        best_hyperparameters['mean_training_accuracy'] = mean_training_accuracy_i\n",
    "        best_hyperparameters['mean_validation_accuracy'] = mean_validation_accuracy_i\n",
    "    \n",
    "    # Case of best Hyperparameters already found\n",
    "    if best_hyperparameters['mean_validation_accuracy'] == 1:\n",
    "        break\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(\"Trial:\", best_hyperparameters['trial'])\n",
    "print(\"Hyperparameters:\", best_hyperparameters['params'])\n",
    "print(\"Mean Training Accuracy:\", best_hyperparameters['mean_training_accuracy'])\n",
    "print(\"Mean Validation Accuracy:\", best_hyperparameters['mean_validation_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x436b77550>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters selected: {'input_units': 17, 'units': 3, 'optimizer': 'sgd', 'learning_rate': 0.4, 'batch_size': 15, 'epochs': 390, 'weight_decay': 0.001, 'momentum': 0.6, 'activation': 'relu', 'output_activation': 'sigmoid', 'metrics': 'accuracy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Lists to store fold-wise accuracies\\nfold_training_accuracies = []\\nfold_validation_accuracies = []\\n\\n# For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\\nfor train_index, val_index in kfold.split(X, y):\\n    X_train, X_val = X[train_index], X[val_index]\\n    y_train, y_val = y[train_index], y[val_index]\\n\\n    # Training of the model with validation split and early stopping\\n    history = model.fit(\\n        x=X_train,\\n        y=y_train,\\n        epochs=params[\\'epochs\\'],\\n        batch_size=params[\\'batch_size\\'],\\n        validation_data=(X_val, y_val),\\n        callbacks=[early_stopping],  # Add early stopping callback\\n        verbose=0\\n    )\\n\\n    # Evaluate on both training and validation sets\\n    training_loss, training_accuracy     = model.evaluate(X_train, y_train, verbose=0)\\n    validation_loss, validation_accuracy = model.evaluate(X_val, y_val, verbose=0)\\n\\n    # Add the TR accuracy and VL accuracy to the lists (to compute the mean)\\n    fold_training_accuracies.append(training_accuracy)\\n    fold_validation_accuracies.append(validation_accuracy)\\n\\n# Calculate the Mean of the Accuracies (for this trial)\\nmean_training_accuracy_i = np.mean(fold_training_accuracies)\\nmean_validation_accuracy_i = np.mean(fold_validation_accuracies)\\n\\n# Print mean accuracies and hyperparameters for this trial\\nprint(f\"Mean Training Accuracy={mean_training_accuracy_i:.4f}, Mean Validation Accuracy={mean_validation_accuracy_i:.4f}\")\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best Hyperparameters selected\n",
    "print(f\"Hyperparameters selected: {best_hyperparameters['params']}\")\n",
    "\n",
    "# Best parameters\n",
    "params = {\n",
    "    'input_units': best_hyperparameters['params']['input_units'],\n",
    "    'units': best_hyperparameters['params']['units'],\n",
    "    'optimizer': best_hyperparameters['params']['optimizer'],\n",
    "    'learning_rate': best_hyperparameters['params']['learning_rate'],\n",
    "    'batch_size': best_hyperparameters['params']['batch_size'],\n",
    "    'epochs': best_hyperparameters['params']['epochs'],\n",
    "    'weight_decay': best_hyperparameters['params']['weight_decay'],\n",
    "    'momentum': best_hyperparameters['params']['momentum'],\n",
    "    'activation': best_hyperparameters['params']['activation'],\n",
    "    'metrics': best_hyperparameters['params']['metrics']\n",
    "}\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=params['input_units'], activation=params['activation'], use_bias=True))\n",
    "model.add(Dense(units=params['units'], activation=params['activation'], use_bias=True))\n",
    "model.add(Dense(units=1, activation='sigmoid', use_bias=True))\n",
    "\n",
    "# Set the optimizer with the sampled learning rate\n",
    "opt = optimizers.legacy.SGD(learning_rate=params['learning_rate'], momentum=params['momentum'])\n",
    "\n",
    "# Sets the Loss Function, the Optimizer used in the model, and the Metrics used for evaluation\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[params['metrics']])\n",
    "\n",
    "# Set the Early Stopping for the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "'''\n",
    "# Lists to store fold-wise accuracies\n",
    "fold_training_accuracies = []\n",
    "fold_validation_accuracies = []\n",
    "\n",
    "# For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "for train_index, val_index in kfold.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Training of the model with validation split and early stopping\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping],  # Add early stopping callback\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate on both training and validation sets\n",
    "    training_loss, training_accuracy     = model.evaluate(X_train, y_train, verbose=0)\n",
    "    validation_loss, validation_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    # Add the TR accuracy and VL accuracy to the lists (to compute the mean)\n",
    "    fold_training_accuracies.append(training_accuracy)\n",
    "    fold_validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "# Calculate the Mean of the Accuracies (for this trial)\n",
    "mean_training_accuracy_i = np.mean(fold_training_accuracies)\n",
    "mean_validation_accuracy_i = np.mean(fold_validation_accuracies)\n",
    "\n",
    "# Print mean accuracies and hyperparameters for this trial\n",
    "print(f\"Mean Training Accuracy={mean_training_accuracy_i:.4f}, Mean Validation Accuracy={mean_validation_accuracy_i:.4f}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gianlucapanzani/Documents/GitHub/Machine_Learning_Project/frameworks/tfkeras\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      target  col1  col2  col3  col4  col5  col6        id\n",
       "NaN       1     1     1     1     1     1     1    data_1\n",
       "NaN       1     1     1     1     1     1     2    data_2\n",
       "NaN       1     1     1     1     1     2     1    data_3\n",
       "NaN       1     1     1     1     1     2     2    data_4\n",
       "NaN       1     1     1     1     1     3     1    data_5\n",
       "..      ...   ...   ...   ...   ...   ...   ...       ...\n",
       "NaN       0     3     3     2     3     2     2  data_428\n",
       "NaN       0     3     3     2     3     3     1  data_429\n",
       "NaN       0     3     3     2     3     3     2  data_430\n",
       "NaN       0     3     3     2     3     4     1  data_431\n",
       "NaN       0     3     3     2     3     4     2  data_432\n",
       "\n",
       "[432 rows x 8 columns]>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Test set into a pandas DataFrame\n",
    "print(os.getcwd())\n",
    "df_test = pd.read_csv(\n",
    "    filepath_or_buffer=os.getcwd()+'/../../data/monks/monks-3.test',\n",
    "    names=['target', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'id'],\n",
    "    delimiter=' '\n",
    ")\n",
    "\n",
    "# Display the loaded data\n",
    "df_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1_1</th>\n",
       "      <th>col1_2</th>\n",
       "      <th>col1_3</th>\n",
       "      <th>col2_1</th>\n",
       "      <th>col2_2</th>\n",
       "      <th>col2_3</th>\n",
       "      <th>col3_1</th>\n",
       "      <th>col3_2</th>\n",
       "      <th>col4_1</th>\n",
       "      <th>col4_2</th>\n",
       "      <th>col4_3</th>\n",
       "      <th>col5_1</th>\n",
       "      <th>col5_2</th>\n",
       "      <th>col5_3</th>\n",
       "      <th>col5_4</th>\n",
       "      <th>col6_1</th>\n",
       "      <th>col6_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     col1_1  col1_2  col1_3  col2_1  col2_2  col2_3  col3_1  col3_2  col4_1  \\\n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "NaN     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "\n",
       "     col4_2  col4_3  col5_1  col5_2  col5_3  col5_4  col6_1  col6_2  \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     0.0     1.0     0.0  \n",
       "NaN     0.0     0.0     1.0     0.0     0.0     0.0     0.0     1.0  \n",
       "NaN     0.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0  \n",
       "NaN     0.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0  \n",
       "NaN     0.0     0.0     0.0     0.0     1.0     0.0     1.0     0.0  \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "NaN     0.0     1.0     0.0     1.0     0.0     0.0     0.0     1.0  \n",
       "NaN     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0  \n",
       "NaN     0.0     1.0     0.0     0.0     1.0     0.0     0.0     1.0  \n",
       "NaN     0.0     1.0     0.0     0.0     0.0     1.0     1.0     0.0  \n",
       "NaN     0.0     1.0     0.0     0.0     0.0     1.0     0.0     1.0  \n",
       "\n",
       "[432 rows x 17 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing labels/targets vector\n",
    "y_test = df_test['target'].values.astype(float)\n",
    "\n",
    "# Drop of the IDs and the targets\n",
    "df_test = df_test.drop(columns=['target','id'], axis=1)\n",
    "\n",
    "# Initializing the one-hot DataFrame\n",
    "df_copy_test = df_test.copy(deep=True)\n",
    "\n",
    "# Iteration on the columns of the DataFrame\n",
    "for column in df_test.columns:\n",
    "\n",
    "    # Creation of the one-hot encoding's columns\n",
    "    df_one_hot = pd.get_dummies(df_test[column], dtype=float)\n",
    "\n",
    "    # Change the name of the columns\n",
    "    df_one_hot = df_one_hot.set_axis([column+'_'+str(col) for col in df_one_hot.columns], axis=1)\n",
    "\n",
    "    # Drop of the initial column\n",
    "    df_copy_test.drop(labels=column, axis=1, inplace=True)\n",
    "\n",
    "    # Concatenation of the new columns to the DataFrame\n",
    "    df_copy_test = pd.concat([df_copy_test,df_one_hot], axis=1)\n",
    "\n",
    "# Print of the obtained DataFrame\n",
    "df_copy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1328e-06 - accuracy: 1.0000 - val_loss: 6.7884e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/390\n",
      "29/29 [==============================] - 0s 701us/step - loss: 4.1208e-06 - accuracy: 1.0000 - val_loss: 6.7687e-06 - val_accuracy: 1.0000\n",
      "Epoch 3/390\n",
      "29/29 [==============================] - 0s 717us/step - loss: 4.1083e-06 - accuracy: 1.0000 - val_loss: 6.7492e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/390\n",
      "29/29 [==============================] - 0s 651us/step - loss: 4.0956e-06 - accuracy: 1.0000 - val_loss: 6.7288e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/390\n",
      "29/29 [==============================] - 0s 667us/step - loss: 4.0837e-06 - accuracy: 1.0000 - val_loss: 6.7085e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/390\n",
      "29/29 [==============================] - 0s 647us/step - loss: 4.0727e-06 - accuracy: 1.0000 - val_loss: 6.6897e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/390\n",
      "29/29 [==============================] - 0s 693us/step - loss: 4.0605e-06 - accuracy: 1.0000 - val_loss: 6.6694e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/390\n",
      "29/29 [==============================] - 0s 681us/step - loss: 4.0480e-06 - accuracy: 1.0000 - val_loss: 6.6498e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/390\n",
      "29/29 [==============================] - 0s 645us/step - loss: 4.0360e-06 - accuracy: 1.0000 - val_loss: 6.6297e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/390\n",
      "29/29 [==============================] - 0s 657us/step - loss: 4.0247e-06 - accuracy: 1.0000 - val_loss: 6.6108e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/390\n",
      "29/29 [==============================] - 0s 760us/step - loss: 4.0138e-06 - accuracy: 1.0000 - val_loss: 6.5917e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/390\n",
      "29/29 [==============================] - 0s 699us/step - loss: 4.0018e-06 - accuracy: 1.0000 - val_loss: 6.5731e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/390\n",
      "29/29 [==============================] - 0s 676us/step - loss: 3.9908e-06 - accuracy: 1.0000 - val_loss: 6.5535e-06 - val_accuracy: 1.0000\n",
      "Epoch 14/390\n",
      "29/29 [==============================] - 0s 726us/step - loss: 3.9780e-06 - accuracy: 1.0000 - val_loss: 6.5346e-06 - val_accuracy: 1.0000\n",
      "Epoch 15/390\n",
      "29/29 [==============================] - 0s 705us/step - loss: 3.9675e-06 - accuracy: 1.0000 - val_loss: 6.5159e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/390\n",
      "29/29 [==============================] - 0s 685us/step - loss: 3.9555e-06 - accuracy: 1.0000 - val_loss: 6.4977e-06 - val_accuracy: 1.0000\n",
      "Epoch 17/390\n",
      "29/29 [==============================] - 0s 656us/step - loss: 3.9446e-06 - accuracy: 1.0000 - val_loss: 6.4780e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/390\n",
      "29/29 [==============================] - 0s 639us/step - loss: 3.9340e-06 - accuracy: 1.0000 - val_loss: 6.4592e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 3.9237e-06 - accuracy: 1.0000 - val_loss: 6.4418e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 3.9117e-06 - accuracy: 1.0000 - val_loss: 6.4226e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 3.9004e-06 - accuracy: 1.0000 - val_loss: 6.4055e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/390\n",
      "29/29 [==============================] - 0s 609us/step - loss: 3.8893e-06 - accuracy: 1.0000 - val_loss: 6.3864e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/390\n",
      "29/29 [==============================] - 0s 627us/step - loss: 3.8783e-06 - accuracy: 1.0000 - val_loss: 6.3687e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 3.8680e-06 - accuracy: 1.0000 - val_loss: 6.3508e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.8570e-06 - accuracy: 1.0000 - val_loss: 6.3330e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8456e-06 - accuracy: 1.0000 - val_loss: 6.3158e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/390\n",
      "29/29 [==============================] - 0s 730us/step - loss: 3.8351e-06 - accuracy: 1.0000 - val_loss: 6.2980e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.8259e-06 - accuracy: 1.0000 - val_loss: 6.2796e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/390\n",
      "29/29 [==============================] - 0s 690us/step - loss: 3.8147e-06 - accuracy: 1.0000 - val_loss: 6.2620e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/390\n",
      "29/29 [==============================] - 0s 706us/step - loss: 3.8036e-06 - accuracy: 1.0000 - val_loss: 6.2449e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/390\n",
      "29/29 [==============================] - 0s 704us/step - loss: 3.7940e-06 - accuracy: 1.0000 - val_loss: 6.2281e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/390\n",
      "29/29 [==============================] - 0s 661us/step - loss: 3.7827e-06 - accuracy: 1.0000 - val_loss: 6.2104e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/390\n",
      "29/29 [==============================] - 0s 651us/step - loss: 3.7728e-06 - accuracy: 1.0000 - val_loss: 6.1936e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/390\n",
      "29/29 [==============================] - 0s 663us/step - loss: 3.7625e-06 - accuracy: 1.0000 - val_loss: 6.1759e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/390\n",
      "29/29 [==============================] - 0s 692us/step - loss: 3.7531e-06 - accuracy: 1.0000 - val_loss: 6.1604e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/390\n",
      "29/29 [==============================] - 0s 667us/step - loss: 3.7418e-06 - accuracy: 1.0000 - val_loss: 6.1423e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/390\n",
      "29/29 [==============================] - 0s 676us/step - loss: 3.7315e-06 - accuracy: 1.0000 - val_loss: 6.1256e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/390\n",
      "29/29 [==============================] - 0s 744us/step - loss: 3.7219e-06 - accuracy: 1.0000 - val_loss: 6.1092e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/390\n",
      "29/29 [==============================] - 0s 697us/step - loss: 3.7117e-06 - accuracy: 1.0000 - val_loss: 6.0929e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 3.7016e-06 - accuracy: 1.0000 - val_loss: 6.0763e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/390\n",
      "29/29 [==============================] - 0s 634us/step - loss: 3.6919e-06 - accuracy: 1.0000 - val_loss: 6.0613e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 3.6818e-06 - accuracy: 1.0000 - val_loss: 6.0437e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 3.6719e-06 - accuracy: 1.0000 - val_loss: 6.0281e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/390\n",
      "29/29 [==============================] - 0s 596us/step - loss: 3.6623e-06 - accuracy: 1.0000 - val_loss: 6.0110e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/390\n",
      "29/29 [==============================] - 0s 598us/step - loss: 3.6533e-06 - accuracy: 1.0000 - val_loss: 5.9954e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/390\n",
      "29/29 [==============================] - 0s 611us/step - loss: 3.6426e-06 - accuracy: 1.0000 - val_loss: 5.9790e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 3.6332e-06 - accuracy: 1.0000 - val_loss: 5.9632e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/390\n",
      "29/29 [==============================] - 0s 626us/step - loss: 3.6230e-06 - accuracy: 1.0000 - val_loss: 5.9473e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 3.6143e-06 - accuracy: 1.0000 - val_loss: 5.9315e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/390\n",
      "29/29 [==============================] - 0s 629us/step - loss: 3.6040e-06 - accuracy: 1.0000 - val_loss: 5.9158e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/390\n",
      "29/29 [==============================] - 0s 606us/step - loss: 3.5947e-06 - accuracy: 1.0000 - val_loss: 5.9003e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.5853e-06 - accuracy: 1.0000 - val_loss: 5.8854e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/390\n",
      "29/29 [==============================] - 0s 912us/step - loss: 3.5765e-06 - accuracy: 1.0000 - val_loss: 5.8696e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 3.5674e-06 - accuracy: 1.0000 - val_loss: 5.8537e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/390\n",
      "29/29 [==============================] - 0s 644us/step - loss: 3.5579e-06 - accuracy: 1.0000 - val_loss: 5.8378e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/390\n",
      "29/29 [==============================] - 0s 658us/step - loss: 3.5485e-06 - accuracy: 1.0000 - val_loss: 5.8240e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/390\n",
      "29/29 [==============================] - 0s 753us/step - loss: 3.5390e-06 - accuracy: 1.0000 - val_loss: 5.8074e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/390\n",
      "29/29 [==============================] - 0s 721us/step - loss: 3.5309e-06 - accuracy: 1.0000 - val_loss: 5.7930e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/390\n",
      "29/29 [==============================] - 0s 672us/step - loss: 3.5208e-06 - accuracy: 1.0000 - val_loss: 5.7779e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/390\n",
      "29/29 [==============================] - 0s 702us/step - loss: 3.5118e-06 - accuracy: 1.0000 - val_loss: 5.7627e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/390\n",
      "29/29 [==============================] - 0s 658us/step - loss: 3.5031e-06 - accuracy: 1.0000 - val_loss: 5.7482e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/390\n",
      "29/29 [==============================] - 0s 667us/step - loss: 3.4939e-06 - accuracy: 1.0000 - val_loss: 5.7341e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 3.4853e-06 - accuracy: 1.0000 - val_loss: 5.7185e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/390\n",
      "29/29 [==============================] - 0s 666us/step - loss: 3.4769e-06 - accuracy: 1.0000 - val_loss: 5.7043e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/390\n",
      "29/29 [==============================] - 0s 699us/step - loss: 3.4684e-06 - accuracy: 1.0000 - val_loss: 5.6898e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/390\n",
      "29/29 [==============================] - 0s 695us/step - loss: 3.4596e-06 - accuracy: 1.0000 - val_loss: 5.6754e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/390\n",
      "29/29 [==============================] - 0s 689us/step - loss: 3.4498e-06 - accuracy: 1.0000 - val_loss: 5.6604e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 3.4417e-06 - accuracy: 1.0000 - val_loss: 5.6468e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/390\n",
      "29/29 [==============================] - 0s 638us/step - loss: 3.4329e-06 - accuracy: 1.0000 - val_loss: 5.6320e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/390\n",
      "29/29 [==============================] - 0s 602us/step - loss: 3.4247e-06 - accuracy: 1.0000 - val_loss: 5.6179e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/390\n",
      "29/29 [==============================] - 0s 605us/step - loss: 3.4157e-06 - accuracy: 1.0000 - val_loss: 5.6037e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 3.4071e-06 - accuracy: 1.0000 - val_loss: 5.5895e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 3.3992e-06 - accuracy: 1.0000 - val_loss: 5.5756e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3898e-06 - accuracy: 1.0000 - val_loss: 5.5624e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/390\n",
      "29/29 [==============================] - 0s 682us/step - loss: 3.3816e-06 - accuracy: 1.0000 - val_loss: 5.5480e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/390\n",
      "29/29 [==============================] - 0s 648us/step - loss: 3.3732e-06 - accuracy: 1.0000 - val_loss: 5.5335e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 3.3645e-06 - accuracy: 1.0000 - val_loss: 5.5204e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/390\n",
      "29/29 [==============================] - 0s 663us/step - loss: 3.3568e-06 - accuracy: 1.0000 - val_loss: 5.5054e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/390\n",
      "29/29 [==============================] - 0s 663us/step - loss: 3.3481e-06 - accuracy: 1.0000 - val_loss: 5.4922e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/390\n",
      "29/29 [==============================] - 0s 681us/step - loss: 3.3401e-06 - accuracy: 1.0000 - val_loss: 5.4784e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/390\n",
      "29/29 [==============================] - 0s 673us/step - loss: 3.3320e-06 - accuracy: 1.0000 - val_loss: 5.4646e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/390\n",
      "29/29 [==============================] - 0s 700us/step - loss: 3.3240e-06 - accuracy: 1.0000 - val_loss: 5.4512e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/390\n",
      "29/29 [==============================] - 0s 698us/step - loss: 3.3159e-06 - accuracy: 1.0000 - val_loss: 5.4385e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/390\n",
      "29/29 [==============================] - 0s 705us/step - loss: 3.3078e-06 - accuracy: 1.0000 - val_loss: 5.4244e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/390\n",
      "29/29 [==============================] - 0s 684us/step - loss: 3.3001e-06 - accuracy: 1.0000 - val_loss: 5.4117e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/390\n",
      "29/29 [==============================] - 0s 691us/step - loss: 3.2918e-06 - accuracy: 1.0000 - val_loss: 5.3983e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/390\n",
      "29/29 [==============================] - 0s 667us/step - loss: 3.2849e-06 - accuracy: 1.0000 - val_loss: 5.3846e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/390\n",
      "29/29 [==============================] - 0s 750us/step - loss: 3.2761e-06 - accuracy: 1.0000 - val_loss: 5.3719e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/390\n",
      "29/29 [==============================] - 0s 742us/step - loss: 3.2688e-06 - accuracy: 1.0000 - val_loss: 5.3587e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/390\n",
      "29/29 [==============================] - 0s 781us/step - loss: 3.2605e-06 - accuracy: 1.0000 - val_loss: 5.3449e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/390\n",
      "29/29 [==============================] - 0s 735us/step - loss: 3.2536e-06 - accuracy: 1.0000 - val_loss: 5.3324e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/390\n",
      "29/29 [==============================] - 0s 684us/step - loss: 3.2450e-06 - accuracy: 1.0000 - val_loss: 5.3198e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/390\n",
      "29/29 [==============================] - 0s 647us/step - loss: 3.2371e-06 - accuracy: 1.0000 - val_loss: 5.3067e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/390\n",
      "29/29 [==============================] - 0s 668us/step - loss: 3.2296e-06 - accuracy: 1.0000 - val_loss: 5.2941e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/390\n",
      "29/29 [==============================] - 0s 690us/step - loss: 3.2226e-06 - accuracy: 1.0000 - val_loss: 5.2813e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 3.2147e-06 - accuracy: 1.0000 - val_loss: 5.2689e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2069e-06 - accuracy: 1.0000 - val_loss: 5.2566e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/390\n",
      "29/29 [==============================] - 0s 670us/step - loss: 3.1994e-06 - accuracy: 1.0000 - val_loss: 5.2437e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/390\n",
      "29/29 [==============================] - 0s 645us/step - loss: 3.1921e-06 - accuracy: 1.0000 - val_loss: 5.2311e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 3.1852e-06 - accuracy: 1.0000 - val_loss: 5.2190e-06 - val_accuracy: 1.0000\n",
      "Epoch 101/390\n",
      "29/29 [==============================] - 0s 652us/step - loss: 3.1777e-06 - accuracy: 1.0000 - val_loss: 5.2064e-06 - val_accuracy: 1.0000\n",
      "Epoch 102/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 3.1699e-06 - accuracy: 1.0000 - val_loss: 5.1940e-06 - val_accuracy: 1.0000\n",
      "Epoch 103/390\n",
      "29/29 [==============================] - 0s 629us/step - loss: 3.1622e-06 - accuracy: 1.0000 - val_loss: 5.1818e-06 - val_accuracy: 1.0000\n",
      "Epoch 104/390\n",
      "29/29 [==============================] - 0s 629us/step - loss: 3.1554e-06 - accuracy: 1.0000 - val_loss: 5.1700e-06 - val_accuracy: 1.0000\n",
      "Epoch 105/390\n",
      "29/29 [==============================] - 0s 637us/step - loss: 3.1473e-06 - accuracy: 1.0000 - val_loss: 5.1573e-06 - val_accuracy: 1.0000\n",
      "Epoch 106/390\n",
      "29/29 [==============================] - 0s 621us/step - loss: 3.1401e-06 - accuracy: 1.0000 - val_loss: 5.1453e-06 - val_accuracy: 1.0000\n",
      "Epoch 107/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 3.1332e-06 - accuracy: 1.0000 - val_loss: 5.1337e-06 - val_accuracy: 1.0000\n",
      "Epoch 108/390\n",
      "29/29 [==============================] - 0s 627us/step - loss: 3.1255e-06 - accuracy: 1.0000 - val_loss: 5.1207e-06 - val_accuracy: 1.0000\n",
      "Epoch 109/390\n",
      "29/29 [==============================] - 0s 653us/step - loss: 3.1190e-06 - accuracy: 1.0000 - val_loss: 5.1092e-06 - val_accuracy: 1.0000\n",
      "Epoch 110/390\n",
      "29/29 [==============================] - 0s 627us/step - loss: 3.1115e-06 - accuracy: 1.0000 - val_loss: 5.0970e-06 - val_accuracy: 1.0000\n",
      "Epoch 111/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 3.1044e-06 - accuracy: 1.0000 - val_loss: 5.0857e-06 - val_accuracy: 1.0000\n",
      "Epoch 112/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 3.0974e-06 - accuracy: 1.0000 - val_loss: 5.0735e-06 - val_accuracy: 1.0000\n",
      "Epoch 113/390\n",
      "29/29 [==============================] - 0s 640us/step - loss: 3.0901e-06 - accuracy: 1.0000 - val_loss: 5.0622e-06 - val_accuracy: 1.0000\n",
      "Epoch 114/390\n",
      "29/29 [==============================] - 0s 610us/step - loss: 3.0833e-06 - accuracy: 1.0000 - val_loss: 5.0506e-06 - val_accuracy: 1.0000\n",
      "Epoch 115/390\n",
      "29/29 [==============================] - 0s 633us/step - loss: 3.0762e-06 - accuracy: 1.0000 - val_loss: 5.0383e-06 - val_accuracy: 1.0000\n",
      "Epoch 116/390\n",
      "29/29 [==============================] - 0s 621us/step - loss: 3.0697e-06 - accuracy: 1.0000 - val_loss: 5.0272e-06 - val_accuracy: 1.0000\n",
      "Epoch 117/390\n",
      "29/29 [==============================] - 0s 628us/step - loss: 3.0622e-06 - accuracy: 1.0000 - val_loss: 5.0156e-06 - val_accuracy: 1.0000\n",
      "Epoch 118/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 3.0553e-06 - accuracy: 1.0000 - val_loss: 5.0040e-06 - val_accuracy: 1.0000\n",
      "Epoch 119/390\n",
      "29/29 [==============================] - 0s 763us/step - loss: 3.0483e-06 - accuracy: 1.0000 - val_loss: 4.9928e-06 - val_accuracy: 1.0000\n",
      "Epoch 120/390\n",
      "29/29 [==============================] - 0s 775us/step - loss: 3.0420e-06 - accuracy: 1.0000 - val_loss: 4.9811e-06 - val_accuracy: 1.0000\n",
      "Epoch 121/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0352e-06 - accuracy: 1.0000 - val_loss: 4.9698e-06 - val_accuracy: 1.0000\n",
      "Epoch 122/390\n",
      "29/29 [==============================] - 0s 678us/step - loss: 3.0282e-06 - accuracy: 1.0000 - val_loss: 4.9586e-06 - val_accuracy: 1.0000\n",
      "Epoch 123/390\n",
      "29/29 [==============================] - 0s 669us/step - loss: 3.0214e-06 - accuracy: 1.0000 - val_loss: 4.9480e-06 - val_accuracy: 1.0000\n",
      "Epoch 124/390\n",
      "29/29 [==============================] - 0s 648us/step - loss: 3.0150e-06 - accuracy: 1.0000 - val_loss: 4.9357e-06 - val_accuracy: 1.0000\n",
      "Epoch 125/390\n",
      "29/29 [==============================] - 0s 687us/step - loss: 3.0078e-06 - accuracy: 1.0000 - val_loss: 4.9251e-06 - val_accuracy: 1.0000\n",
      "Epoch 126/390\n",
      "29/29 [==============================] - 0s 680us/step - loss: 3.0009e-06 - accuracy: 1.0000 - val_loss: 4.9139e-06 - val_accuracy: 1.0000\n",
      "Epoch 127/390\n",
      "29/29 [==============================] - 0s 660us/step - loss: 2.9949e-06 - accuracy: 1.0000 - val_loss: 4.9022e-06 - val_accuracy: 1.0000\n",
      "Epoch 128/390\n",
      "29/29 [==============================] - 0s 654us/step - loss: 2.9876e-06 - accuracy: 1.0000 - val_loss: 4.8916e-06 - val_accuracy: 1.0000\n",
      "Epoch 129/390\n",
      "29/29 [==============================] - 0s 654us/step - loss: 2.9815e-06 - accuracy: 1.0000 - val_loss: 4.8806e-06 - val_accuracy: 1.0000\n",
      "Epoch 130/390\n",
      "29/29 [==============================] - 0s 672us/step - loss: 2.9748e-06 - accuracy: 1.0000 - val_loss: 4.8696e-06 - val_accuracy: 1.0000\n",
      "Epoch 131/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 2.9679e-06 - accuracy: 1.0000 - val_loss: 4.8584e-06 - val_accuracy: 1.0000\n",
      "Epoch 132/390\n",
      "29/29 [==============================] - 0s 664us/step - loss: 2.9612e-06 - accuracy: 1.0000 - val_loss: 4.8479e-06 - val_accuracy: 1.0000\n",
      "Epoch 133/390\n",
      "29/29 [==============================] - 0s 657us/step - loss: 2.9550e-06 - accuracy: 1.0000 - val_loss: 4.8373e-06 - val_accuracy: 1.0000\n",
      "Epoch 134/390\n",
      "29/29 [==============================] - 0s 650us/step - loss: 2.9485e-06 - accuracy: 1.0000 - val_loss: 4.8265e-06 - val_accuracy: 1.0000\n",
      "Epoch 135/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 2.9421e-06 - accuracy: 1.0000 - val_loss: 4.8159e-06 - val_accuracy: 1.0000\n",
      "Epoch 136/390\n",
      "29/29 [==============================] - 0s 694us/step - loss: 2.9357e-06 - accuracy: 1.0000 - val_loss: 4.8051e-06 - val_accuracy: 1.0000\n",
      "Epoch 137/390\n",
      "29/29 [==============================] - 0s 674us/step - loss: 2.9300e-06 - accuracy: 1.0000 - val_loss: 4.7948e-06 - val_accuracy: 1.0000\n",
      "Epoch 138/390\n",
      "29/29 [==============================] - 0s 633us/step - loss: 2.9230e-06 - accuracy: 1.0000 - val_loss: 4.7842e-06 - val_accuracy: 1.0000\n",
      "Epoch 139/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.9162e-06 - accuracy: 1.0000 - val_loss: 4.7736e-06 - val_accuracy: 1.0000\n",
      "Epoch 140/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 2.9103e-06 - accuracy: 1.0000 - val_loss: 4.7634e-06 - val_accuracy: 1.0000\n",
      "Epoch 141/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.9038e-06 - accuracy: 1.0000 - val_loss: 4.7532e-06 - val_accuracy: 1.0000\n",
      "Epoch 142/390\n",
      "29/29 [==============================] - 0s 628us/step - loss: 2.8979e-06 - accuracy: 1.0000 - val_loss: 4.7422e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/390\n",
      "29/29 [==============================] - 0s 627us/step - loss: 2.8916e-06 - accuracy: 1.0000 - val_loss: 4.7326e-06 - val_accuracy: 1.0000\n",
      "Epoch 144/390\n",
      "29/29 [==============================] - 0s 623us/step - loss: 2.8857e-06 - accuracy: 1.0000 - val_loss: 4.7215e-06 - val_accuracy: 1.0000\n",
      "Epoch 145/390\n",
      "29/29 [==============================] - 0s 635us/step - loss: 2.8796e-06 - accuracy: 1.0000 - val_loss: 4.7116e-06 - val_accuracy: 1.0000\n",
      "Epoch 146/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.8730e-06 - accuracy: 1.0000 - val_loss: 4.7012e-06 - val_accuracy: 1.0000\n",
      "Epoch 147/390\n",
      "29/29 [==============================] - 0s 839us/step - loss: 2.8677e-06 - accuracy: 1.0000 - val_loss: 4.6909e-06 - val_accuracy: 1.0000\n",
      "Epoch 148/390\n",
      "29/29 [==============================] - 0s 609us/step - loss: 2.8611e-06 - accuracy: 1.0000 - val_loss: 4.6813e-06 - val_accuracy: 1.0000\n",
      "Epoch 149/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 2.8546e-06 - accuracy: 1.0000 - val_loss: 4.6709e-06 - val_accuracy: 1.0000\n",
      "Epoch 150/390\n",
      "29/29 [==============================] - 0s 629us/step - loss: 2.8487e-06 - accuracy: 1.0000 - val_loss: 4.6605e-06 - val_accuracy: 1.0000\n",
      "Epoch 151/390\n",
      "29/29 [==============================] - 0s 626us/step - loss: 2.8425e-06 - accuracy: 1.0000 - val_loss: 4.6511e-06 - val_accuracy: 1.0000\n",
      "Epoch 152/390\n",
      "29/29 [==============================] - 0s 618us/step - loss: 2.8370e-06 - accuracy: 1.0000 - val_loss: 4.6410e-06 - val_accuracy: 1.0000\n",
      "Epoch 153/390\n",
      "29/29 [==============================] - 0s 630us/step - loss: 2.8304e-06 - accuracy: 1.0000 - val_loss: 4.6313e-06 - val_accuracy: 1.0000\n",
      "Epoch 154/390\n",
      "29/29 [==============================] - 0s 629us/step - loss: 2.8247e-06 - accuracy: 1.0000 - val_loss: 4.6212e-06 - val_accuracy: 1.0000\n",
      "Epoch 155/390\n",
      "29/29 [==============================] - 0s 623us/step - loss: 2.8190e-06 - accuracy: 1.0000 - val_loss: 4.6111e-06 - val_accuracy: 1.0000\n",
      "Epoch 156/390\n",
      "29/29 [==============================] - 0s 620us/step - loss: 2.8130e-06 - accuracy: 1.0000 - val_loss: 4.6015e-06 - val_accuracy: 1.0000\n",
      "Epoch 157/390\n",
      "29/29 [==============================] - 0s 607us/step - loss: 2.8068e-06 - accuracy: 1.0000 - val_loss: 4.5915e-06 - val_accuracy: 1.0000\n",
      "Epoch 158/390\n",
      "29/29 [==============================] - 0s 623us/step - loss: 2.8012e-06 - accuracy: 1.0000 - val_loss: 4.5820e-06 - val_accuracy: 1.0000\n",
      "Epoch 159/390\n",
      "29/29 [==============================] - 0s 630us/step - loss: 2.7951e-06 - accuracy: 1.0000 - val_loss: 4.5721e-06 - val_accuracy: 1.0000\n",
      "Epoch 160/390\n",
      "29/29 [==============================] - 0s 627us/step - loss: 2.7895e-06 - accuracy: 1.0000 - val_loss: 4.5621e-06 - val_accuracy: 1.0000\n",
      "Epoch 161/390\n",
      "29/29 [==============================] - 0s 638us/step - loss: 2.7840e-06 - accuracy: 1.0000 - val_loss: 4.5526e-06 - val_accuracy: 1.0000\n",
      "Epoch 162/390\n",
      "29/29 [==============================] - 0s 608us/step - loss: 2.7778e-06 - accuracy: 1.0000 - val_loss: 4.5433e-06 - val_accuracy: 1.0000\n",
      "Epoch 163/390\n",
      "29/29 [==============================] - 0s 618us/step - loss: 2.7719e-06 - accuracy: 1.0000 - val_loss: 4.5339e-06 - val_accuracy: 1.0000\n",
      "Epoch 164/390\n",
      "29/29 [==============================] - 0s 618us/step - loss: 2.7664e-06 - accuracy: 1.0000 - val_loss: 4.5245e-06 - val_accuracy: 1.0000\n",
      "Epoch 165/390\n",
      "29/29 [==============================] - 0s 592us/step - loss: 2.7608e-06 - accuracy: 1.0000 - val_loss: 4.5148e-06 - val_accuracy: 1.0000\n",
      "Epoch 166/390\n",
      "29/29 [==============================] - 0s 621us/step - loss: 2.7553e-06 - accuracy: 1.0000 - val_loss: 4.5058e-06 - val_accuracy: 1.0000\n",
      "Epoch 167/390\n",
      "29/29 [==============================] - 0s 621us/step - loss: 2.7493e-06 - accuracy: 1.0000 - val_loss: 4.4961e-06 - val_accuracy: 1.0000\n",
      "Epoch 168/390\n",
      "29/29 [==============================] - 0s 628us/step - loss: 2.7437e-06 - accuracy: 1.0000 - val_loss: 4.4867e-06 - val_accuracy: 1.0000\n",
      "Epoch 169/390\n",
      "29/29 [==============================] - 0s 614us/step - loss: 2.7382e-06 - accuracy: 1.0000 - val_loss: 4.4781e-06 - val_accuracy: 1.0000\n",
      "Epoch 170/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7325e-06 - accuracy: 1.0000 - val_loss: 4.4679e-06 - val_accuracy: 1.0000\n",
      "Epoch 171/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 2.7274e-06 - accuracy: 1.0000 - val_loss: 4.4588e-06 - val_accuracy: 1.0000\n",
      "Epoch 172/390\n",
      "29/29 [==============================] - 0s 612us/step - loss: 2.7218e-06 - accuracy: 1.0000 - val_loss: 4.4499e-06 - val_accuracy: 1.0000\n",
      "Epoch 173/390\n",
      "29/29 [==============================] - 0s 626us/step - loss: 2.7163e-06 - accuracy: 1.0000 - val_loss: 4.4407e-06 - val_accuracy: 1.0000\n",
      "Epoch 174/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 2.7106e-06 - accuracy: 1.0000 - val_loss: 4.4316e-06 - val_accuracy: 1.0000\n",
      "Epoch 175/390\n",
      "29/29 [==============================] - 0s 635us/step - loss: 2.7052e-06 - accuracy: 1.0000 - val_loss: 4.4226e-06 - val_accuracy: 1.0000\n",
      "Epoch 176/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 2.6997e-06 - accuracy: 1.0000 - val_loss: 4.4138e-06 - val_accuracy: 1.0000\n",
      "Epoch 177/390\n",
      "29/29 [==============================] - 0s 610us/step - loss: 2.6944e-06 - accuracy: 1.0000 - val_loss: 4.4040e-06 - val_accuracy: 1.0000\n",
      "Epoch 178/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 2.6886e-06 - accuracy: 1.0000 - val_loss: 4.3956e-06 - val_accuracy: 1.0000\n",
      "Epoch 179/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 2.6832e-06 - accuracy: 1.0000 - val_loss: 4.3860e-06 - val_accuracy: 1.0000\n",
      "Epoch 180/390\n",
      "29/29 [==============================] - 0s 600us/step - loss: 2.6776e-06 - accuracy: 1.0000 - val_loss: 4.3773e-06 - val_accuracy: 1.0000\n",
      "Epoch 181/390\n",
      "29/29 [==============================] - 0s 670us/step - loss: 2.6725e-06 - accuracy: 1.0000 - val_loss: 4.3690e-06 - val_accuracy: 1.0000\n",
      "Epoch 182/390\n",
      "29/29 [==============================] - 0s 632us/step - loss: 2.6670e-06 - accuracy: 1.0000 - val_loss: 4.3595e-06 - val_accuracy: 1.0000\n",
      "Epoch 183/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 2.6615e-06 - accuracy: 1.0000 - val_loss: 4.3504e-06 - val_accuracy: 1.0000\n",
      "Epoch 184/390\n",
      "29/29 [==============================] - 0s 850us/step - loss: 2.6563e-06 - accuracy: 1.0000 - val_loss: 4.3418e-06 - val_accuracy: 1.0000\n",
      "Epoch 185/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 2.6512e-06 - accuracy: 1.0000 - val_loss: 4.3330e-06 - val_accuracy: 1.0000\n",
      "Epoch 186/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 2.6461e-06 - accuracy: 1.0000 - val_loss: 4.3241e-06 - val_accuracy: 1.0000\n",
      "Epoch 187/390\n",
      "29/29 [==============================] - 0s 600us/step - loss: 2.6405e-06 - accuracy: 1.0000 - val_loss: 4.3154e-06 - val_accuracy: 1.0000\n",
      "Epoch 188/390\n",
      "29/29 [==============================] - 0s 887us/step - loss: 2.6359e-06 - accuracy: 1.0000 - val_loss: 4.3074e-06 - val_accuracy: 1.0000\n",
      "Epoch 189/390\n",
      "29/29 [==============================] - 0s 648us/step - loss: 2.6309e-06 - accuracy: 1.0000 - val_loss: 4.2987e-06 - val_accuracy: 1.0000\n",
      "Epoch 190/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 2.6252e-06 - accuracy: 1.0000 - val_loss: 4.2900e-06 - val_accuracy: 1.0000\n",
      "Epoch 191/390\n",
      "29/29 [==============================] - 0s 597us/step - loss: 2.6199e-06 - accuracy: 1.0000 - val_loss: 4.2813e-06 - val_accuracy: 1.0000\n",
      "Epoch 192/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6147e-06 - accuracy: 1.0000 - val_loss: 4.2732e-06 - val_accuracy: 1.0000\n",
      "Epoch 193/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 2.6096e-06 - accuracy: 1.0000 - val_loss: 4.2645e-06 - val_accuracy: 1.0000\n",
      "Epoch 194/390\n",
      "29/29 [==============================] - 0s 614us/step - loss: 2.6046e-06 - accuracy: 1.0000 - val_loss: 4.2559e-06 - val_accuracy: 1.0000\n",
      "Epoch 195/390\n",
      "29/29 [==============================] - 0s 634us/step - loss: 2.5999e-06 - accuracy: 1.0000 - val_loss: 4.2475e-06 - val_accuracy: 1.0000\n",
      "Epoch 196/390\n",
      "29/29 [==============================] - 0s 614us/step - loss: 2.5945e-06 - accuracy: 1.0000 - val_loss: 4.2396e-06 - val_accuracy: 1.0000\n",
      "Epoch 197/390\n",
      "29/29 [==============================] - 0s 649us/step - loss: 2.5895e-06 - accuracy: 1.0000 - val_loss: 4.2310e-06 - val_accuracy: 1.0000\n",
      "Epoch 198/390\n",
      "29/29 [==============================] - 0s 608us/step - loss: 2.5845e-06 - accuracy: 1.0000 - val_loss: 4.2226e-06 - val_accuracy: 1.0000\n",
      "Epoch 199/390\n",
      "29/29 [==============================] - 0s 609us/step - loss: 2.5797e-06 - accuracy: 1.0000 - val_loss: 4.2146e-06 - val_accuracy: 1.0000\n",
      "Epoch 200/390\n",
      "29/29 [==============================] - 0s 656us/step - loss: 2.5745e-06 - accuracy: 1.0000 - val_loss: 4.2062e-06 - val_accuracy: 1.0000\n",
      "Epoch 201/390\n",
      "29/29 [==============================] - 0s 608us/step - loss: 2.5695e-06 - accuracy: 1.0000 - val_loss: 4.1982e-06 - val_accuracy: 1.0000\n",
      "Epoch 202/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.5646e-06 - accuracy: 1.0000 - val_loss: 4.1894e-06 - val_accuracy: 1.0000\n",
      "Epoch 203/390\n",
      "29/29 [==============================] - 0s 637us/step - loss: 2.5596e-06 - accuracy: 1.0000 - val_loss: 4.1813e-06 - val_accuracy: 1.0000\n",
      "Epoch 204/390\n",
      "29/29 [==============================] - 0s 599us/step - loss: 2.5549e-06 - accuracy: 1.0000 - val_loss: 4.1732e-06 - val_accuracy: 1.0000\n",
      "Epoch 205/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 2.5497e-06 - accuracy: 1.0000 - val_loss: 4.1653e-06 - val_accuracy: 1.0000\n",
      "Epoch 206/390\n",
      "29/29 [==============================] - 0s 595us/step - loss: 2.5450e-06 - accuracy: 1.0000 - val_loss: 4.1572e-06 - val_accuracy: 1.0000\n",
      "Epoch 207/390\n",
      "29/29 [==============================] - 0s 630us/step - loss: 2.5408e-06 - accuracy: 1.0000 - val_loss: 4.1493e-06 - val_accuracy: 1.0000\n",
      "Epoch 208/390\n",
      "29/29 [==============================] - 0s 621us/step - loss: 2.5350e-06 - accuracy: 1.0000 - val_loss: 4.1412e-06 - val_accuracy: 1.0000\n",
      "Epoch 209/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.5302e-06 - accuracy: 1.0000 - val_loss: 4.1334e-06 - val_accuracy: 1.0000\n",
      "Epoch 210/390\n",
      "29/29 [==============================] - 0s 637us/step - loss: 2.5257e-06 - accuracy: 1.0000 - val_loss: 4.1251e-06 - val_accuracy: 1.0000\n",
      "Epoch 211/390\n",
      "29/29 [==============================] - 0s 620us/step - loss: 2.5208e-06 - accuracy: 1.0000 - val_loss: 4.1173e-06 - val_accuracy: 1.0000\n",
      "Epoch 212/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.5161e-06 - accuracy: 1.0000 - val_loss: 4.1093e-06 - val_accuracy: 1.0000\n",
      "Epoch 213/390\n",
      "29/29 [==============================] - 0s 613us/step - loss: 2.5113e-06 - accuracy: 1.0000 - val_loss: 4.1013e-06 - val_accuracy: 1.0000\n",
      "Epoch 214/390\n",
      "29/29 [==============================] - 0s 635us/step - loss: 2.5066e-06 - accuracy: 1.0000 - val_loss: 4.0935e-06 - val_accuracy: 1.0000\n",
      "Epoch 215/390\n",
      "29/29 [==============================] - 0s 619us/step - loss: 2.5018e-06 - accuracy: 1.0000 - val_loss: 4.0859e-06 - val_accuracy: 1.0000\n",
      "Epoch 216/390\n",
      "29/29 [==============================] - 0s 613us/step - loss: 2.4972e-06 - accuracy: 1.0000 - val_loss: 4.0777e-06 - val_accuracy: 1.0000\n",
      "Epoch 217/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.4926e-06 - accuracy: 1.0000 - val_loss: 4.0701e-06 - val_accuracy: 1.0000\n",
      "Epoch 218/390\n",
      "29/29 [==============================] - 0s 602us/step - loss: 2.4876e-06 - accuracy: 1.0000 - val_loss: 4.0626e-06 - val_accuracy: 1.0000\n",
      "Epoch 219/390\n",
      "29/29 [==============================] - 0s 633us/step - loss: 2.4839e-06 - accuracy: 1.0000 - val_loss: 4.0547e-06 - val_accuracy: 1.0000\n",
      "Epoch 220/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 2.4787e-06 - accuracy: 1.0000 - val_loss: 4.0472e-06 - val_accuracy: 1.0000\n",
      "Epoch 221/390\n",
      "29/29 [==============================] - 0s 628us/step - loss: 2.4739e-06 - accuracy: 1.0000 - val_loss: 4.0392e-06 - val_accuracy: 1.0000\n",
      "Epoch 222/390\n",
      "29/29 [==============================] - 0s 614us/step - loss: 2.4693e-06 - accuracy: 1.0000 - val_loss: 4.0317e-06 - val_accuracy: 1.0000\n",
      "Epoch 223/390\n",
      "29/29 [==============================] - 0s 613us/step - loss: 2.4647e-06 - accuracy: 1.0000 - val_loss: 4.0243e-06 - val_accuracy: 1.0000\n",
      "Epoch 224/390\n",
      "29/29 [==============================] - 0s 598us/step - loss: 2.4601e-06 - accuracy: 1.0000 - val_loss: 4.0167e-06 - val_accuracy: 1.0000\n",
      "Epoch 225/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 2.4557e-06 - accuracy: 1.0000 - val_loss: 4.0090e-06 - val_accuracy: 1.0000\n",
      "Epoch 226/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 2.4512e-06 - accuracy: 1.0000 - val_loss: 4.0018e-06 - val_accuracy: 1.0000\n",
      "Epoch 227/390\n",
      "29/29 [==============================] - 0s 623us/step - loss: 2.4464e-06 - accuracy: 1.0000 - val_loss: 3.9938e-06 - val_accuracy: 1.0000\n",
      "Epoch 228/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 2.4419e-06 - accuracy: 1.0000 - val_loss: 3.9866e-06 - val_accuracy: 1.0000\n",
      "Epoch 229/390\n",
      "29/29 [==============================] - 0s 981us/step - loss: 2.4378e-06 - accuracy: 1.0000 - val_loss: 3.9791e-06 - val_accuracy: 1.0000\n",
      "Epoch 230/390\n",
      "29/29 [==============================] - 0s 897us/step - loss: 2.4332e-06 - accuracy: 1.0000 - val_loss: 3.9714e-06 - val_accuracy: 1.0000\n",
      "Epoch 231/390\n",
      "29/29 [==============================] - 0s 652us/step - loss: 2.4286e-06 - accuracy: 1.0000 - val_loss: 3.9645e-06 - val_accuracy: 1.0000\n",
      "Epoch 232/390\n",
      "29/29 [==============================] - 0s 733us/step - loss: 2.4243e-06 - accuracy: 1.0000 - val_loss: 3.9568e-06 - val_accuracy: 1.0000\n",
      "Epoch 233/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 2.4198e-06 - accuracy: 1.0000 - val_loss: 3.9496e-06 - val_accuracy: 1.0000\n",
      "Epoch 234/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 2.4154e-06 - accuracy: 1.0000 - val_loss: 3.9423e-06 - val_accuracy: 1.0000\n",
      "Epoch 235/390\n",
      "29/29 [==============================] - 0s 629us/step - loss: 2.4106e-06 - accuracy: 1.0000 - val_loss: 3.9353e-06 - val_accuracy: 1.0000\n",
      "Epoch 236/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 2.4060e-06 - accuracy: 1.0000 - val_loss: 3.9276e-06 - val_accuracy: 1.0000\n",
      "Epoch 237/390\n",
      "29/29 [==============================] - 0s 627us/step - loss: 2.4019e-06 - accuracy: 1.0000 - val_loss: 3.9208e-06 - val_accuracy: 1.0000\n",
      "Epoch 238/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 2.3976e-06 - accuracy: 1.0000 - val_loss: 3.9130e-06 - val_accuracy: 1.0000\n",
      "Epoch 239/390\n",
      "29/29 [==============================] - 0s 655us/step - loss: 2.3932e-06 - accuracy: 1.0000 - val_loss: 3.9060e-06 - val_accuracy: 1.0000\n",
      "Epoch 240/390\n",
      "29/29 [==============================] - 0s 619us/step - loss: 2.3889e-06 - accuracy: 1.0000 - val_loss: 3.8989e-06 - val_accuracy: 1.0000\n",
      "Epoch 241/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 2.3848e-06 - accuracy: 1.0000 - val_loss: 3.8918e-06 - val_accuracy: 1.0000\n",
      "Epoch 242/390\n",
      "29/29 [==============================] - 0s 613us/step - loss: 2.3804e-06 - accuracy: 1.0000 - val_loss: 3.8852e-06 - val_accuracy: 1.0000\n",
      "Epoch 243/390\n",
      "29/29 [==============================] - 0s 667us/step - loss: 2.3758e-06 - accuracy: 1.0000 - val_loss: 3.8778e-06 - val_accuracy: 1.0000\n",
      "Epoch 244/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 2.3721e-06 - accuracy: 1.0000 - val_loss: 3.8705e-06 - val_accuracy: 1.0000\n",
      "Epoch 245/390\n",
      "29/29 [==============================] - 0s 618us/step - loss: 2.3675e-06 - accuracy: 1.0000 - val_loss: 3.8634e-06 - val_accuracy: 1.0000\n",
      "Epoch 246/390\n",
      "29/29 [==============================] - 0s 621us/step - loss: 2.3634e-06 - accuracy: 1.0000 - val_loss: 3.8567e-06 - val_accuracy: 1.0000\n",
      "Epoch 247/390\n",
      "29/29 [==============================] - 0s 608us/step - loss: 2.3589e-06 - accuracy: 1.0000 - val_loss: 3.8502e-06 - val_accuracy: 1.0000\n",
      "Epoch 248/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.3548e-06 - accuracy: 1.0000 - val_loss: 3.8425e-06 - val_accuracy: 1.0000\n",
      "Epoch 249/390\n",
      "29/29 [==============================] - 0s 656us/step - loss: 2.3509e-06 - accuracy: 1.0000 - val_loss: 3.8357e-06 - val_accuracy: 1.0000\n",
      "Epoch 250/390\n",
      "29/29 [==============================] - 0s 611us/step - loss: 2.3466e-06 - accuracy: 1.0000 - val_loss: 3.8285e-06 - val_accuracy: 1.0000\n",
      "Epoch 251/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 2.3424e-06 - accuracy: 1.0000 - val_loss: 3.8221e-06 - val_accuracy: 1.0000\n",
      "Epoch 252/390\n",
      "29/29 [==============================] - 0s 647us/step - loss: 2.3380e-06 - accuracy: 1.0000 - val_loss: 3.8149e-06 - val_accuracy: 1.0000\n",
      "Epoch 253/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 2.3340e-06 - accuracy: 1.0000 - val_loss: 3.8081e-06 - val_accuracy: 1.0000\n",
      "Epoch 254/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 2.3300e-06 - accuracy: 1.0000 - val_loss: 3.8011e-06 - val_accuracy: 1.0000\n",
      "Epoch 255/390\n",
      "29/29 [==============================] - 0s 618us/step - loss: 2.3255e-06 - accuracy: 1.0000 - val_loss: 3.7942e-06 - val_accuracy: 1.0000\n",
      "Epoch 256/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 2.3215e-06 - accuracy: 1.0000 - val_loss: 3.7879e-06 - val_accuracy: 1.0000\n",
      "Epoch 257/390\n",
      "29/29 [==============================] - 0s 604us/step - loss: 2.3173e-06 - accuracy: 1.0000 - val_loss: 3.7806e-06 - val_accuracy: 1.0000\n",
      "Epoch 258/390\n",
      "29/29 [==============================] - 0s 656us/step - loss: 2.3133e-06 - accuracy: 1.0000 - val_loss: 3.7742e-06 - val_accuracy: 1.0000\n",
      "Epoch 259/390\n",
      "29/29 [==============================] - 0s 626us/step - loss: 2.3094e-06 - accuracy: 1.0000 - val_loss: 3.7669e-06 - val_accuracy: 1.0000\n",
      "Epoch 260/390\n",
      "29/29 [==============================] - 0s 614us/step - loss: 2.3052e-06 - accuracy: 1.0000 - val_loss: 3.7603e-06 - val_accuracy: 1.0000\n",
      "Epoch 261/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 2.3012e-06 - accuracy: 1.0000 - val_loss: 3.7539e-06 - val_accuracy: 1.0000\n",
      "Epoch 262/390\n",
      "29/29 [==============================] - 0s 630us/step - loss: 2.2972e-06 - accuracy: 1.0000 - val_loss: 3.7473e-06 - val_accuracy: 1.0000\n",
      "Epoch 263/390\n",
      "29/29 [==============================] - 0s 595us/step - loss: 2.2931e-06 - accuracy: 1.0000 - val_loss: 3.7404e-06 - val_accuracy: 1.0000\n",
      "Epoch 264/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.2892e-06 - accuracy: 1.0000 - val_loss: 3.7339e-06 - val_accuracy: 1.0000\n",
      "Epoch 265/390\n",
      "29/29 [==============================] - 0s 828us/step - loss: 2.2853e-06 - accuracy: 1.0000 - val_loss: 3.7276e-06 - val_accuracy: 1.0000\n",
      "Epoch 266/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.2812e-06 - accuracy: 1.0000 - val_loss: 3.7207e-06 - val_accuracy: 1.0000\n",
      "Epoch 267/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 2.2773e-06 - accuracy: 1.0000 - val_loss: 3.7141e-06 - val_accuracy: 1.0000\n",
      "Epoch 268/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.2735e-06 - accuracy: 1.0000 - val_loss: 3.7077e-06 - val_accuracy: 1.0000\n",
      "Epoch 269/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 2.2696e-06 - accuracy: 1.0000 - val_loss: 3.7012e-06 - val_accuracy: 1.0000\n",
      "Epoch 270/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 2.2655e-06 - accuracy: 1.0000 - val_loss: 3.6945e-06 - val_accuracy: 1.0000\n",
      "Epoch 271/390\n",
      "29/29 [==============================] - 0s 648us/step - loss: 2.2618e-06 - accuracy: 1.0000 - val_loss: 3.6882e-06 - val_accuracy: 1.0000\n",
      "Epoch 272/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.2579e-06 - accuracy: 1.0000 - val_loss: 3.6816e-06 - val_accuracy: 1.0000\n",
      "Epoch 273/390\n",
      "29/29 [==============================] - 0s 724us/step - loss: 2.2540e-06 - accuracy: 1.0000 - val_loss: 3.6754e-06 - val_accuracy: 1.0000\n",
      "Epoch 274/390\n",
      "29/29 [==============================] - 0s 658us/step - loss: 2.2503e-06 - accuracy: 1.0000 - val_loss: 3.6690e-06 - val_accuracy: 1.0000\n",
      "Epoch 275/390\n",
      "29/29 [==============================] - 0s 709us/step - loss: 2.2462e-06 - accuracy: 1.0000 - val_loss: 3.6627e-06 - val_accuracy: 1.0000\n",
      "Epoch 276/390\n",
      "29/29 [==============================] - 0s 694us/step - loss: 2.2425e-06 - accuracy: 1.0000 - val_loss: 3.6561e-06 - val_accuracy: 1.0000\n",
      "Epoch 277/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 2.2385e-06 - accuracy: 1.0000 - val_loss: 3.6500e-06 - val_accuracy: 1.0000\n",
      "Epoch 278/390\n",
      "29/29 [==============================] - 0s 678us/step - loss: 2.2348e-06 - accuracy: 1.0000 - val_loss: 3.6437e-06 - val_accuracy: 1.0000\n",
      "Epoch 279/390\n",
      "29/29 [==============================] - 0s 727us/step - loss: 2.2308e-06 - accuracy: 1.0000 - val_loss: 3.6374e-06 - val_accuracy: 1.0000\n",
      "Epoch 280/390\n",
      "29/29 [==============================] - 0s 706us/step - loss: 2.2272e-06 - accuracy: 1.0000 - val_loss: 3.6313e-06 - val_accuracy: 1.0000\n",
      "Epoch 281/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 2.2233e-06 - accuracy: 1.0000 - val_loss: 3.6252e-06 - val_accuracy: 1.0000\n",
      "Epoch 282/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.2196e-06 - accuracy: 1.0000 - val_loss: 3.6193e-06 - val_accuracy: 1.0000\n",
      "Epoch 283/390\n",
      "29/29 [==============================] - 0s 618us/step - loss: 2.2158e-06 - accuracy: 1.0000 - val_loss: 3.6130e-06 - val_accuracy: 1.0000\n",
      "Epoch 284/390\n",
      "29/29 [==============================] - 0s 637us/step - loss: 2.2120e-06 - accuracy: 1.0000 - val_loss: 3.6069e-06 - val_accuracy: 1.0000\n",
      "Epoch 285/390\n",
      "29/29 [==============================] - 0s 653us/step - loss: 2.2085e-06 - accuracy: 1.0000 - val_loss: 3.6007e-06 - val_accuracy: 1.0000\n",
      "Epoch 286/390\n",
      "29/29 [==============================] - 0s 641us/step - loss: 2.2047e-06 - accuracy: 1.0000 - val_loss: 3.5950e-06 - val_accuracy: 1.0000\n",
      "Epoch 287/390\n",
      "29/29 [==============================] - 0s 633us/step - loss: 2.2011e-06 - accuracy: 1.0000 - val_loss: 3.5888e-06 - val_accuracy: 1.0000\n",
      "Epoch 288/390\n",
      "29/29 [==============================] - 0s 649us/step - loss: 2.1976e-06 - accuracy: 1.0000 - val_loss: 3.5824e-06 - val_accuracy: 1.0000\n",
      "Epoch 289/390\n",
      "29/29 [==============================] - 0s 649us/step - loss: 2.1938e-06 - accuracy: 1.0000 - val_loss: 3.5766e-06 - val_accuracy: 1.0000\n",
      "Epoch 290/390\n",
      "29/29 [==============================] - 0s 638us/step - loss: 2.1901e-06 - accuracy: 1.0000 - val_loss: 3.5706e-06 - val_accuracy: 1.0000\n",
      "Epoch 291/390\n",
      "29/29 [==============================] - 0s 755us/step - loss: 2.1864e-06 - accuracy: 1.0000 - val_loss: 3.5648e-06 - val_accuracy: 1.0000\n",
      "Epoch 292/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 2.1828e-06 - accuracy: 1.0000 - val_loss: 3.5588e-06 - val_accuracy: 1.0000\n",
      "Epoch 293/390\n",
      "29/29 [==============================] - 0s 630us/step - loss: 2.1794e-06 - accuracy: 1.0000 - val_loss: 3.5530e-06 - val_accuracy: 1.0000\n",
      "Epoch 294/390\n",
      "29/29 [==============================] - 0s 649us/step - loss: 2.1756e-06 - accuracy: 1.0000 - val_loss: 3.5469e-06 - val_accuracy: 1.0000\n",
      "Epoch 295/390\n",
      "29/29 [==============================] - 0s 639us/step - loss: 2.1720e-06 - accuracy: 1.0000 - val_loss: 3.5412e-06 - val_accuracy: 1.0000\n",
      "Epoch 296/390\n",
      "29/29 [==============================] - 0s 693us/step - loss: 2.1685e-06 - accuracy: 1.0000 - val_loss: 3.5350e-06 - val_accuracy: 1.0000\n",
      "Epoch 297/390\n",
      "29/29 [==============================] - 0s 702us/step - loss: 2.1649e-06 - accuracy: 1.0000 - val_loss: 3.5295e-06 - val_accuracy: 1.0000\n",
      "Epoch 298/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.1611e-06 - accuracy: 1.0000 - val_loss: 3.5236e-06 - val_accuracy: 1.0000\n",
      "Epoch 299/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 2.1576e-06 - accuracy: 1.0000 - val_loss: 3.5179e-06 - val_accuracy: 1.0000\n",
      "Epoch 300/390\n",
      "29/29 [==============================] - 0s 621us/step - loss: 2.1540e-06 - accuracy: 1.0000 - val_loss: 3.5121e-06 - val_accuracy: 1.0000\n",
      "Epoch 301/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 2.1505e-06 - accuracy: 1.0000 - val_loss: 3.5063e-06 - val_accuracy: 1.0000\n",
      "Epoch 302/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1471e-06 - accuracy: 1.0000 - val_loss: 3.5007e-06 - val_accuracy: 1.0000\n",
      "Epoch 303/390\n",
      "29/29 [==============================] - 0s 632us/step - loss: 2.1435e-06 - accuracy: 1.0000 - val_loss: 3.4950e-06 - val_accuracy: 1.0000\n",
      "Epoch 304/390\n",
      "29/29 [==============================] - 0s 683us/step - loss: 2.1399e-06 - accuracy: 1.0000 - val_loss: 3.4894e-06 - val_accuracy: 1.0000\n",
      "Epoch 305/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 2.1365e-06 - accuracy: 1.0000 - val_loss: 3.4832e-06 - val_accuracy: 1.0000\n",
      "Epoch 306/390\n",
      "29/29 [==============================] - 0s 692us/step - loss: 2.1331e-06 - accuracy: 1.0000 - val_loss: 3.4777e-06 - val_accuracy: 1.0000\n",
      "Epoch 307/390\n",
      "29/29 [==============================] - 0s 680us/step - loss: 2.1295e-06 - accuracy: 1.0000 - val_loss: 3.4721e-06 - val_accuracy: 1.0000\n",
      "Epoch 308/390\n",
      "29/29 [==============================] - 0s 655us/step - loss: 2.1261e-06 - accuracy: 1.0000 - val_loss: 3.4663e-06 - val_accuracy: 1.0000\n",
      "Epoch 309/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 2.1225e-06 - accuracy: 1.0000 - val_loss: 3.4608e-06 - val_accuracy: 1.0000\n",
      "Epoch 310/390\n",
      "29/29 [==============================] - 0s 640us/step - loss: 2.1194e-06 - accuracy: 1.0000 - val_loss: 3.4554e-06 - val_accuracy: 1.0000\n",
      "Epoch 311/390\n",
      "29/29 [==============================] - 0s 638us/step - loss: 2.1157e-06 - accuracy: 1.0000 - val_loss: 3.4498e-06 - val_accuracy: 1.0000\n",
      "Epoch 312/390\n",
      "29/29 [==============================] - 0s 626us/step - loss: 2.1124e-06 - accuracy: 1.0000 - val_loss: 3.4441e-06 - val_accuracy: 1.0000\n",
      "Epoch 313/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.1090e-06 - accuracy: 1.0000 - val_loss: 3.4382e-06 - val_accuracy: 1.0000\n",
      "Epoch 314/390\n",
      "29/29 [==============================] - 0s 612us/step - loss: 2.1054e-06 - accuracy: 1.0000 - val_loss: 3.4327e-06 - val_accuracy: 1.0000\n",
      "Epoch 315/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.1021e-06 - accuracy: 1.0000 - val_loss: 3.4272e-06 - val_accuracy: 1.0000\n",
      "Epoch 316/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 2.0986e-06 - accuracy: 1.0000 - val_loss: 3.4218e-06 - val_accuracy: 1.0000\n",
      "Epoch 317/390\n",
      "29/29 [==============================] - 0s 675us/step - loss: 2.0952e-06 - accuracy: 1.0000 - val_loss: 3.4163e-06 - val_accuracy: 1.0000\n",
      "Epoch 318/390\n",
      "29/29 [==============================] - 0s 633us/step - loss: 2.0919e-06 - accuracy: 1.0000 - val_loss: 3.4106e-06 - val_accuracy: 1.0000\n",
      "Epoch 319/390\n",
      "29/29 [==============================] - 0s 661us/step - loss: 2.0886e-06 - accuracy: 1.0000 - val_loss: 3.4054e-06 - val_accuracy: 1.0000\n",
      "Epoch 320/390\n",
      "29/29 [==============================] - 0s 652us/step - loss: 2.0855e-06 - accuracy: 1.0000 - val_loss: 3.3998e-06 - val_accuracy: 1.0000\n",
      "Epoch 321/390\n",
      "29/29 [==============================] - 0s 619us/step - loss: 2.0819e-06 - accuracy: 1.0000 - val_loss: 3.3945e-06 - val_accuracy: 1.0000\n",
      "Epoch 322/390\n",
      "29/29 [==============================] - 0s 682us/step - loss: 2.0791e-06 - accuracy: 1.0000 - val_loss: 3.3887e-06 - val_accuracy: 1.0000\n",
      "Epoch 323/390\n",
      "29/29 [==============================] - 0s 706us/step - loss: 2.0753e-06 - accuracy: 1.0000 - val_loss: 3.3835e-06 - val_accuracy: 1.0000\n",
      "Epoch 324/390\n",
      "29/29 [==============================] - 0s 640us/step - loss: 2.0720e-06 - accuracy: 1.0000 - val_loss: 3.3781e-06 - val_accuracy: 1.0000\n",
      "Epoch 325/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 2.0687e-06 - accuracy: 1.0000 - val_loss: 3.3728e-06 - val_accuracy: 1.0000\n",
      "Epoch 326/390\n",
      "29/29 [==============================] - 0s 725us/step - loss: 2.0655e-06 - accuracy: 1.0000 - val_loss: 3.3674e-06 - val_accuracy: 1.0000\n",
      "Epoch 327/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.0622e-06 - accuracy: 1.0000 - val_loss: 3.3622e-06 - val_accuracy: 1.0000\n",
      "Epoch 328/390\n",
      "29/29 [==============================] - 0s 658us/step - loss: 2.0589e-06 - accuracy: 1.0000 - val_loss: 3.3572e-06 - val_accuracy: 1.0000\n",
      "Epoch 329/390\n",
      "29/29 [==============================] - 0s 640us/step - loss: 2.0557e-06 - accuracy: 1.0000 - val_loss: 3.3519e-06 - val_accuracy: 1.0000\n",
      "Epoch 330/390\n",
      "29/29 [==============================] - 0s 649us/step - loss: 2.0526e-06 - accuracy: 1.0000 - val_loss: 3.3466e-06 - val_accuracy: 1.0000\n",
      "Epoch 331/390\n",
      "29/29 [==============================] - 0s 633us/step - loss: 2.0494e-06 - accuracy: 1.0000 - val_loss: 3.3406e-06 - val_accuracy: 1.0000\n",
      "Epoch 332/390\n",
      "29/29 [==============================] - 0s 653us/step - loss: 2.0461e-06 - accuracy: 1.0000 - val_loss: 3.3358e-06 - val_accuracy: 1.0000\n",
      "Epoch 333/390\n",
      "29/29 [==============================] - 0s 645us/step - loss: 2.0427e-06 - accuracy: 1.0000 - val_loss: 3.3306e-06 - val_accuracy: 1.0000\n",
      "Epoch 334/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 2.0395e-06 - accuracy: 1.0000 - val_loss: 3.3253e-06 - val_accuracy: 1.0000\n",
      "Epoch 335/390\n",
      "29/29 [==============================] - 0s 640us/step - loss: 2.0363e-06 - accuracy: 1.0000 - val_loss: 3.3202e-06 - val_accuracy: 1.0000\n",
      "Epoch 336/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 2.0334e-06 - accuracy: 1.0000 - val_loss: 3.3148e-06 - val_accuracy: 1.0000\n",
      "Epoch 337/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0302e-06 - accuracy: 1.0000 - val_loss: 3.3097e-06 - val_accuracy: 1.0000\n",
      "Epoch 338/390\n",
      "29/29 [==============================] - 0s 601us/step - loss: 2.0268e-06 - accuracy: 1.0000 - val_loss: 3.3045e-06 - val_accuracy: 1.0000\n",
      "Epoch 339/390\n",
      "29/29 [==============================] - 0s 617us/step - loss: 2.0237e-06 - accuracy: 1.0000 - val_loss: 3.2992e-06 - val_accuracy: 1.0000\n",
      "Epoch 340/390\n",
      "29/29 [==============================] - 0s 645us/step - loss: 2.0209e-06 - accuracy: 1.0000 - val_loss: 3.2942e-06 - val_accuracy: 1.0000\n",
      "Epoch 341/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.0176e-06 - accuracy: 1.0000 - val_loss: 3.2890e-06 - val_accuracy: 1.0000\n",
      "Epoch 342/390\n",
      "29/29 [==============================] - 0s 599us/step - loss: 2.0145e-06 - accuracy: 1.0000 - val_loss: 3.2839e-06 - val_accuracy: 1.0000\n",
      "Epoch 343/390\n",
      "29/29 [==============================] - 0s 645us/step - loss: 2.0111e-06 - accuracy: 1.0000 - val_loss: 3.2790e-06 - val_accuracy: 1.0000\n",
      "Epoch 344/390\n",
      "29/29 [==============================] - 0s 632us/step - loss: 2.0081e-06 - accuracy: 1.0000 - val_loss: 3.2739e-06 - val_accuracy: 1.0000\n",
      "Epoch 345/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 2.0051e-06 - accuracy: 1.0000 - val_loss: 3.2686e-06 - val_accuracy: 1.0000\n",
      "Epoch 346/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 2.0019e-06 - accuracy: 1.0000 - val_loss: 3.2636e-06 - val_accuracy: 1.0000\n",
      "Epoch 347/390\n",
      "29/29 [==============================] - 0s 635us/step - loss: 1.9989e-06 - accuracy: 1.0000 - val_loss: 3.2585e-06 - val_accuracy: 1.0000\n",
      "Epoch 348/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 1.9960e-06 - accuracy: 1.0000 - val_loss: 3.2537e-06 - val_accuracy: 1.0000\n",
      "Epoch 349/390\n",
      "29/29 [==============================] - 0s 644us/step - loss: 1.9925e-06 - accuracy: 1.0000 - val_loss: 3.2486e-06 - val_accuracy: 1.0000\n",
      "Epoch 350/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 1.9900e-06 - accuracy: 1.0000 - val_loss: 3.2437e-06 - val_accuracy: 1.0000\n",
      "Epoch 351/390\n",
      "29/29 [==============================] - 0s 610us/step - loss: 1.9866e-06 - accuracy: 1.0000 - val_loss: 3.2388e-06 - val_accuracy: 1.0000\n",
      "Epoch 352/390\n",
      "29/29 [==============================] - 0s 643us/step - loss: 1.9836e-06 - accuracy: 1.0000 - val_loss: 3.2334e-06 - val_accuracy: 1.0000\n",
      "Epoch 353/390\n",
      "29/29 [==============================] - 0s 660us/step - loss: 1.9805e-06 - accuracy: 1.0000 - val_loss: 3.2287e-06 - val_accuracy: 1.0000\n",
      "Epoch 354/390\n",
      "29/29 [==============================] - 0s 638us/step - loss: 1.9774e-06 - accuracy: 1.0000 - val_loss: 3.2239e-06 - val_accuracy: 1.0000\n",
      "Epoch 355/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 1.9745e-06 - accuracy: 1.0000 - val_loss: 3.2190e-06 - val_accuracy: 1.0000\n",
      "Epoch 356/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.9714e-06 - accuracy: 1.0000 - val_loss: 3.2139e-06 - val_accuracy: 1.0000\n",
      "Epoch 357/390\n",
      "29/29 [==============================] - 0s 622us/step - loss: 1.9684e-06 - accuracy: 1.0000 - val_loss: 3.2092e-06 - val_accuracy: 1.0000\n",
      "Epoch 358/390\n",
      "29/29 [==============================] - 0s 652us/step - loss: 1.9654e-06 - accuracy: 1.0000 - val_loss: 3.2040e-06 - val_accuracy: 1.0000\n",
      "Epoch 359/390\n",
      "29/29 [==============================] - 0s 630us/step - loss: 1.9625e-06 - accuracy: 1.0000 - val_loss: 3.1992e-06 - val_accuracy: 1.0000\n",
      "Epoch 360/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 1.9595e-06 - accuracy: 1.0000 - val_loss: 3.1942e-06 - val_accuracy: 1.0000\n",
      "Epoch 361/390\n",
      "29/29 [==============================] - 0s 615us/step - loss: 1.9566e-06 - accuracy: 1.0000 - val_loss: 3.1892e-06 - val_accuracy: 1.0000\n",
      "Epoch 362/390\n",
      "29/29 [==============================] - 0s 655us/step - loss: 1.9537e-06 - accuracy: 1.0000 - val_loss: 3.1844e-06 - val_accuracy: 1.0000\n",
      "Epoch 363/390\n",
      "29/29 [==============================] - 0s 629us/step - loss: 1.9507e-06 - accuracy: 1.0000 - val_loss: 3.1796e-06 - val_accuracy: 1.0000\n",
      "Epoch 364/390\n",
      "29/29 [==============================] - 0s 625us/step - loss: 1.9478e-06 - accuracy: 1.0000 - val_loss: 3.1751e-06 - val_accuracy: 1.0000\n",
      "Epoch 365/390\n",
      "29/29 [==============================] - 0s 636us/step - loss: 1.9447e-06 - accuracy: 1.0000 - val_loss: 3.1702e-06 - val_accuracy: 1.0000\n",
      "Epoch 366/390\n",
      "29/29 [==============================] - 0s 638us/step - loss: 1.9420e-06 - accuracy: 1.0000 - val_loss: 3.1655e-06 - val_accuracy: 1.0000\n",
      "Epoch 367/390\n",
      "29/29 [==============================] - 0s 637us/step - loss: 1.9390e-06 - accuracy: 1.0000 - val_loss: 3.1607e-06 - val_accuracy: 1.0000\n",
      "Epoch 368/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9361e-06 - accuracy: 1.0000 - val_loss: 3.1560e-06 - val_accuracy: 1.0000\n",
      "Epoch 369/390\n",
      "29/29 [==============================] - 0s 607us/step - loss: 1.9335e-06 - accuracy: 1.0000 - val_loss: 3.1513e-06 - val_accuracy: 1.0000\n",
      "Epoch 370/390\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.9303e-06 - accuracy: 1.0000 - val_loss: 3.1466e-06 - val_accuracy: 1.0000\n",
      "Epoch 371/390\n",
      "29/29 [==============================] - 0s 635us/step - loss: 1.9276e-06 - accuracy: 1.0000 - val_loss: 3.1421e-06 - val_accuracy: 1.0000\n",
      "Epoch 372/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 1.9246e-06 - accuracy: 1.0000 - val_loss: 3.1371e-06 - val_accuracy: 1.0000\n",
      "Epoch 373/390\n",
      "29/29 [==============================] - 0s 626us/step - loss: 1.9219e-06 - accuracy: 1.0000 - val_loss: 3.1326e-06 - val_accuracy: 1.0000\n",
      "Epoch 374/390\n",
      "29/29 [==============================] - 0s 654us/step - loss: 1.9189e-06 - accuracy: 1.0000 - val_loss: 3.1281e-06 - val_accuracy: 1.0000\n",
      "Epoch 375/390\n",
      "29/29 [==============================] - 0s 627us/step - loss: 1.9161e-06 - accuracy: 1.0000 - val_loss: 3.1232e-06 - val_accuracy: 1.0000\n",
      "Epoch 376/390\n",
      "29/29 [==============================] - 0s 642us/step - loss: 1.9133e-06 - accuracy: 1.0000 - val_loss: 3.1185e-06 - val_accuracy: 1.0000\n",
      "Epoch 377/390\n",
      "29/29 [==============================] - 0s 646us/step - loss: 1.9104e-06 - accuracy: 1.0000 - val_loss: 3.1141e-06 - val_accuracy: 1.0000\n",
      "Epoch 378/390\n",
      "29/29 [==============================] - 0s 616us/step - loss: 1.9076e-06 - accuracy: 1.0000 - val_loss: 3.1090e-06 - val_accuracy: 1.0000\n",
      "Epoch 379/390\n",
      "29/29 [==============================] - 0s 624us/step - loss: 1.9048e-06 - accuracy: 1.0000 - val_loss: 3.1047e-06 - val_accuracy: 1.0000\n",
      "Epoch 380/390\n",
      "29/29 [==============================] - 0s 631us/step - loss: 1.9020e-06 - accuracy: 1.0000 - val_loss: 3.1000e-06 - val_accuracy: 1.0000\n",
      "Epoch 381/390\n",
      "29/29 [==============================] - 0s 659us/step - loss: 1.8991e-06 - accuracy: 1.0000 - val_loss: 3.0954e-06 - val_accuracy: 1.0000\n",
      "Epoch 382/390\n",
      "29/29 [==============================] - 0s 648us/step - loss: 1.8963e-06 - accuracy: 1.0000 - val_loss: 3.0910e-06 - val_accuracy: 1.0000\n",
      "Epoch 383/390\n",
      "29/29 [==============================] - 0s 634us/step - loss: 1.8935e-06 - accuracy: 1.0000 - val_loss: 3.0865e-06 - val_accuracy: 1.0000\n",
      "Epoch 384/390\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.8910e-06 - accuracy: 1.0000 - val_loss: 3.0818e-06 - val_accuracy: 1.0000\n",
      "Epoch 385/390\n",
      "29/29 [==============================] - 0s 647us/step - loss: 1.8880e-06 - accuracy: 1.0000 - val_loss: 3.0774e-06 - val_accuracy: 1.0000\n",
      "Epoch 386/390\n",
      "29/29 [==============================] - 0s 648us/step - loss: 1.8853e-06 - accuracy: 1.0000 - val_loss: 3.0730e-06 - val_accuracy: 1.0000\n",
      "Epoch 387/390\n",
      "29/29 [==============================] - 0s 691us/step - loss: 1.8824e-06 - accuracy: 1.0000 - val_loss: 3.0685e-06 - val_accuracy: 1.0000\n",
      "Epoch 388/390\n",
      "29/29 [==============================] - 0s 674us/step - loss: 1.8798e-06 - accuracy: 1.0000 - val_loss: 3.0638e-06 - val_accuracy: 1.0000\n",
      "Epoch 389/390\n",
      "29/29 [==============================] - 0s 692us/step - loss: 1.8772e-06 - accuracy: 1.0000 - val_loss: 3.0595e-06 - val_accuracy: 1.0000\n",
      "Epoch 390/390\n",
      "29/29 [==============================] - 0s 639us/step - loss: 1.8742e-06 - accuracy: 1.0000 - val_loss: 3.0550e-06 - val_accuracy: 1.0000\n",
      "Test Accuracy=1.0000\n"
     ]
    }
   ],
   "source": [
    "# Assigning new DataFrame to Data set variable\n",
    "X_test = df_copy_test\n",
    "\n",
    "# Training of the model with validation split and early stopping\n",
    "history = model.fit(\n",
    "    x=X_test,\n",
    "    y=y_test,\n",
    "    epochs=params['epochs'],\n",
    "    batch_size=params['batch_size'],\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],  # Add early stopping callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on both training and validation sets\n",
    "testing_loss, testing_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print mean accuracies and hyperparameters for this trial\n",
    "print(f\"Test Accuracy={testing_accuracy:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
