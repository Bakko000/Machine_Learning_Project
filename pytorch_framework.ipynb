{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       1     1     1     1     1     3     1   data_5\n",
      "NaN       1     1     1     1     1     3     2   data_6\n",
      "NaN       1     1     1     1     3     2     1  data_19\n",
      "NaN       1     1     1     1     3     3     2  data_22\n",
      "NaN       1     1     1     2     1     2     1  data_27\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6       id\n",
      "NaN       0     1     1     1     1     2     2   data_4\n",
      "NaN       0     1     1     1     1     4     1   data_7\n",
      "NaN       0     1     1     1     2     1     1   data_9\n",
      "NaN       0     1     1     1     2     1     2  data_10\n",
      "NaN       0     1     1     1     2     2     1  data_11\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       0     1     1     1     1     1     1  data_1\n",
      "NaN       0     1     1     1     1     1     2  data_2\n",
      "NaN       0     1     1     1     1     2     1  data_3\n",
      "NaN       0     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       0     1     1     1     1     3     1  data_5\n",
      "NaN       0     1     1     1     1     4     1  data_7\n",
      "     target  col1  col2  col3  col4  col5  col6      id\n",
      "NaN       1     1     1     1     1     1     1  data_1\n",
      "NaN       1     1     1     1     1     1     2  data_2\n",
      "NaN       1     1     1     1     1     2     1  data_3\n",
      "NaN       1     1     1     1     1     2     2  data_4\n",
      "NaN       1     1     1     1     1     3     1  data_5\n"
     ]
    }
   ],
   "source": [
    "from api.data_handler import DataHandler\n",
    "\n",
    "# Creation of a DataHandler Object\n",
    "data_handler = DataHandler(['target', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'id'])\n",
    "\n",
    "# Number of different Datasets\n",
    "datasets_number = 3\n",
    "\n",
    "# Lists of DataFrames\n",
    "df_train : list[pd.DataFrame] = []\n",
    "df_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Load the Training/Test sets into pandas DataFrames\n",
    "for i in range(datasets_number):\n",
    "    df_train.append(data_handler.load_data(f'data/monks/monks-{i+1}.train'))\n",
    "    df_test.append(data_handler.load_data(f'data/monks/monks-{i+1}.test'))\n",
    "\n",
    "    # Print the head of the loaded data\n",
    "    print(df_train[i].head())\n",
    "    print(df_test[i].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data\n",
    "x_train : list[pd.DataFrame] = []\n",
    "y_train : list[pd.DataFrame] = []\n",
    "x_test  : list[pd.DataFrame] = []\n",
    "y_test  : list[pd.DataFrame] = []\n",
    "\n",
    "# Split data into TR set and TS set\n",
    "for i in range(datasets_number):\n",
    "\n",
    "    # Saving the splitted TR set data into the lists\n",
    "    x, y = data_handler.split_data(data=df_train[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "\n",
    "    # Saving the splitted TS set data into the lists\n",
    "    x, y = data_handler.split_data(df_test[i], target_col='target', drop_cols=['target', 'id'])\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monk 1 [TRAIN]: (124, 17)\n",
      "Monk 1 [TEST]: (432, 17)\n",
      "Monk 2 [TRAIN]: (169, 17)\n",
      "Monk 2 [TEST]: (432, 17)\n",
      "Monk 3 [TRAIN]: (122, 17)\n",
      "Monk 3 [TEST]: (432, 17)\n"
     ]
    }
   ],
   "source": [
    "# Applies the 1-Hot Encoding to the \"x\" data\n",
    "for i in range(datasets_number):\n",
    "    x_train[i] = data_handler.one_hot_encoding(x_train[i])\n",
    "    x_test[i]  = data_handler.one_hot_encoding(x_test[i])\n",
    "\n",
    "    # Print of the data modified\n",
    "    print(f\"Monk {i+1} [TRAIN]: \" + str(x_train[i].shape))\n",
    "    print(f\"Monk {i+1} [TEST]: \" + str(x_test[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters' space for Grid Search (1 for each Dataset)\n",
    "param_space = {\n",
    "    0: {\n",
    "        'input_size': [17],\n",
    "        'hidden_size': [2, 3, 4],\n",
    "        'learning_rate': [float(i/10) for i in range(1,10)] + [float(i/100) for i in range(1,10)] + [0.99, 0.999],\n",
    "        'batch_size': [7, 8, 9, 15, 16, 17, 31, 32, 33, 62, 63, 64, 65],\n",
    "        'epochs': [int(350+epochs) for epochs in range(0,50,10)],\n",
    "        'weight_decay': [float(i/10) for i in range(1,10)] + [0.01, 0.001, 0.0001],\n",
    "        'momentum': [float(i/100) for i in range(1,9)] + [float(i/10) for i in range(1,9)],\n",
    "        'hidden_activation': ['Tanh', 'ReLU'],\n",
    "        'optimizer': ['SGD', 'Adam', 'RMSprop'],\n",
    "        'metrics': ['accuracy'],\n",
    "    },\n",
    "    1: {\n",
    "        'input_size': [17],\n",
    "        'hidden_size': [2, 3, 4],\n",
    "        'learning_rate': [float(i/100) for i in range(1,101,5)] + [0.999, 0.9999],\n",
    "        'batch_size': [7, 8, 9, 15, 16, 17, 31, 32, 33, 62, 63, 64, 65],\n",
    "        'epochs': [int(250+epochs) for epochs in range(0,200,20)],\n",
    "        'weight_decay': [float(i/1000) for i in range(1,101,5)] + [0.001, 0.0001],\n",
    "        'momentum': [float(i/100) for i in range(50,90,5)],\n",
    "        'hidden_activation': ['Tanh', 'ReLU'],\n",
    "        'optimizer': ['SGD', 'Adam', 'RMSprop'],\n",
    "        'metrics': ['accuracy'],\n",
    "    },\n",
    "    2: {\n",
    "        'input_size': [17],\n",
    "        'hidden_size': [2, 3, 4],\n",
    "        'learning_rate': [float(i/10) for i in range(1,10)] + [float(i/100) for i in range(1,10)] + [float(i/1000) for i in range(1,10)],\n",
    "        'batch_size': [7, 8, 9, 15, 16, 17, 31, 32, 33, 62, 63, 64, 65],\n",
    "        'epochs': [int(350+epochs) for epochs in range(0,50,10)],\n",
    "        'weight_decay': [float(i/1000) for i in range(1,10)] + [float(i/100) for i in range(1,10)] + [float(i/10) for i in range(1,10)],\n",
    "        'momentum': [float(i/1000) for i in range(10,90,5)] + [float(i/100) for i in range(10,90,5)],\n",
    "        'hidden_activation': ['Tanh', 'ReLU'],\n",
    "        'optimizer': ['SGD', 'Adam', 'RMSprop'],\n",
    "        'metrics': ['accuracy'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyperparameters Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.999, 'batch_size': 7, 'epochs': 360, 'weight_decay': 0.3, 'momentum': 0.02, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7043170068230906\n",
      " Mean Validation Loss:     0.7232362154498694\n",
      " Mean Training Accuracy:   0.48434656084654815\n",
      " Mean Validation Accuracy: 0.4990625000000002\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.999, 'batch_size': 7, 'epochs': 360, 'weight_decay': 0.3, 'momentum': 0.02, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7043170068230906\n",
      " Mean Validation Loss:     0.7232362154498694\n",
      " Mean Training Accuracy:   0.48434656084654815\n",
      " Mean Validation Accuracy: 0.4990625000000002\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.99, 'batch_size': 32, 'epochs': 370, 'weight_decay': 0.7, 'momentum': 0.01, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7001635420845947\n",
      " Mean Validation Loss:     0.6975977221695158\n",
      " Mean Training Accuracy:   0.4946551238738746\n",
      " Mean Validation Accuracy: 0.4997189189189191\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.999, 'batch_size': 7, 'epochs': 360, 'weight_decay': 0.3, 'momentum': 0.02, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7043170068230906\n",
      " Mean Validation Loss:     0.7232362154498694\n",
      " Mean Training Accuracy:   0.48434656084654815\n",
      " Mean Validation Accuracy: 0.4990625000000002\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    3\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.09, 'batch_size': 15, 'epochs': 370, 'weight_decay': 0.1, 'momentum': 0.8, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6948929951411871\n",
      " Mean Validation Loss:     0.6935184141912971\n",
      " Mean Training Accuracy:   0.47295409695408613\n",
      " Mean Validation Accuracy: 0.4927057057057044\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.99, 'batch_size': 32, 'epochs': 370, 'weight_decay': 0.7, 'momentum': 0.01, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7001635420845947\n",
      " Mean Validation Loss:     0.6975977221695158\n",
      " Mean Training Accuracy:   0.4946551238738746\n",
      " Mean Validation Accuracy: 0.4997189189189191\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    4\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.999, 'batch_size': 62, 'epochs': 350, 'weight_decay': 0.01, 'momentum': 0.7, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.341794015118053\n",
      " Mean Validation Loss:     1.3459252368552366\n",
      " Mean Training Accuracy:   0.4988416922865137\n",
      " Mean Validation Accuracy: 0.5043761904761899\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.99, 'batch_size': 32, 'epochs': 370, 'weight_decay': 0.7, 'momentum': 0.01, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7001635420845947\n",
      " Mean Validation Loss:     0.6975977221695158\n",
      " Mean Training Accuracy:   0.4946551238738746\n",
      " Mean Validation Accuracy: 0.4997189189189191\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    5\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.06, 'batch_size': 62, 'epochs': 370, 'weight_decay': 0.8, 'momentum': 0.04, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6942785184125645\n",
      " Mean Validation Loss:     0.6933953376074092\n",
      " Mean Training Accuracy:   0.4759365206531706\n",
      " Mean Validation Accuracy: 0.4998657657657659\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    4\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.999, 'batch_size': 62, 'epochs': 350, 'weight_decay': 0.01, 'momentum': 0.7, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.341794015118053\n",
      " Mean Validation Loss:     1.3459252368552366\n",
      " Mean Training Accuracy:   0.4988416922865137\n",
      " Mean Validation Accuracy: 0.5043761904761899\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    6\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.05, 'batch_size': 7, 'epochs': 380, 'weight_decay': 0.6, 'momentum': 0.3, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6942130111058594\n",
      " Mean Validation Loss:     0.6933714778407609\n",
      " Mean Training Accuracy:   0.4723458646616345\n",
      " Mean Validation Accuracy: 0.49903508771929767\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    4\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.999, 'batch_size': 62, 'epochs': 350, 'weight_decay': 0.01, 'momentum': 0.7, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.341794015118053\n",
      " Mean Validation Loss:     1.3459252368552366\n",
      " Mean Training Accuracy:   0.4988416922865137\n",
      " Mean Validation Accuracy: 0.5043761904761899\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    4\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.999, 'batch_size': 62, 'epochs': 350, 'weight_decay': 0.01, 'momentum': 0.7, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.341794015118053\n",
      " Mean Validation Loss:     1.3459252368552366\n",
      " Mean Training Accuracy:   0.4988416922865137\n",
      " Mean Validation Accuracy: 0.5043761904761899\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    8\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.8, 'batch_size': 33, 'epochs': 380, 'weight_decay': 0.7, 'momentum': 0.02, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6978067994901993\n",
      " Mean Validation Loss:     0.6961150334697027\n",
      " Mean Training Accuracy:   0.4919906299840542\n",
      " Mean Validation Accuracy: 0.49924210526315815\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    9\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.4, 'batch_size': 16, 'epochs': 370, 'weight_decay': 0.5, 'momentum': 0.8, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6988529985107541\n",
      " Mean Validation Loss:     0.6993025011146389\n",
      " Mean Training Accuracy:   0.4769095881595879\n",
      " Mean Validation Accuracy: 0.49802927927927926\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    10\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.06, 'batch_size': 65, 'epochs': 350, 'weight_decay': 0.5, 'momentum': 0.4, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6936430414404182\n",
      " Mean Validation Loss:     0.693473066295897\n",
      " Mean Training Accuracy:   0.4922826484439928\n",
      " Mean Validation Accuracy: 0.4886171428571477\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    11\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.07, 'batch_size': 17, 'epochs': 350, 'weight_decay': 0.8, 'momentum': 0.04, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.693930391050521\n",
      " Mean Validation Loss:     0.6932911905220569\n",
      " Mean Training Accuracy:   0.47998932906495506\n",
      " Mean Validation Accuracy: 0.4975387154861949\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    12\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.8, 'batch_size': 9, 'epochs': 370, 'weight_decay': 0.0001, 'momentum': 0.3, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       2.710728369086512\n",
      " Mean Validation Loss:     2.745082419560298\n",
      " Mean Training Accuracy:   0.48732303732304594\n",
      " Mean Validation Accuracy: 0.4999570999570975\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    13\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.8, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.001, 'momentum': 0.03, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.1702593358794338\n",
      " Mean Validation Loss:     1.3885795405900878\n",
      " Mean Training Accuracy:   0.49562925170068134\n",
      " Mean Validation Accuracy: 0.500288737717309\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    14\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.4, 'batch_size': 62, 'epochs': 380, 'weight_decay': 0.2, 'momentum': 0.3, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6945352322804293\n",
      " Mean Validation Loss:     0.6939890849590304\n",
      " Mean Training Accuracy:   0.4931338285832975\n",
      " Mean Validation Accuracy: 0.49770526315789587\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    15\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 63, 'epochs': 370, 'weight_decay': 0.6, 'momentum': 0.06, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.693573089483622\n",
      " Mean Validation Loss:     0.6932988625603751\n",
      " Mean Training Accuracy:   0.4837010272821065\n",
      " Mean Validation Accuracy: 0.49347027027027374\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    16\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.08, 'batch_size': 16, 'epochs': 350, 'weight_decay': 0.0001, 'momentum': 0.2, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.41564949518521416\n",
      " Mean Validation Loss:     0.42829213077255657\n",
      " Mean Training Accuracy:   0.801413265306125\n",
      " Mean Validation Accuracy: 0.795363095238098\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    17\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.08, 'batch_size': 62, 'epochs': 370, 'weight_decay': 0.8, 'momentum': 0.04, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6933368624545421\n",
      " Mean Validation Loss:     0.6932666209903928\n",
      " Mean Training Accuracy:   0.4947554136525353\n",
      " Mean Validation Accuracy: 0.4965405405405421\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.04, 'batch_size': 65, 'epochs': 370, 'weight_decay': 0.1, 'momentum': 0.04, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6930361358217284\n",
      " Mean Validation Loss:     0.6933369323047435\n",
      " Mean Training Accuracy:   0.50244265273677\n",
      " Mean Validation Accuracy: 0.49407567567567917\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.03, 'batch_size': 31, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.329043344941714\n",
      " Mean Validation Loss:     0.4497426190806763\n",
      " Mean Training Accuracy:   0.8762998165216322\n",
      " Mean Validation Accuracy: 0.8038731481481404\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    20\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.09, 'batch_size': 7, 'epochs': 350, 'weight_decay': 0.01, 'momentum': 0.02, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.4637648339150916\n",
      " Mean Validation Loss:     0.588308884391295\n",
      " Mean Training Accuracy:   0.806582312925156\n",
      " Mean Validation Accuracy: 0.7232840136054245\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    21\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.3, 'batch_size': 8, 'epochs': 350, 'weight_decay': 0.0001, 'momentum': 0.03, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7494316713259787\n",
      " Mean Validation Loss:     0.7313883116012225\n",
      " Mean Training Accuracy:   0.47782967032967016\n",
      " Mean Validation Accuracy: 0.5024812030075186\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    22\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.5, 'batch_size': 62, 'epochs': 390, 'weight_decay': 0.6, 'momentum': 0.03, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.778197490939727\n",
      " Mean Validation Loss:     0.7845812679559756\n",
      " Mean Training Accuracy:   0.48720683658714176\n",
      " Mean Validation Accuracy: 0.49893931623931675\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    23\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.7, 'batch_size': 16, 'epochs': 360, 'weight_decay': 0.5, 'momentum': 0.04, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.8910276605419464\n",
      " Mean Validation Loss:     0.939952115209566\n",
      " Mean Training Accuracy:   0.4933548280423285\n",
      " Mean Validation Accuracy: 0.500038580246913\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    24\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.999, 'batch_size': 16, 'epochs': 380, 'weight_decay': 0.9, 'momentum': 0.05, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.19466218292217\n",
      " Mean Validation Loss:     1.2792021286801274\n",
      " Mean Training Accuracy:   0.49729636591478693\n",
      " Mean Validation Accuracy: 0.4999835526315793\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    25\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.1, 'batch_size': 7, 'epochs': 380, 'weight_decay': 0.3, 'momentum': 0.03, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6982903821029146\n",
      " Mean Validation Loss:     0.6985400767310677\n",
      " Mean Training Accuracy:   0.4752631578947253\n",
      " Mean Validation Accuracy: 0.5000657894736883\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    26\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.08, 'batch_size': 32, 'epochs': 370, 'weight_decay': 0.2, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6945934032346739\n",
      " Mean Validation Loss:     0.6943822501801158\n",
      " Mean Training Accuracy:   0.49801942567567514\n",
      " Mean Validation Accuracy: 0.4989621621621624\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    27\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.999, 'batch_size': 65, 'epochs': 360, 'weight_decay': 0.1, 'momentum': 0.4, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7033986005932097\n",
      " Mean Validation Loss:     0.7040190935466023\n",
      " Mean Training Accuracy:   0.49328041729512395\n",
      " Mean Validation Accuracy: 0.49933333333333446\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    28\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.07, 'batch_size': 8, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.8, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6696443924396969\n",
      " Mean Validation Loss:     0.6909199712863354\n",
      " Mean Training Accuracy:   0.6109205840455849\n",
      " Mean Validation Accuracy: 0.5923062865497045\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    29\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.99, 'batch_size': 32, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.1, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.9415387838842192\n",
      " Mean Validation Loss:     1.1593405011296292\n",
      " Mean Training Accuracy:   0.4962514467592593\n",
      " Mean Validation Accuracy: 0.5023268518518498\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     1\n",
      " Trial:                    30\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.1, 'batch_size': 63, 'epochs': 350, 'weight_decay': 0.7, 'momentum': 0.05, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6951419481209336\n",
      " Mean Validation Loss:     0.6943133325576781\n",
      " Mean Training Accuracy:   0.4723500643500583\n",
      " Mean Validation Accuracy: 0.49667714285714304\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "### Best Hyperparameters of Monk 1 ###\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.81, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.081, 'momentum': 0.75, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6835776576321377\n",
      " Mean Validation Loss:     0.6871794103745907\n",
      " Mean Training Accuracy:   0.584248120300662\n",
      " Mean Validation Accuracy: 0.5766950113378682\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.81, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.081, 'momentum': 0.75, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6835776576321377\n",
      " Mean Validation Loss:     0.6871794103745907\n",
      " Mean Training Accuracy:   0.584248120300662\n",
      " Mean Validation Accuracy: 0.5766950113378682\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.81, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.081, 'momentum': 0.75, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6835776576321377\n",
      " Mean Validation Loss:     0.6871794103745907\n",
      " Mean Training Accuracy:   0.584248120300662\n",
      " Mean Validation Accuracy: 0.5766950113378682\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    3\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.86, 'batch_size': 33, 'epochs': 310, 'weight_decay': 0.081, 'momentum': 0.75, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6797272234155284\n",
      " Mean Validation Loss:     0.6925283762609666\n",
      " Mean Training Accuracy:   0.592404692082111\n",
      " Mean Validation Accuracy: 0.5570326925165723\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    4\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.71, 'batch_size': 9, 'epochs': 290, 'weight_decay': 0.071, 'momentum': 0.75, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6824146387621982\n",
      " Mean Validation Loss:     0.6836530427506238\n",
      " Mean Training Accuracy:   0.5881730187537054\n",
      " Mean Validation Accuracy: 0.5824001094690807\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    5\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.9999, 'batch_size': 63, 'epochs': 410, 'weight_decay': 0.011, 'momentum': 0.65, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.9788801348291153\n",
      " Mean Validation Loss:     1.057786707180303\n",
      " Mean Training Accuracy:   0.5635251000129078\n",
      " Mean Validation Accuracy: 0.5479457414895057\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    6\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.86, 'batch_size': 17, 'epochs': 410, 'weight_decay': 0.076, 'momentum': 0.55, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6730185395043093\n",
      " Mean Validation Loss:     0.6686085989126329\n",
      " Mean Training Accuracy:   0.6159103748207122\n",
      " Mean Validation Accuracy: 0.6179357962697227\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    7\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.41, 'batch_size': 17, 'epochs': 390, 'weight_decay': 0.081, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.71150678125616\n",
      " Mean Validation Loss:     0.7088753443574304\n",
      " Mean Training Accuracy:   0.5666190610860162\n",
      " Mean Validation Accuracy: 0.5691053921568634\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    8\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.11, 'batch_size': 15, 'epochs': 370, 'weight_decay': 0.041, 'momentum': 0.7, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6669460235730467\n",
      " Mean Validation Loss:     0.6652888096828716\n",
      " Mean Training Accuracy:   0.6206227967097983\n",
      " Mean Validation Accuracy: 0.6213693693693457\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    9\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.91, 'batch_size': 15, 'epochs': 370, 'weight_decay': 0.011, 'momentum': 0.6, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7482002059814161\n",
      " Mean Validation Loss:     0.7506964598382966\n",
      " Mean Training Accuracy:   0.558119858989454\n",
      " Mean Validation Accuracy: 0.566147147147135\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    10\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.66, 'batch_size': 7, 'epochs': 370, 'weight_decay': 0.001, 'momentum': 0.7, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       4.1698266924502905\n",
      " Mean Validation Loss:     4.243176081453429\n",
      " Mean Training Accuracy:   0.5482799227799352\n",
      " Mean Validation Accuracy: 0.5444998712998691\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    11\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.999, 'batch_size': 63, 'epochs': 310, 'weight_decay': 0.071, 'momentum': 0.65, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.671883438492334\n",
      " Mean Validation Loss:     0.6717527051894887\n",
      " Mean Training Accuracy:   0.61471445639189\n",
      " Mean Validation Accuracy: 0.6078454372951546\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    12\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.96, 'batch_size': 16, 'epochs': 310, 'weight_decay': 0.036, 'momentum': 0.7, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7102622283327523\n",
      " Mean Validation Loss:     0.7099947731957951\n",
      " Mean Training Accuracy:   0.5747535842293876\n",
      " Mean Validation Accuracy: 0.5732795698924719\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    13\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.21, 'batch_size': 32, 'epochs': 270, 'weight_decay': 0.066, 'momentum': 0.8, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6676945338779033\n",
      " Mean Validation Loss:     0.6683049602751373\n",
      " Mean Training Accuracy:   0.6213802910052909\n",
      " Mean Validation Accuracy: 0.6169328703703707\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    14\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.81, 'batch_size': 15, 'epochs': 290, 'weight_decay': 0.011, 'momentum': 0.5, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7374331424206864\n",
      " Mean Validation Loss:     0.7440474200026062\n",
      " Mean Training Accuracy:   0.5632033983008822\n",
      " Mean Validation Accuracy: 0.5650881226053595\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    15\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.11, 'batch_size': 31, 'epochs': 350, 'weight_decay': 0.041, 'momentum': 0.6, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.665366458180972\n",
      " Mean Validation Loss:     0.6646326522656859\n",
      " Mean Training Accuracy:   0.6213861192571133\n",
      " Mean Validation Accuracy: 0.6216635944700413\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.01, 'batch_size': 17, 'epochs': 370, 'weight_decay': 0.031, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6632393084546975\n",
      " Mean Validation Loss:     0.6638740708376928\n",
      " Mean Training Accuracy:   0.6212860194754328\n",
      " Mean Validation Accuracy: 0.6213751987281386\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    16\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.06, 'batch_size': 31, 'epochs': 310, 'weight_decay': 0.086, 'momentum': 0.8, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6662437093757818\n",
      " Mean Validation Loss:     0.6653770758163552\n",
      " Mean Training Accuracy:   0.6208674991328398\n",
      " Mean Validation Accuracy: 0.6227662157474833\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    15\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.11, 'batch_size': 31, 'epochs': 350, 'weight_decay': 0.041, 'momentum': 0.6, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.665366458180972\n",
      " Mean Validation Loss:     0.6646326522656859\n",
      " Mean Training Accuracy:   0.6213861192571133\n",
      " Mean Validation Accuracy: 0.6216635944700413\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    17\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.76, 'batch_size': 16, 'epochs': 330, 'weight_decay': 0.081, 'momentum': 0.75, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.675974929531414\n",
      " Mean Validation Loss:     0.6734160826964806\n",
      " Mean Training Accuracy:   0.6057335257335222\n",
      " Mean Validation Accuracy: 0.6044570707070716\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    16\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.06, 'batch_size': 31, 'epochs': 310, 'weight_decay': 0.086, 'momentum': 0.8, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6662437093757818\n",
      " Mean Validation Loss:     0.6653770758163552\n",
      " Mean Training Accuracy:   0.6208674991328398\n",
      " Mean Validation Accuracy: 0.6227662157474833\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    16\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.06, 'batch_size': 31, 'epochs': 310, 'weight_decay': 0.086, 'momentum': 0.8, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6662437093757818\n",
      " Mean Validation Loss:     0.6653770758163552\n",
      " Mean Training Accuracy:   0.6208674991328398\n",
      " Mean Validation Accuracy: 0.6227662157474833\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.71, 'batch_size': 8, 'epochs': 430, 'weight_decay': 0.091, 'momentum': 0.6, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.0798511639352542\n",
      " Mean Validation Loss:     0.9883312438525642\n",
      " Mean Training Accuracy:   0.5477335352745842\n",
      " Mean Validation Accuracy: 0.5520116279069759\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    20\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.11, 'batch_size': 62, 'epochs': 410, 'weight_decay': 0.031, 'momentum': 0.75, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6648111225095223\n",
      " Mean Validation Loss:     0.6642720870855384\n",
      " Mean Training Accuracy:   0.6209481121203824\n",
      " Mean Validation Accuracy: 0.6213760271292814\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    21\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.51, 'batch_size': 62, 'epochs': 410, 'weight_decay': 0.076, 'momentum': 0.8, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6688662932849498\n",
      " Mean Validation Loss:     0.6673384544326044\n",
      " Mean Training Accuracy:   0.6199107916298741\n",
      " Mean Validation Accuracy: 0.6205686709273752\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    22\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.31, 'batch_size': 65, 'epochs': 270, 'weight_decay': 0.076, 'momentum': 0.55, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6707962580595503\n",
      " Mean Validation Loss:     0.6705572153462295\n",
      " Mean Training Accuracy:   0.6131851851851673\n",
      " Mean Validation Accuracy: 0.6135452564864357\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    23\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.51, 'batch_size': 63, 'epochs': 310, 'weight_decay': 0.066, 'momentum': 0.75, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.377840759254272\n",
      " Mean Validation Loss:     1.4582138722173617\n",
      " Mean Training Accuracy:   0.5705021334698857\n",
      " Mean Validation Accuracy: 0.5635765625898473\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    24\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.66, 'batch_size': 7, 'epochs': 330, 'weight_decay': 0.071, 'momentum': 0.5, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6785521478562659\n",
      " Mean Validation Loss:     0.6807203050237703\n",
      " Mean Training Accuracy:   0.5990721500721914\n",
      " Mean Validation Accuracy: 0.5866568542568468\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    25\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.9999, 'batch_size': 32, 'epochs': 370, 'weight_decay': 0.021, 'momentum': 0.7, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       1.366748993752272\n",
      " Mean Validation Loss:     1.4670022022417444\n",
      " Mean Training Accuracy:   0.5231385135135136\n",
      " Mean Validation Accuracy: 0.5250506756756751\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    26\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.26, 'batch_size': 9, 'epochs': 370, 'weight_decay': 0.096, 'momentum': 0.8, 'hidden_activation': 'Tanh', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6742611320119647\n",
      " Mean Validation Loss:     0.6700624623814125\n",
      " Mean Training Accuracy:   0.6122056266791909\n",
      " Mean Validation Accuracy: 0.6116312741312689\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    27\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.51, 'batch_size': 65, 'epochs': 330, 'weight_decay': 0.041, 'momentum': 0.8, 'hidden_activation': 'ReLU', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.9247023362224221\n",
      " Mean Validation Loss:     1.0078489501909802\n",
      " Mean Training Accuracy:   0.5357244237244188\n",
      " Mean Validation Accuracy: 0.5300383514287259\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    28\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 3, 'learning_rate': 0.21, 'batch_size': 65, 'epochs': 390, 'weight_decay': 0.076, 'momentum': 0.65, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6700192455552577\n",
      " Mean Validation Loss:     0.6690091012074392\n",
      " Mean Training Accuracy:   0.6156515450361549\n",
      " Mean Validation Accuracy: 0.6173275743864164\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    29\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.66, 'batch_size': 7, 'epochs': 370, 'weight_decay': 0.091, 'momentum': 0.75, 'hidden_activation': 'ReLU', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.691039882792612\n",
      " Mean Validation Loss:     0.6896818590067534\n",
      " Mean Training Accuracy:   0.5766164736164954\n",
      " Mean Validation Accuracy: 0.5776133848133731\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     2\n",
      " Trial:                    30\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.46, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.031, 'momentum': 0.5, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.6859686864890067\n",
      " Mean Validation Loss:     0.6879357053339481\n",
      " Mean Training Accuracy:   0.5998830409355538\n",
      " Mean Validation Accuracy: 0.6041802721088397\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "### Best Hyperparameters of Monk 2 ###\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     3\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.006, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.006, 'momentum': 0.7, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.06315215589788117\n",
      " Mean Validation Loss:     0.23690538572627876\n",
      " Mean Training Accuracy:   0.9860677179963016\n",
      " Mean Validation Accuracy: 0.9153469387754908\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     3\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.006, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.006, 'momentum': 0.7, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.06315215589788117\n",
      " Mean Validation Loss:     0.23690538572627876\n",
      " Mean Training Accuracy:   0.9860677179963016\n",
      " Mean Validation Accuracy: 0.9153469387754908\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     3\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.007, 'batch_size': 32, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.5, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.14151567635540938\n",
      " Mean Validation Loss:     0.24392057843713347\n",
      " Mean Training Accuracy:   0.9684765625\n",
      " Mean Validation Accuracy: 0.9278018518518564\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     3\n",
      " Trial:                    1\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.006, 'batch_size': 9, 'epochs': 350, 'weight_decay': 0.006, 'momentum': 0.7, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.06315215589788117\n",
      " Mean Validation Loss:     0.23690538572627876\n",
      " Mean Training Accuracy:   0.9860677179963016\n",
      " Mean Validation Accuracy: 0.9153469387754908\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------ Current Hyperparameters ------------------\n",
      " Monk:                     3\n",
      " Trial:                    3\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.4, 'batch_size': 31, 'epochs': 350, 'weight_decay': 0.1, 'momentum': 0.085, 'hidden_activation': 'Tanh', 'optimizer': 'RMSprop', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.7195823708432069\n",
      " Mean Validation Loss:     0.7277001131602696\n",
      " Mean Training Accuracy:   0.4789449308755817\n",
      " Mean Validation Accuracy: 0.49995714285714277\n",
      "-------------------- Best Hyperparameters -------------------\n",
      " Monk:                     3\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.007, 'batch_size': 32, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.5, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.14151567635540938\n",
      " Mean Validation Loss:     0.24392057843713347\n",
      " Mean Training Accuracy:   0.9684765625\n",
      " Mean Validation Accuracy: 0.9278018518518564\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     x_kfold_train, x_kfold_val \u001b[38;5;241m=\u001b[39m X[train_index], X[val_index]\n\u001b[0;32m     33\u001b[0m     y_kfold_train, y_kfold_val \u001b[38;5;241m=\u001b[39m y[train_index], y[val_index]\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mnn_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_kfold_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_kfold_val\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Case of first append\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nn) \u001b[38;5;241m==\u001b[39m dataset_i:\n",
      "File \u001b[1;32mc:\\Users\\corra\\Documents\\GitHub\\Machine_Learning_Project\\api\\pytorch\\binary_nn.py:318\u001b[0m, in \u001b[0;36mBinaryNN.fit\u001b[1;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m    315\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# Optimization\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[0;32m    321\u001b[0m batch_pred_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mround(tr_outputs)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\corra\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:324\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(params):\n\u001b[0;32m    323\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grads[i] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m maximize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mgrads[i]\n\u001b[1;32m--> 324\u001b[0m     exp_avg \u001b[38;5;241m=\u001b[39m \u001b[43mexp_avgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    325\u001b[0m     exp_avg_sq \u001b[38;5;241m=\u001b[39m exp_avg_sqs[i]\n\u001b[0;32m    326\u001b[0m     step_t \u001b[38;5;241m=\u001b[39m state_steps[i]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from api.pytorch.binary_nn import BinaryNN\n",
    "\n",
    "# Creation of a BinaryNN objct for each dataset\n",
    "nn: list[BinaryNN] = []\n",
    "\n",
    "# Different values per dataset\n",
    "trials_list = [10, 10, 10]   # 30, 30, 50\n",
    "k_values = [5, 5, 5]\n",
    "n_hidden_layers_list = [0, 1, 1]\n",
    "\n",
    "# Search of the best Hyperparameters to each Training set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_train[dataset_i].values.astype(dtype=float)\n",
    "    y = y_train[dataset_i].values.astype(dtype=float)\n",
    "    k = k_values[dataset_i]\n",
    "\n",
    "    # K-fold Cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # For each iteration we choose the hyperparameters (randomly) and we use them with K-fold CV\n",
    "    for i in range(trials_list[dataset_i]):\n",
    "        \n",
    "        # Random parameters\n",
    "        params = data_handler.random_dictionary(param_space[dataset_i])\n",
    "\n",
    "        # Creation of the Neural Network object\n",
    "        nn_i = BinaryNN(params=params, monk_i=dataset_i+1, trial=i+1, n_hidden_layers=n_hidden_layers_list[dataset_i])\n",
    "\n",
    "        # For each K-fold returns the indexes of the data splitted in: <X_train,y_train> and <X_val,y_val>\n",
    "        for train_index, val_index in kfold.split(X, y):\n",
    "            x_kfold_train, x_kfold_val = X[train_index], X[val_index]\n",
    "            y_kfold_train, y_kfold_val = y[train_index], y[val_index]\n",
    "\n",
    "            nn_i.fit(\n",
    "                x_train=x_kfold_train,\n",
    "                y_train=y_kfold_train,\n",
    "                x_val=x_kfold_val,\n",
    "                y_val=y_kfold_val\n",
    "            )\n",
    "\n",
    "        # Case of first append\n",
    "        if len(nn) == dataset_i:\n",
    "            nn.append(nn_i)\n",
    "        \n",
    "        # Print the results of this trial\n",
    "        print(\"\\n------------------ Current Hyperparameters ------------------\")\n",
    "        nn_i.print_training_info()\n",
    "        print(\"-------------------- Best Hyperparameters -------------------\")\n",
    "        nn[dataset_i].print_training_info()\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # Update best hyperparameters if: no high overfitting AND (higher mean VL accuracy OR (equal mean AND\n",
    "        if nn_i.mean_tr_accuracy-0.1 <= nn_i.mean_vl_accuracy \\\n",
    "            and (\n",
    "                    nn[dataset_i].mean_vl_accuracy < nn_i.mean_vl_accuracy \\\n",
    "                or (\n",
    "                    nn[dataset_i].mean_vl_accuracy == nn_i.mean_vl_accuracy and nn[dataset_i].mean_tr_accuracy < nn_i.mean_tr_accuracy\n",
    "                    )\n",
    "            ):\n",
    "            nn[dataset_i] = nn_i\n",
    "        \n",
    "        # Case of TR/VL accuracy = 1.0 AND TR/VL loss minor\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy == 1 \\\n",
    "            and nn_i.mean_tr_accuracy == nn[dataset_i].mean_tr_accuracy \\\n",
    "            and nn_i.mean_vl_accuracy == nn[dataset_i].mean_vl_accuracy \\\n",
    "            and abs(nn_i.mean_tr_accuracy - nn_i.mean_vl_accuracy) < 0.02 \\\n",
    "            and nn_i.mean_vl_loss < nn[dataset_i].mean_vl_loss \\\n",
    "            and nn_i.mean_tr_loss < nn[dataset_i].mean_tr_loss:\n",
    "            nn[dataset_i] = nn_i\n",
    "        \n",
    "        # Exit case\n",
    "        if nn_i.mean_tr_accuracy == 1 and nn_i.mean_vl_accuracy == 1 \\\n",
    "            and nn_i.mean_vl_loss < 0.1 and nn_i.mean_tr_loss < 0.1 \\\n",
    "            and abs(nn_i.mean_vl_loss - nn_i.mean_tr_loss) < 0.01:\n",
    "            nn[dataset_i] = nn_i\n",
    "            break\n",
    "\n",
    "    # Print output\n",
    "    print(f\"### Best Hyperparameters of Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print of best Hyperparameters and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Best Hyperparameters for Monk 1 ###\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29447874151568015\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946706649832106\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "### Best Hyperparameters for Monk 2 ###\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.0082272038385272\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976907142857142\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "### Best Hyperparameters for Monk 3 ###\n",
      " Monk:                     3\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.007, 'batch_size': 32, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.5, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.14151567635540938\n",
      " Mean Validation Loss:     0.24392057843713347\n",
      " Mean Training Accuracy:   0.9684765625\n",
      " Mean Validation Accuracy: 0.9278018518518564\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt9UlEQVR4nO3deXxU1f3/8dcnCwkQ9qAii4EWSIWQEGJQQAkFW1wKylKgWo18RaVWKjxaQevCt36ptuXXKt+Kllrlq7Wg1ULRIlgQxYoLi6hEQVmiIIosEoJhSWbO74+ZDJMwWcCEyR3ez8cjj9y599xzP2cInzlz7r3nmnMOERHxvrhoByAiInVDCV1EJEYooYuIxAgldBGRGKGELiISI5TQRURihBK6nBbM7EIz2xTtOETqkxK61DszKzSzIdGMwTn3mnOue33Vb2bfN7OVZlZsZrvN7FUzG1ZfxxOJRAldYoKZxUfx2KOAvwNPAB2AM4G7gR+cRF1mZvp/KSdFfzgSNWYWZ2bTzGyLme01s2fMrHXY9r+b2RdmVhTs/fYI2zbXzB42s8Vm9jUwKPhN4Odm9l5wn6fNLDlYPs/MdoTtX2XZ4PbbzOxzM9tpZtebmTOzb0dogwG/B+51zj3qnCtyzvmdc6865yYEy0w3s7+G7ZMWrC8h+PoVM5thZq8DJcAdZram0nEmm9mi4HKSmc00s0/NbJeZPWJmjb/hP4fEACV0iaZJwBXAQOBs4CvgobDtLwJdgTOAdcBTlfb/ETADaAb8J7juh8BQoDPQC8iv5vgRy5rZUGAKMAT4djC+qnQHOgLPVlOmNn4M3ECgLf8LdDezrmHbfwT8Lbj8G6AbkBWMrz2BbwRymlNCl2i6Efilc26Hc+4IMB0YVd5zdc495pwrDtuWaWYtwvb/p3Pu9WCP+HBw3Szn3E7n3D7geQJJrypVlf0h8LhzrsA5VwL8dzV1tAn+/ryWba7K3ODxypxzRcA/gXEAwcSeDiwKfiOYAEx2zu1zzhUDvwbGfsPjSwxQQpdoOgdYYGb7zWw/8CHgA840s3gzuz84HHMAKAzukxq2//YIdX4RtlwCpFRz/KrKnl2p7kjHKbc3+LtdNWVqo/Ix/kYwoRPonS8Mfri0BZoAa8PetyXB9XKaU0KXaNoOXOKcaxn2k+yc+4xAEhtOYNijBZAW3MfC9q+vqUI/J3Bys1zHaspuItCOkdWU+ZpAEi53VoQyldvyEpBqZlkEEnv5cMse4BDQI+w9a+Gcq+6DS04TSuhyqiSaWXLYTwLwCDDDzM4BMLO2ZjY8WL4ZcIRAD7gJgWGFU+UZ4Doz+46ZNaGa8WkXmH96CnCXmV1nZs2DJ3sHmNmcYLH1wEVm1ik4ZHR7TQE458oIjMv/DmgN/Du43g/8GfiDmZ0BYGbtzez7J9tYiR1K6HKqLCbQsyz/mQ48CCwCXjKzYuBNoG+w/BPAJ8BnwAfBbaeEc+5FYBawAtgMvBHcdKSK8s8CY4DxwE5gF/A/BMbBcc79G3gaeA9YC7xQy1D+RuAbyt+DCb7c1GBcbwaHo5YRODkrpznTAy5Eqmdm3wE2AEmVEqtIg6IeukgEZnalmTUys1YELhN8XslcGjoldJHIbgR2A1sIXHkzMbrhiNRMQy4iIjFCPXQRkRiREK0Dp6amurS0tGgdXkTEk9auXbvHORfxRrKoJfS0tDTWrFlTc0EREQkxs0+q2qYhFxGRGKGELiISI5TQRURihBK6iEiMUEIXEYkRNSZ0M3vMzL40sw1VbDczm2Vmm4OP88qu+zBFRKQmtemhzyXwmK6qXELgMWFdCTxC6+FvHpaIiJyoGq9Dd86tNLO0aooMB54Izgv9ppm1NLN2zrlv+kiuKh187T9snzCBf/QzOrZII7Vxm5p3Es8pa9yITy/vHe0wROpc9hnZ9Gvfr87rrYsbi9pT8fFZO4LrjkvoZnYDgV48nTp1OukDbp8wAYARqxx+tgHbTrouabj2Noc7O62OdhgidW58z/ENNqFbhHURZ/xyzs0B5gDk5OR841nB/pVj/N/F8bx/7fvftCppoN6LdgAiHlIXV7nsoOIzFzsQeGpL/Yv0USIicpqqi4S+CLgmeLXL+UBRfY6fh9PEvyIix9Q45GJm84A8Ak8g3wHcAyQCOOceIfCsyEsJPOOwBLiuvoKtzKmHLiISUpurXMbVsN0BN9dZRCIiclJ0p6iISIzwdELXkIuIyDHeTujRDkBEpAHxdELXZYsiIsd4OqGrhy4icoy3E7p66CIiIZ5O6F+0UkYXESnn6YT+RroSuohIOU8ndA25iIgc4+mELiIix3g6oauHLiJyjLcTerQDEBFpQDyd0HVjkYjIMZ5O6Oqhi4gc4+mELiIix3g6oeukqIjIMZ5O6CIicoynE7p66CIix3g7oUc7ABGRBsTTCV2XLYqIHOPphK4euojIMZ5O6CIicoy3E7ppzEVEpJy3E7qIiIR4L6EfLop2BCIiDZL3EvoHi6IdgYhIg+S9hC4iIhF5MKHrYkURkUg8mNBFRCQS7yV0px66iEgk3kvoIiISUa0SupkNNbNNZrbZzKZF2N7CzJ43s3fNrMDMrqv7UMuphy4iEkmNCd3M4oGHgEuAc4FxZnZupWI3Ax845zKBPOD/mVmjOo5VRESqUZseei6w2Tm31Tl3FJgPDK9UxgHNzMyAFGAfUFankYaOpB66iEgktUno7YHtYa93BNeF+yPwHWAn8D7wM+ecv3JFZnaDma0xszW7d+8+yZCV0EVEIqlNQo80A1blrPp9YD1wNpAF/NHMmh+3k3NznHM5zrmctm3bnmCooUpObj8RkRhXm4S+A+gY9roDgZ54uOuAf7iAzcA2IL1uQqzk+I6/iIhQu4S+GuhqZp2DJzrHApUnVPkUGAxgZmcC3YGtdRloVYZ0GnIqDiMi0uAl1FTAOVdmZj8FlgLxwGPOuQIzuym4/RHgXmCumb1PYIhmqnNuT71EXGnI5bcX/bZeDiMi4jU1JnQA59xiYHGldY+ELe8Evle3oVUZTYVXifGJp+awIiINnPfuFNUYuohIRB5M6LrKRUQkEu8ldF2HLiISkecS+hHf0WiHICLSIHkuoX/tV0IXEYnEcwm9+HD9TBEjIuJ1nkvo+w4einYIIiINkucSuq5yERGJzHMJ/auvj0Q7BBGRBsl7Cf2gToqKiETiuYRuwcl8db+oiEhFtZrLpSExcxSeAbtbRJqmXUTk9OW5HnpcMI875XMRkQq8l9AB04UuIiLH8WBCD2Rz5XQRkYo8l9CNyA85FRE53XkuoZePoSuri4hU5LmEbuY03iIiEoH3ErrG0EVEIvJcQo8z02iLiEgEnkvo5clc16GLiFTkuYRe2DJX16GLiETguVv/iW8c7QhE6lxpaSk7duzg8OHD0Q5FGojk5GQ6dOhAYmJirffxXELPTmvNnmgHIVLHduzYQbNmzUhLS8NM44mnO+cce/fuZceOHXTu3LnW+3luyKVzmyaAxtAlthw+fJg2bdoomQsAZkabNm1O+Bub5xK6YRpDl5ikZC7hTubvwXMJ3ek6dJE6tXfvXrKyssjKyuKss86iffv2oddHj1b/QJk1a9YwadKkGo/Rr1+/Oon1lVde4fLLL6+TumKR58bQyz7fTft9sK9ZtCMRiQ1t2rRh/fr1AEyfPp2UlBR+/vOfh7aXlZWRkBA5VeTk5JCTk1PjMVatWlUnsUr1PNdD//gfzwGQ8Yn66CL1JT8/nylTpjBo0CCmTp3K22+/Tb9+/ejduzf9+vVj06ZNQMUe8/Tp0xk/fjx5eXl06dKFWbNmhepLSUkJlc/Ly2PUqFGkp6dz1VVX4YIPfl+8eDHp6ekMGDCASZMmnVBPfN68eWRkZNCzZ0+mTp0KgM/nIz8/n549e5KRkcEf/vAHAGbNmsW5555Lr169GDt27Dd/sxoQz/XQj361P9ohiNSr/36+gA92HqjTOs89uzn3/KDHCe3z0UcfsWzZMuLj4zlw4AArV64kISGBZcuWcccdd/Dcc88dt8/GjRtZsWIFxcXFdO/enYkTJx532d0777xDQUEBZ599Nv379+f1118nJyeHG2+8kZUrV9K5c2fGjRtX6zh37tzJ1KlTWbt2La1ateJ73/seCxcupGPHjnz22Wds2LABgP379wNw//33s23bNpKSkkLrYkWteuhmNtTMNpnZZjObVkWZPDNbb2YFZvZq3YYpIqfa6NGjiY+PB6CoqIjRo0fTs2dPJk+eTEFBQcR9LrvsMpKSkkhNTeWMM85g165dx5XJzc2lQ4cOxMXFkZWVRWFhIRs3bqRLly6hS/ROJKGvXr2avLw82rZtS0JCAldddRUrV66kS5cubN26lVtuuYUlS5bQvHlzAHr16sVVV13FX//61yqHkryqxtaYWTzwEHAxsANYbWaLnHMfhJVpCcwGhjrnPjWzM+opXk2bKzHvRHvS9aVp06ah5bvuuotBgwaxYMECCgsLycvLi7hPUlJSaDk+Pp6ysrJalSkfdjkZVe3bqlUr3n33XZYuXcpDDz3EM888w2OPPca//vUvVq5cyaJFi7j33nspKCiImcRemx56LrDZObfVOXcUmA8Mr1TmR8A/nHOfAjjnvqzbMMMpo4ucakVFRbRv3x6AuXPn1nn96enpbN26lcLCQgCefvrpWu/bt29fXn31Vfbs2YPP52PevHkMHDiQPXv24Pf7GTlyJPfeey/r1q3D7/ezfft2Bg0axG9/+1v279/PwYMH67w90VKbj6X2wPaw1zuAvpXKdAMSzewVoBnwoHPuicoVmdkNwA0AnTp1Opl40aW6IqfebbfdxrXXXsvvf/97vvvd79Z5/Y0bN2b27NkMHTqU1NRUcnNzqyy7fPlyOnToEHr997//nfvuu49BgwbhnOPSSy9l+PDhvPvuu1x33XX4/X4A7rvvPnw+H1dffTVFRUU455g8eTItW7as8/ZEi9X0VcfMRgPfd85dH3z9YyDXOXdLWJk/AjnAYKAx8AZwmXPuo6rqzcnJcWvWrDnhgFf+9Ie0XfY+AD+8PYH3r33/hOsQaWg+/PBDvvOd70Q7jKg6ePAgKSkpOOe4+eab6dq1K5MnT452WFEV6e/CzNY65yJeK1qbIZcdQMew1x2AnRHKLHHOfe2c2wOsBDJrHfWJiK/9RDUi4h1//vOfycrKokePHhQVFXHjjTdGOyTPqc2Qy2qgq5l1Bj4DxhIYMw/3T+CPZpYANCIwJPOHugxURGLb5MmTT/se+TdVY0J3zpWZ2U+BpUA88JhzrsDMbgpuf8Q596GZLQHeA/zAo865DfUSsQbRRUQiqtW1Os65xcDiSuseqfT6d8Dv6i40ERE5EZ679V+XLYqIROa5hJ4Yf+xLhe9wuyhGIiLSsHguoac0OjbNYsm2m6MYiUjsyMvLY+nSpRXWPfDAA/zkJz+pdp/yS48vvfTSiPOiTJ8+nZkzZ1Z77IULF/LBB6Ebz7n77rtZtmzZCUQf2ek41a7nEnrFq+Zj43ZdkWgbN24c8+fPr7Bu/vz5tZ5TZfHixSd9g07lhP6rX/2KIUOGnFRdpzvPJXQNoYvUvVGjRvHCCy9w5MgRAAoLC9m5cycDBgxg4sSJ5OTk0KNHD+65556I+6elpbFnT+BpvzNmzKB79+4MGTIkNM0uBK4zP++888jMzGTkyJGUlJSwatUqFi1axC9+8QuysrLYsmUL+fn5PPvss0DgrtDevXuTkZHB+PHjQ/GlpaVxzz33kJ2dTUZGBhs3bqx1W2N5ql3PdXGdLluUWPfiNPiiju+APisDLrm/ys1t2rQhNzeXJUuWMHz4cObPn8+YMWMwM2bMmEHr1q3x+XwMHjyY9957j169ekWsZ+3atcyfP5933nmHsrIysrOz6dOnDwAjRoxgwoQJANx555385S9/4ZZbbmHYsGFcfvnljBo1qkJdhw8fJj8/n+XLl9OtWzeuueYaHn74YW699VYAUlNTWbduHbNnz2bmzJk8+uijNb4NsT7Vrvd66CJSL8KHXcKHW5555hmys7Pp3bs3BQUFFYZHKnvttde48soradKkCc2bN2fYsGGhbRs2bODCCy8kIyODp556qsopeMtt2rSJzp07061bNwCuvfZaVq5cGdo+YsQIAPr06ROa1KsmsT7VbsOPUOR0U01Puj5dccUVTJkyhXXr1nHo0CGys7PZtm0bM2fOZPXq1bRq1Yr8/Pwan0Rf1cON8/PzWbhwIZmZmcydO5dXXnml2npqmmeqfBreqqbpPZE6Y2WqXe/10DXiIlIvUlJSyMvLY/z48aHe+YEDB2jatCktWrRg165dvPjii9XWcdFFF7FgwQIOHTpEcXExzz//fGhbcXEx7dq1o7S0lKeeeiq0vlmzZhQXFx9XV3p6OoWFhWzevBmAJ598koEDB36jNsb6VLsN96OmCnqSqEj9GTduHCNGjAgNvWRmZtK7d2969OhBly5d6N+/f7X7Z2dnM2bMGLKysjjnnHO48MILQ9vuvfde+vbtyznnnENGRkYoiY8dO5YJEyYwa9as0MlQgOTkZB5//HFGjx5NWVkZ5513HjfddNMJted0m2q3xulz68vJTp+7/s6fkfTsSwBccsVMCu+/rK5DEznlNH2uRFIf0+c2KOqhi4hE5rmErjF0EZHIvJfQRUQkIs8ldA25iIhE5rmErgdciIhE5sGEHu0AREQaJs8ldA25iNStvXv3kpWVRVZWFmeddRbt27cPvT569Gi1+65Zs4ZJkybVeIx+/frVVbgA/OxnP6N9+/ah68YlwHM3FhGl6+ZFYlWbNm1Yv349EJi/PCUlhZ///Oeh7WVlZVXe7p6Tk0NOTsRLoitYtWpVncQK4Pf7WbBgAR07dmTlypXk5eXVWd3hfD4f8fHx9VJ3ffFcD11DLiL1Lz8/nylTpjBo0CCmTp3K22+/Tb9+/ejduzf9+vULTYsb/hCJ6dOnM378ePLy8ujSpQuzZs0K1ZeSkhIqn5eXx6hRo0hPT+eqq64Kza+yePFi0tPTGTBgAJMmTary4RQrVqygZ8+eTJw4kXnz5oXW79q1iyuvvJLMzEwyMzNDHyJPPPEEvXr1IjMzkx//+Meh9oXflRoe36BBg/jRj35ERkYGEJjjpk+fPvTo0YM5c+aE9lmyZAnZ2dlkZmYyePBg/H4/Xbt2Zffu3UDgg+fb3/52aFrhU8FzPXR10CXW/ebt37BxX+3n966N9NbpTM2dekL7fPTRRyxbtoz4+HgOHDjAypUrSUhIYNmyZdxxxx0899xzx+2zceNGVqxYQXFxMd27d2fixIkkJiZWKPPOO+9QUFDA2WefTf/+/Xn99dfJycnhxhtvZOXKlXTu3LnaB2vMmzePcePGMXz4cO644w5KS0tJTExk0qRJDBw4kAULFuDz+Th48CAFBQXMmDGD119/ndTUVPbt21dju99++202bNhA586dAXjsscdo3bo1hw4d4rzzzmPkyJH4/X4mTJgQinffvn3ExcVx9dVX89RTT3HrrbeybNkyMjMzSU1NPaH3/ZvwXg89zNktkqMdgkjMGj16dGjIoaioiNGjR9OzZ08mT55c5dS3l112GUlJSaSmpnLGGWewa9eu48rk5ubSoUMH4uLiyMrKorCwkI0bN9KlS5dQEq0qoR89epTFixdzxRVX0Lx5c/r27ctLLwWmAnn55ZeZOHEiEJiBsUWLFrz88suMGjUqlFRbt25dY7tzc3NDcUDgIReZmZmcf/75bN++nY8//pg333yTiy66KFSuvN7x48fzxBNPAIEPguuuu67G49Ul7/XQw4Zcvn1ms6oLinjUifak60vTpk1Dy3fddReDBg1iwYIFFBYWVjluXT6lLVQ9rW2kMrWdU2rJkiUUFRWFhkNKSkpo0qQJl10WeU4n51zE6XwTEhJCJ1SdcxVO/oa3+5VXXmHZsmW88cYbNGnShLy8PA4fPlxlvR07duTMM8/k5Zdf5q233qowq+Sp4OkeerQmFhM53RQVFdG+fXsA5s6dW+f1p6ens3Xr1tCDKp5++umI5ebNm8ejjz5KYWEhhYWFbNu2jZdeeomSkhIGDx7Mww8/DAROaB44cIDBgwfzzDPPsHfvXoDQkEtaWhpr164F4J///CelpaURj1dUVESrVq1o0qQJGzdu5M033wTgggsu4NVXX2Xbtm0V6gW4/vrrufrqq/nhD394yk+qejChK4mLnGq33XYbt99+O/3798fn89V5/Y0bN2b27NkMHTqUAQMGcOaZZ9KiRYsKZUpKSli6dGmF3njTpk0ZMGAAzz//PA8++CArVqwgIyODPn36UFBQQI8ePfjlL3/JwIEDyczMZMqUKQBMmDCBV199ldzcXN56660KvfJwQ4cOpaysjF69enHXXXdx/vnnA9C2bVvmzJnDiBEjyMzMZMyYMaF9hg0bxsGDB0/5cAt4cPrct++ZRLOn/w3Ar38xlyf/q29dhyZyymn6XDh48CApKSk457j55pvp2rUrkydPjnZYJ2zNmjVMnjyZ11577RvXFfPT54Zft6gRF5HY8ec//5msrCx69OhBUVERN954Y7RDOmH3338/I0eO5L777ovK8T13UjR8yMVp+EUkZkyePNmTPfJw06ZNY9q0aVE7vud66EriIiKReS6hh9OQi4jIMUroIiIxolYJ3cyGmtkmM9tsZlUOEJnZeWbmM7NRdRdiRa7CsjK6iEi5GhO6mcUDDwGXAOcC48zs3CrK/QZYWtdBhnONPHgeV6SBy8vLY+nSiv91H3jgAX7yk59Uu0/5pceXXnop+/fvP67M9OnTmTlzZrXHXrhwIR988EHo9d13382yZctOIPrqnU5T7damh54LbHbObXXOHQXmA8MjlLsFeA74sg7jO85ZbbsA0ORbJRpyEakj48aNY/78+RXWzZ8/v9pJssItXryYli1bntSxKyf0X/3qVwwZMuSk6qqs8lS79aU+brY6GbVJ6O2B7WGvdwTXhZhZe+BK4JHqKjKzG8xsjZmtKZ9i8kS1SGoOQFK8n7e21TxzmojUbNSoUbzwwgscOXIEgMLCQnbu3MmAAQOYOHEiOTk59OjRg3vuuSfi/mlpaaFpYmfMmEH37t0ZMmRIaJpdCFxnft5555GZmcnIkSMpKSlh1apVLFq0iF/84hdkZWWxZcuWClPbLl++nN69e5ORkcH48eND8aWlpXHPPfeQnZ1NRkYGGzdGnp3ydJtqtzbjF5FmIK/cN34AmOqc80WasCa0k3NzgDkQuFO0ljGKnFa++PWvOfJh3U6fm/SddM66444qt7dp04bc3FyWLFnC8OHDmT9/PmPGjMHMmDFjBq1bt8bn8zF48GDee+89evXqFbGetWvXMn/+fN555x3KysrIzs6mT58+AIwYMYIJEyYAcOedd/KXv/yFW265hWHDhnH55ZczalTFU2+HDx8mPz+f5cuX061bN6655hoefvhhbr31VgBSU1NZt24ds2fPZubMmTz66KPHxXO6TbVbmx76DqBj2OsOwM5KZXKA+WZWCIwCZpvZFd8oMhE5pcKHXcKHW5555hmys7Pp3bs3BQUFFYZHKnvttde48soradKkCc2bN2fYsGGhbRs2bODCCy8kIyODp556qsopeMtt2rSJzp07061bNwCuvfbaCsMmI0aMAKBPnz6hSb3CnY5T7damh74a6GpmnYHPgLHAj8ILOOdCLTKzucALzrmF3zg6kdNQdT3p+nTFFVcwZcoU1q1bx6FDh8jOzmbbtm3MnDmT1atX06pVK/Lz8zl8+HC19VT1LT0/P5+FCxeSmZnJ3LlzeeWVV6qtp6Z5psqn4a1qmt7TcardGnvozrky4KcErl75EHjGOVdgZjeZ2U3fOAIRaRBSUlLIy8tj/Pjxod75gQMHaNq0KS1atGDXrl28+OKL1dZx0UUXsWDBAg4dOkRxcTHPP/98aFtxcTHt2rWjtLS0QvJq1qwZxcXFx9WVnp5OYWEhmzdvBuDJJ59k4MCBtW7P6TjVbq2uQ3fOLXbOdXPOfcs5NyO47hHn3HEnQZ1z+c65Z4+vRUQaunHjxvHuu+8yduxYADIzM+nduzc9evRg/Pjx9O/fv9r9s7OzGTNmDFlZWYwcOZILL7wwtO3ee++lb9++XHzxxaSnp4fWjx07lt/97nf07t2bLVu2hNYnJyfz+OOPM3r0aDIyMoiLi+Omm2rXhzxdp9r13PS5+554gl2/vo9W3Q5y/rmPUHh/5K9PIl6i6XNPTzVNtXui0+d6/i6dqsanREQasvvvv5+HH364Th9T5925XIJfLJZ9WK/3MYmI1Itp06bxySefMGDAgDqr04MJvWJv/Ka/ro1SHCIiDYsHE3pFPr/uT5LYoIeeS7iT+XvwfEIXiQXJycns3btXSV2AQDLfu3cvycnJJ7Sf50+KisSCDh06sGPHDk52jiOJPcnJyXTo0OGE9lFCF2kAEhMTK9xCLnIyNOQiIhIjlNBFRGKE9xK6biISEYnIewldREQi8nBCV09dRCSc9xK6hlxERCLyXkIXEZGIlNBFRGKEErqISIxQQhcRiRFK6CIiMcK7CV2T0omIVOC9hK6rFkVEIvJeQhcRkYg8m9A14iIiUpH3ErruFBURich7CV1ERCJSQhcRiRFK6CIiMUIJXUQkRiihi4jECCV0EZEYUauEbmZDzWyTmW02s2kRtl9lZu8Ff1aZWWbdhxo6Vn1VLSLiaTUmdDOLBx4CLgHOBcaZ2bmVim0DBjrnegH3AnPqOlAREalebXroucBm59xW59xRYD4wPLyAc26Vc+6r4Ms3gQ51G2YEulVURKSC2iT09sD2sNc7guuq8l/Ai5E2mNkNZrbGzNbs3r279lFWrOTk9hMRiXG1SeiRMmjE/rGZDSKQ0KdG2u6cm+Ocy3HO5bRt27b2UVas5OT2ExGJcQm1KLMD6Bj2ugOws3IhM+sFPApc4pzbWzfhiYhIbdWmh74a6Gpmnc2sETAWWBRewMw6Af8Afuyc+6juw6xwsHqtXkTEq2rsoTvnyszsp8BSIB54zDlXYGY3Bbc/AtwNtAFmBy8rLHPO5dRf2CIiUllthlxwzi0GFlda90jY8vXA9XUbmoiInAjdKSoiEiM8mNA1hi4iEokHE7qIiETi3YSuy9FFRCrwXkIPu2zxHPsiioGIiDQs3kvoYXeKNuZoFAMREWlYvJfQyxn4dYJURCTEuwndgVNCFxEJ8V5CDxtD13lREZFjvJfQw6iHLiJyjBK6iEiM8F5CD8vhSugiIsd4L6GH0VUuIiLHeDah64SoiEhFnk3oAGfyVc2FREROE55N6AaMSXgl2mGIiDQYnk3oAKaBFxGREM8mdIcSuohIOO8l9LA7RePxRzEQEZGGxXsJPUyceugiIiHeTegOTD10EZEQzyV0CxtyUQ9dROQYzyX0cB+5jqSmNIp2GCIiDYKHE7rRpFNvmiUnRjsQEZEGwcMJHeINyvwaRxcRAU8ndEeCOXw+jaOLiICnEzokxPkp9Suhi4iApxO68ebmPewuPsKRMl+0gxERiTrvJfSwyxbLr0PfXXykfo+5qwAW3wafv1f7ffx++Pc9sH97/cUlIhLGewk9zIONZgMwfu7q+jnA13ug7Cg8eSW8/Sf404Xw0UtVl//qE/hVG9i5Hj5YCK8/AM9cA7/7duADYWZ3eKgvlOwD/0l+q/jkDdi75eT2FZGY5umEDpBIGV0S9sC216As2FNf/zc4FJwr/WhJIIE6BzvWwpcba1/5774Fs/vCwV3H1u3dHEiq01sEftbPO7b86m/AXwZzBsKz1wXK7/kYvt4d+EA4+AXs3gi/7Qy/al3xWF/vhQ+fDywX74InRwTqLPqsYrnHh8L/ZgeW/X7Y+K9A22rL7w/Ef6J8ZYF969snb4CvtP6PIxKDEmpTyMyGAg8C8cCjzrn7K2234PZLgRIg3zm3ro5jLT9ahVcfJ18De4H/q30NB9IuYdcZ/el4Zipxqx6k0d4PAVjd+EIymxcTf0Y68e/PDxTet7Xizktvr/h64U3Hltc/dfzBjhZXHUjRZ/CHcyuu6301vPPXY6+fux6yxsFZGdCi07H1K34d+AABOKsXtPkWlB6CDjnQ8hzoejFsXw0t2kObrvDZWnjpTvhsTWCfK/8E5w6Hkr3w4lTY+EJgfdfvQeeLoN8tgQ9Ivw8K/wN/G43reD7+hGTidm+EC27G2qbDoX2BeDtdAG88BP1/Bp+8Dttehfx/wdzL4AcP4tplQuNWWKu0wHFK9sGWl6HnSDj6deBD+MAOeP1BaJcFE1YEhtesdo8ZXPvJV3Ro1ZgzmyfXqny4o2V+EuOtwl3IVXHO1apcXavpuF8UHaboUCndz2pWYz1lfkdifN335UqOlpGUEE98nB4NGS3maujdmVk88BFwMbADWA2Mc859EFbmUuAWAgm9L/Cgc65vdfXm5OS4NWvWnHDA+5/7B5//8pe06FzC2X33n/D+4i1ph5+i8oe4iNdNuySdmwZ+66T2NbO1zrmcSNtq8zGdC2x2zm11zh0F5gPDK5UZDjzhAt4EWppZu5OKtgaWGPhSYd2G1Ef10sAkoeEXiT1Nk2o1OHLCalNreyD8Uo0dBHrhNZVpD3weXsjMbgBuAOjUqRMno/kll3Dko49oc8MN0PwvofWHvtzC/qIDtCtciOuTj/vrSOJ6jeFIv8nsKfHRvugd8Ptwn63jQNFXNMscjit4jvjeV0Pha4EhgrIj8P37YPO/Kc26hkNlfpr7D0LT1MCQROkh6H4JfLIqMCzQtC2smAHpl3MkOZVGlGJHimH7W3DkAPSbBCV74NB+3Nd7sCMH+DptCI39Jezdtp42hz8l7uhBWHZPxUZmXQVpF8KHiyjLvYmEPZvgnSfgcBH8eCF8uAi2r8Y1aoq9/wzu0pkcTRtE4qE9uLVzif9gAb4r5+BLaMKRs3NJKv6URolJYMaBpDPwuzhaugPw+XrcpiXQpA1l37qYhLQLKN7yFo3adib5q4/x+XwciW9MsjvC4a8+o/ELNweGdIb9Ef+aucS/9RCuUQr+Fp0oa9mFpI9fwN+pH3GfrsINfwj7580cOWcQHPyCpL0f4pp3wJ3xHeI2/zviv61L/wG28fnQ6+Jrl/N62wxSU5Io9fnZXXyEdi2SQ6cMAiMyxuFSHwlxRkJ8HIdLfSQnxuPzO+KC24sOlZKUEEdyYnzF4wWHMZxz7Dl4lLbNkipscw7i4gL1JyXEURq8iS3OID4uMERT5vPzVUkpjRLiaJaUgBkc9fk5XOqneXKw82HGZ/sP0b5l41DdZX5Hqc9PQlwcfuf4aFcxnVOb0ighjje27CUhLo6MDi1onpyAmeH3Oz7dV8I5bZqE2l9S6qNpo3icA59z+PyO/SWltElpRGJ8HEUlpTRNig/FWv5tvNTnSIgzzAKnX74qOUrrpo0o8zsOHCrFzGjZOJFte78mrU1TSn1+Dh310Sw5gTiz0PteruhQKT6/o3XTRhw66sOM495rgDJf4BzM10d8tGhybMqOI2U+khLig++HUepzHCr10aJxoMzeg0do3jiRxPg4tu4+yNdHfHRu25QmifH4g+9lcmI8JUfLaNIogaNl/lD7Sn3uuOG08n/34sOlJCfGkxBnrPt0P13PTKF5cCqR8JGL8L83n9+REB8XqqPM56f4cBmtmjYK/c2U+gP/ruX1FB8uC7XFAV8fLQsdp67VZshlNPB959z1wdc/BnKdc7eElfkXcJ9z7j/B18uB25xza6uq92SHXERETmffdMhlB9Ax7HUHYOdJlBERkXpUm4S+GuhqZp3NrBEwFlhUqcwi4BoLOB8ocs59XrkiERGpPzWOoTvnyszsp8BSApctPuacKzCzm4LbHwEWE7jCZTOByxavq7+QRUQkklqdanXOLSaQtMPXPRK27ICb6zY0ERE5EZ6/U1RERAKU0EVEYoQSuohIjFBCFxGJETXeWFRvBzbbDXxykrunAnvqMJxoUBsaBq+3wevxg9pwos5xzrWNtCFqCf2bMLM1Vd0p5RVqQ8Pg9TZ4PX5QG+qShlxERGKEErqISIzwakKfE+0A6oDa0DB4vQ1ejx/UhjrjyTF0ERE5nld76CIiUokSuohIjPBcQjezoWa2ycw2m9m0aMdTzsweM7MvzWxD2LrWZvZvM/s4+LtV2Lbbg23YZGbfD1vfx8zeD26bZafwicRm1tHMVpjZh2ZWYGY/81o7zCzZzN42s3eDbfhvr7UheOx4M3vHzF7waPyFwWOvN7M1Hm1DSzN71sw2Bv9PXNDg2xB4bJI3fghM37sF6AI0At4Fzo12XMHYLgKygQ1h634LTAsuTwN+E1w+Nxh7EtA52Kb44La3gQsIPBn5ReCSU9iGdkB2cLkZgYeDn+uldgSPlxJcTgTeAs73UhuCx54C/A14waN/S4VAaqV1XmvD/wHXB5cbAS0behtOyRtTh2/wBcDSsNe3A7dHO66weNKomNA3Ae2Cy+2ATZHiJjDX/AXBMhvD1o8D/hTF9vwTuNir7QCaAOsIPAPXM20g8MSv5cB3OZbQPRN/8HiFHJ/QPdMGoDmwjeCFI15pg9eGXKp6GHVDdaYLPrkp+PuM4Pqq2tE+uFx5/SlnZmlAbwI9XE+1IzhcsR74Evi3c85rbXgAuA3wh63zUvwQeB7yS2a21gIPhwdvtaELsBt4PDj09aiZNaWBt8FrCT3S2JMXr7usqh0Non1mlgI8B9zqnDtQXdEI66LeDueczzmXRaCnm2tmPasp3qDaYGaXA1+6ah6wXnmXCOui/m8A9HfOZQOXADeb2UXVlG2IbUggMIT6sHOuN/A1gSGWqjSINngtoXvtYdS7zKwdQPD3l8H1VbVjR3C58vpTxswSCSTzp5xz/wiu9lw7AJxz+4FXgKF4pw39gWFmVgjMB75rZn/FO/ED4JzbGfz9JbAAyMVbbdgB7Ah+uwN4lkCCb9Bt8FpCr80DqxuSRcC1weVrCYxJl68fa2ZJZtYZ6Aq8HfwKV2xm5wfPhF8Ttk+9Cx7zL8CHzrnfh23yTDvMrK2ZtQwuNwaGABu90gbn3O3OuQ7OuTQCf98vO+eu9kr8AGbW1MyalS8D3wM2eKkNzrkvgO1m1j24ajDwQYNvw6k6SVKHJysuJXD1xRbgl9GOJyyuecDnQCmBT+X/AtoQOLn1cfB367Dyvwy2YRNhZ72BHAJ//FuAP1LppEw9t2EAga+D7wHrgz+XeqkdQC/gnWAbNgB3B9d7pg1hx8/j2ElRz8RPYPz53eBPQfn/Uy+1IXjsLGBN8G9pIdCqobdBt/6LiMQIrw25iIhIFZTQRURihBK6iEiMUEIXEYkRSugiIjFCCV1ilpn5grP9lf/U2eycZpZmYTNrijQECdEOQKQeHXKBKQBETgvqoctpJzhX928sMG/622b27eD6c8xsuZm9F/zdKbj+TDNbYIE51t81s37BquLN7M8WmHf9peCdqSJRo4QusaxxpSGXMWHbDjjncgncufdAcN0fgSecc72Ap4BZwfWzgFedc5kE5vMoCK7vCjzknOsB7AdG1mtrRGqgO0UlZpnZQedcSoT1hcB3nXNbg5ORfeGca2NmewjMdV0aXP+5cy7VzHYDHZxzR8LqSCMwNW/X4OupQKJz7n9OQdNEIlIPXU5XrorlqspEciRs2YfOSUmUKaHL6WpM2O83gsurCMxwCHAV8J/g8nJgIoQentH8VAUpciLUo5BY1jj45KJyS5xz5ZcuJpnZWwQ6NeOC6yYBj5nZLwg8rea64PqfAXPM7L8I9MQnEphZU6RB0Ri6nHaCY+g5zrk90Y5FpC5pyEVEJEaohy4iEiPUQxcRiRFK6CIiMUIJXUQkRiihi4jECCV0EZEY8f8BxT3JJY8mkjoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iteration on all the Datasets\n",
    "for dataset_i in range(datasets_number):\n",
    "\n",
    "    # Print best hyperparameters\n",
    "    print(f\"\\n### Best Hyperparameters for Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()\n",
    "\n",
    "    # Plot the learning curve\n",
    "    nn[dataset_i].print_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Retraining of Monk 1 ###\n",
      " Monk:                     1\n",
      " Trial:                    19\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.02, 'batch_size': 33, 'epochs': 360, 'weight_decay': 0.001, 'momentum': 0.07, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.29440661238995697\n",
      " Mean Validation Loss:     0.3488185548699572\n",
      " Mean Training Accuracy:   0.8946947616344325\n",
      " Mean Validation Accuracy: 0.8682064814814783\n",
      "\n",
      "### Retraining of Monk 2 ###\n",
      " Monk:                     2\n",
      " Trial:                    18\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 4, 'learning_rate': 0.51, 'batch_size': 32, 'epochs': 250, 'weight_decay': 0.001, 'momentum': 0.85, 'hidden_activation': 'ReLU', 'optimizer': 'SGD', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.008223163603898489\n",
      " Mean Validation Loss:     0.009403041204786862\n",
      " Mean Training Accuracy:   0.9976929290738034\n",
      " Mean Validation Accuracy: 0.9973125\n",
      "\n",
      "### Retraining of Monk 3 ###\n",
      " Monk:                     3\n",
      " Trial:                    2\n",
      " Hyperparameters:          {'input_size': 17, 'hidden_size': 2, 'learning_rate': 0.007, 'batch_size': 32, 'epochs': 360, 'weight_decay': 0.01, 'momentum': 0.5, 'hidden_activation': 'Tanh', 'optimizer': 'Adam', 'metrics': 'accuracy'}\n",
      " Mean Training Loss:       0.14151036204964212\n",
      " Mean Validation Loss:     0.24392057843713347\n",
      " Mean Training Accuracy:   0.9684800511467987\n",
      " Mean Validation Accuracy: 0.9278018518518564\n"
     ]
    }
   ],
   "source": [
    "# Iterations on each Dataset\n",
    "for dataset_i in range(datasets_number):\n",
    "\n",
    "    # Training the model\n",
    "    nn[dataset_i].fit(\n",
    "        x_train=x_train[dataset_i].values,\n",
    "        y_train=y_train[dataset_i].values\n",
    "    )\n",
    "\n",
    "    # Print values\n",
    "    print(f\"\\n### Retraining of Monk {dataset_i+1} ###\")\n",
    "    nn[dataset_i].print_training_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ts_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m y_test[dataset_i]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate the Model on TS set\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mnn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_i\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Computes the score of the Model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m nn[dataset_i]\u001b[38;5;241m.\u001b[39mscore()\n",
      "File \u001b[1;32mc:\\Users\\corra\\Documents\\GitHub\\Machine_Learning_Project\\api\\pytorch\\binary_nn.py:474\u001b[0m, in \u001b[0;36mBinaryNN.test\u001b[1;34m(self, x_test, y_test)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# Updates the history\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mts_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(ts_accuracy)\n\u001b[1;32m--> 474\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mts_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(ts_loss)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Updates the mean of the Accuracy and the Loss on TR set\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ts_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ts_accuracy \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts_batch_counter \u001b[38;5;241m+\u001b[39m ts_accuracy) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts_batch_counter\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ts_loss'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation of the Models for each Test set\n",
    "for dataset_i in range(datasets_number):\n",
    "    X = x_test[dataset_i].values\n",
    "    y = y_test[dataset_i].values\n",
    "\n",
    "    # Evaluate the Model on TS set\n",
    "    nn[dataset_i].test(\n",
    "        x_test=X,\n",
    "        y_test=y\n",
    "    )\n",
    "\n",
    "    # Computes the score of the Model\n",
    "    nn[dataset_i].score()\n",
    "\n",
    "    # Prints the results obtained\n",
    "    print(nn[dataset_i])\n",
    "    nn[dataset_i].print_confusion_matrix(y_test=y)\n",
    "    nn[dataset_i].print_roc_curve(y_test=y)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
